{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "datadir = '/root/input/rsna-2022-cervical-spine-fracture-detection'\n",
    "libdir = '/root/workspace/RSNA2022RAWE'\n",
    "outputdir = '/root/workspace/RSNA2022RAWE'\n",
    "otherdir = '/root/workspace/RSNA2022RAWE'\n",
    "train_bs_ = 4\n",
    "valid_bs_ = 8\n",
    "num_workers_ = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU'\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    fold_num=5\n",
    "\n",
    "    target_cols=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\"]\n",
    "    num_classes=7\n",
    "\n",
    "    accum_iter=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] # [0.485, 0.456, 0.406] [0.4824, 0.4824, 0.4824]\n",
    "    normalize_std=[0.22, 0.22, 0.22] # [0.229, 0.224, 0.225] [0.22, 0.22, 0.22]\n",
    "    \n",
    "    suffix=\"401\" \n",
    "    fold_list=[0] \n",
    "    epochs=25\n",
    "    model_arch=\"resnet50d\" # tf_efficientnetv2_s, resnest50d\n",
    "    img_size=320\n",
    "    optimizer=\"AdamW\"\n",
    "    scheduler=\"CosineAnnealingLR\"\n",
    "    loss_fn=\"BCEWithLogitsLoss\"\n",
    "    scheduler_warmup=\"GradualWarmupSchedulerV3\" \n",
    "\n",
    "    warmup_epo=1\n",
    "    warmup_factor = 10\n",
    "    T_max= epochs-warmup_epo-2 if scheduler_warmup==\"GradualWarmupSchedulerV2\" else \\\n",
    "           epochs-warmup_epo-1 if scheduler_warmup==\"GradualWarmupSchedulerV3\" else epochs-1 # CosineAnnealingLR\n",
    "    \n",
    "    seq_len = 24\n",
    "    # lr=5e-4\n",
    "    lr = 0.001\n",
    "    min_lr=1e-6 \n",
    "    weight_decay=0\n",
    "    dropout=0.1\n",
    "\n",
    "    gpu_parallel=False\n",
    "    n_early_stopping=4\n",
    "    debug=False\n",
    "    multihead=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.16.2)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (20.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.21.6)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (2.4.6)\n",
      "Installing collected packages: tifffile, scikit-image\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.16.2\n",
      "    Uninstalling scikit-image-0.16.2:\n",
      "      Successfully uninstalled scikit-image-0.16.2\n",
      "Successfully installed scikit-image-0.19.3 tifffile-2021.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting timm\n",
      "  Using cached timm-0.6.11-py3-none-any.whl (548 kB)\n",
      "Collecting torch>=1.7\n",
      "  Using cached torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.3.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (59.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (0.34.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.0.12)\n",
      "Collecting packaging>=20.9\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\n",
      "Installing collected packages: packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, huggingface-hub, torch, torchvision, timm\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.11.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-21.3 timm-0.6.11 torch-1.13.0 torchvision-0.14.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-4.0.2-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from nibabel) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nibabel) (59.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from nibabel) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->nibabel) (2.4.6)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-4.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting python-gdcm\n",
      "  Using cached python_gdcm-3.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Installing collected packages: python-gdcm\n",
      "Successfully installed python-gdcm-3.0.19\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pylibjpeg\n",
      "  Using cached pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting pylibjpeg-libjpeg\n",
      "  Using cached pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting pydicom\n",
      "  Using cached pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n",
      "Installing collected packages: pylibjpeg-libjpeg, pylibjpeg, pydicom\n",
      "Successfully installed pydicom-2.3.1 pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (6.0)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Using cached opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (0.22.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.16.1->albumentations) (4.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (0.14.1)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.0 opencv-python-headless-4.6.0.66 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting segmentation_models_pytorch\n",
      "  Using cached segmentation_models_pytorch-0.3.0-py3-none-any.whl (97 kB)\n",
      "Collecting efficientnet-pytorch==0.7.1\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (9.2.0)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (4.42.1)\n",
      "Collecting pretrainedmodels==0.7.4\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\n",
      "Collecting timm==0.4.12\n",
      "  Using cached timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
      "Collecting munch\n",
      "  Using cached munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (59.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (0.34.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.12)\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 0.6.11\n",
      "    Uninstalling timm-0.6.11:\n",
      "      Successfully uninstalled timm-0.6.11\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-2.5.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.0 timm-0.4.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-image\n",
    "!pip install timm\n",
    "!pip install nibabel\n",
    "! pip install python-gdcm\n",
    "! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n",
    "!pip install -U albumentations\n",
    "!pip install segmentation_models_pytorch\n",
    "!pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [f'{libdir}pytorch-image-models-master']\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "import ast\n",
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import gc \n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(f'{datadir}/vertebrae_df.pkl')\n",
    "submission_df = pd.read_csv(f'{datadir}/sample_submission.csv')\n",
    "\n",
    "train_df = train_df[train_df[\"StudyInstanceUID\"] != \"1.2.826.0.1.3680043.20574\"].reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"StudyInstanceUID\"] != \"1.2.826.0.1.3680043.29952\"].reset_index(drop=True)\n",
    "train_df\n",
    "\n",
    "gkf = GroupKFold(n_splits=CFG.fold_num)\n",
    "folds = gkf.split(X=train_df, y=None, groups=train_df['StudyInstanceUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    VERSION = \"1.7\"\n",
    "    CP_V = \"36\" if ENV == \"colab\" else \"37\"\n",
    "    wheel = f\"torch_xla-{VERSION}-cp{CP_V}-cp{CP_V}m-linux_x86_64.whl\"\n",
    "    url = f\"https://storage.googleapis.com/tpu-pytorch/wheels/{wheel}\"\n",
    "    !pip3 -q install cloud-tpu-client==0.10 $url\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.train_bs = CFG.train_bs // CFG.nprocs\n",
    "    device = xm.xla_device()\n",
    "    \n",
    "elif CFG.device == \"GPU\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=outputdir+'stage2_train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger(outputdir+f'/stage2_train{CFG.suffix}.log')\n",
    "\n",
    "if CFG.device=='TPU' and CFG.nprocs==8:\n",
    "    loginfo = xm.master_print\n",
    "    cusprint = xm.master_print\n",
    "else:\n",
    "    loginfo = LOGGER.info\n",
    "    cusprint = print\n",
    "\n",
    "\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    # data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        study_id = row[\"StudyInstanceUID\"]\n",
    "        slice_num_list = row['slice_num_list']\n",
    "        slice_list = []\n",
    "        for s_num in slice_num_list:\n",
    "            path = f\"{datadir}/train_images/{study_id}/{s_num}.dcm\"\n",
    "            img = load_dicom(path)\n",
    "            if len(slice_list) == 0:\n",
    "                imgh = img.shape[0]\n",
    "                imgw = img.shape[1]\n",
    "            elif img.shape != (imgh, imgw):\n",
    "                img = cv2.resize(img,(imgh,imgw))\n",
    "\n",
    "            slice_list.append(img)\n",
    "        for _ in range(CFG.seq_len - len(slice_list)):\n",
    "            slice_list.append(np.zeros((imgh,imgw)))\n",
    "\n",
    "        image = np.stack(slice_list, axis=2) # 512*512*seq_len; 0-1\n",
    "\n",
    "        assert image.shape == (imgh, imgw, CFG.seq_len)\n",
    "\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1)) # seq_len*img_size*img_size; 0-1\n",
    "        return torch.from_numpy(image), torch.tensor(row['label']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n",
    "    CenterCrop, Resize, RandomCrop, GaussianBlur, JpegCompression, Downscale, ElasticTransform\n",
    ")\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(CFG.img_size, CFG.img_size, scale=(0.9, 1), p=1), \n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "            CLAHE(clip_limit=(1,4), p=0.5),\n",
    "            OneOf([\n",
    "                OpticalDistortion(distort_limit=1.0),\n",
    "                GridDistortion(num_steps=5, distort_limit=1.),\n",
    "                ElasticTransform(alpha=3),\n",
    "            ], p=0.2),\n",
    "            OneOf([\n",
    "                GaussNoise(var_limit=[10, 50]),\n",
    "                GaussianBlur(),\n",
    "                MotionBlur(),\n",
    "                MedianBlur(),\n",
    "            ], p=0.2),\n",
    "            Resize(CFG.img_size, CFG.img_size),\n",
    "            OneOf([\n",
    "                JpegCompression(),\n",
    "                Downscale(scale_min=0.1, scale_max=0.15),\n",
    "            ], p=0.2),\n",
    "            IAAPiecewiseAffine(p=0.2),\n",
    "            IAASharpen(p=0.2),\n",
    "            Cutout(max_h_size=int(CFG.img_size * 0.1), max_w_size=int(CFG.img_size * 0.1), num_holes=5, p=0.5),\n",
    "            ])\n",
    "    elif data == 'light_train':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20, p=0.5),\n",
    "            OneOf([\n",
    "                # GaussNoise(),\n",
    "                GaussianBlur(),\n",
    "                MotionBlur(),\n",
    "                # MedianBlur(),\n",
    "            ], p=0.3),\n",
    "            OneOf([\n",
    "                GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "                OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "                ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "            ], p=0.3),\n",
    "            # CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "            #              min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "            ], p=1.0)    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "dataset_show = TrainDataset(\n",
    "    train_df,\n",
    "    transform=get_transforms(data='light_train') # None, get_transforms(data='check')\n",
    "    )\n",
    "rcParams['figure.figsize'] = 30,20\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1,5)\n",
    "    idx = np.random.randint(0, len(dataset_show))\n",
    "    img, label= dataset_show[idx]\n",
    "    # axarr[p].imshow(img) # transform=None\n",
    "    axarr[0].imshow(img[0]); plt.axis('OFF');\n",
    "    axarr[1].imshow(img[1]); plt.axis('OFF');\n",
    "    axarr[2].imshow(img[2]); plt.axis('OFF');\n",
    "    axarr[3].imshow(img[3]); plt.axis('OFF');\n",
    "    axarr[4].imshow(img[4]); plt.axis('OFF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from itertools import repeat\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict, Optional\n",
    " \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "    \n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        return attn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, hidden_dim=256, seq_len=24, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.model = timm.create_model(model_arch, in_chans=1, pretrained=pretrained)\n",
    "\n",
    "        if 'efficientnet' in CFG.model_arch:\n",
    "            cnn_feature = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "        elif \"res\" in CFG.model_arch:\n",
    "            cnn_feature = self.model.fc.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.fc = nn.Identity()\n",
    "            self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(cnn_feature, hidden_dim, 2, batch_first=True, bidirectional=True)\n",
    "        self.mlp_attention_layer = MLPAttentionNetwork(2 * hidden_dim)\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(CFG.dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "\n",
    "    def forward(self, x): # (B, seq_len, H, W)\n",
    "        bs = x.size(0) \n",
    "        x = x.reshape(bs*self.seq_len, 1, x.size(2), x.size(3)) # (B*seq_len, 1, H, W)\n",
    "        features = self.model(x)   \n",
    "        if \"res\" in CFG.model_arch:                             \n",
    "            features = self.pooling(features).view(bs*self.seq_len, -1) # (B*seq_len, cnn_feature)\n",
    "        features = self.spatialdropout(features)                # (B*seq_len, cnn_feature)\n",
    "        # print(features.shape)\n",
    "        features = features.reshape(bs, self.seq_len, -1)       # (B, seq_len, cnn_feature)\n",
    "        features, _ = self.gru(features)                        # (B, seq_len, hidden_dim*2)\n",
    "        atten_out = self.mlp_attention_layer(features)          # (B, hidden_dim*2)\n",
    "        pred = self.logits(atten_out)                           # (B, 1)\n",
    "        pred = pred.view(bs, -1)                                # (B, 1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init GRU(2048, 256, num_layers=2, batch_first=True, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "model = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=24, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size, stride, padding,\n",
    "        bias=False, use_bn=True, activ=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels,\n",
    "        out_channels_list,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadResNet200D(nn.Module):\n",
    "    def __init__(self, out_dims_head=[3, 4, 3, 1],  pretrained=False):\n",
    "        self.base_name = \"resnet200d_320\"\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadResNet200D, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(self.base_name, num_classes=sum(out_dims_head), pretrained=False)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        if pretrained:\n",
    "            pretrained_model_path = CFG.student\n",
    "            state_dict = dict()\n",
    "            for k, v in torch.load(pretrained_model_path, map_location='cpu')[\"model\"].items():\n",
    "                if k[:6] == \"model.\":\n",
    "                    k = k.replace(\"model.\", \"\")\n",
    "                state_dict[k] = v\n",
    "            base_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        hs = [getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return None, None, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                y_preds = model(images)\n",
    "                y_preds = y_preds.squeeze(1)\n",
    "                loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        elif CFG.device == 'TPU':\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            cusprint('Epoch: [{0}][{1}/{2}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                'Grad: {grad_norm:.4f}  '\n",
    "                'LR: {lr:.7f}  '\n",
    "                .format(\n",
    "                epoch, step, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                grad_norm=grad_norm,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                ))\n",
    "\n",
    "    return losses.avg, optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.accum_iter > 1:\n",
    "            loss = loss / CFG.accum_iter\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            cusprint('EVAL: [{0}/{1}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                ))\n",
    "\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss & optimizer & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(df, fold, trn_idx, val_idx):\n",
    "    loginfo(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = train_df.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train_df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='light_train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='valid'))\n",
    "    if CFG.device == 'GPU':\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.train_bs, sampler=train_sampler, drop_last=True, num_workers=CFG.num_workers)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.valid_bs, sampler=valid_sampler, drop_last=False, num_workers=CFG.num_workers)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer & scheduler & loss\n",
    "    # ====================================================\n",
    "    # not checkpoint\n",
    "\n",
    "    if CFG.multihead:\n",
    "        model = MultiHeadResNet200D([3, 4, 3, 1], True)\n",
    "    else:\n",
    "        model = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=24, pretrained=True)\n",
    "\n",
    "        \n",
    "    if CFG.gpu_parallel:    \n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        model = DataParallel(model, device_ids=range(num_gpu))\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    if CFG.optimizer == \"AdamW\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    # scheduler\n",
    "    if CFG.scheduler=='ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "    elif CFG.scheduler=='CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "\n",
    "    scheduler_warmup = GradualWarmupSchedulerV3(optimizer, multiplier=10, total_epoch=CFG.warmup_epo, after_scheduler=scheduler)\n",
    "\n",
    "    # loss\n",
    "    if CFG.loss_fn == \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    valid_acc_max=0; valid_loss_min=float(\"inf\")\n",
    "    valid_acc_max_cnt=0; valid_loss_min_cnt=0;\n",
    "    best_acc_epoch=0;\n",
    "\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        loginfo(f\"***** Epoch {epoch} *****\")\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            loginfo(f\"schwarmup_last_epoch:{scheduler_warmup.last_epoch}, schwarmup_lr:{scheduler_warmup.get_last_lr()[0]}\")\n",
    "        if CFG.scheduler=='CosineAnnealingLR':\n",
    "            loginfo(f\"scheduler_last_epoch:{scheduler.last_epoch}, scheduler_lr:{scheduler.get_last_lr()[0]}\")\n",
    "        loginfo(f\"optimizer_lr:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "                \n",
    "        start_time = time.time()\n",
    "        \n",
    "        avg_loss, cur_lr = train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device) # train\n",
    "        avg_val_loss, preds, _ = valid_one_epoch(valid_loader, model, criterion, device) # valid\n",
    "\n",
    "        # scoring\n",
    "        elapsed = time.time() - start_time \n",
    "\n",
    "        loginfo(f'Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            scheduler_warmup.step()\n",
    "        elif CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif CFG.scheduler in [\"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "        # early stopping\n",
    "        if avg_val_loss < valid_loss_min:\n",
    "            valid_loss_min = avg_val_loss\n",
    "            valid_loss_min_cnt=0\n",
    "            best_acc_epoch = epoch\n",
    "        else:\n",
    "            valid_loss_min_cnt+=1\n",
    "\n",
    "        if valid_loss_min_cnt >= CFG.n_early_stopping:\n",
    "            if CFG.device == 'GPU':\n",
    "                torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                xm.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "            print(\"early_stopping\")\n",
    "            break\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "        elif CFG.device == 'TPU':\n",
    "            xm.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        if fold in CFG.fold_list:\n",
    "            train_loop(train_df, fold, trn_idx, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_cid</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>cid</th>\n",
       "      <th>slice_num_list</th>\n",
       "      <th>before_image_size</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10001_1</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>1</td>\n",
       "      <td>[50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 63, 6...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10001_2</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10001_3</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>3</td>\n",
       "      <td>[108, 109, 110, 111, 112, 113, 114, 115, 116, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.10001_4</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>4</td>\n",
       "      <td>[129, 130, 131, 132, 133, 134, 135, 136, 137, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.10001_5</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>5</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13555</th>\n",
       "      <td>1.2.826.0.1.3680043.9997_3</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>3</td>\n",
       "      <td>[93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 10...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13556</th>\n",
       "      <td>1.2.826.0.1.3680043.9997_4</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>4</td>\n",
       "      <td>[114, 115, 116, 117, 118, 119, 120, 121, 122, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13557</th>\n",
       "      <td>1.2.826.0.1.3680043.9997_5</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>5</td>\n",
       "      <td>[136, 137, 138, 139, 140, 141, 142, 144, 145, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13558</th>\n",
       "      <td>1.2.826.0.1.3680043.9997_6</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>6</td>\n",
       "      <td>[158, 159, 160, 161, 162, 163, 164, 165, 166, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13559</th>\n",
       "      <td>1.2.826.0.1.3680043.9997_7</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>7</td>\n",
       "      <td>[175, 176, 177, 178, 179, 180, 181, 182, 183, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13560 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         study_cid           StudyInstanceUID  cid  \\\n",
       "0      1.2.826.0.1.3680043.10001_1  1.2.826.0.1.3680043.10001    1   \n",
       "1      1.2.826.0.1.3680043.10001_2  1.2.826.0.1.3680043.10001    2   \n",
       "2      1.2.826.0.1.3680043.10001_3  1.2.826.0.1.3680043.10001    3   \n",
       "3      1.2.826.0.1.3680043.10001_4  1.2.826.0.1.3680043.10001    4   \n",
       "4      1.2.826.0.1.3680043.10001_5  1.2.826.0.1.3680043.10001    5   \n",
       "...                            ...                        ...  ...   \n",
       "13555   1.2.826.0.1.3680043.9997_3   1.2.826.0.1.3680043.9997    3   \n",
       "13556   1.2.826.0.1.3680043.9997_4   1.2.826.0.1.3680043.9997    4   \n",
       "13557   1.2.826.0.1.3680043.9997_5   1.2.826.0.1.3680043.9997    5   \n",
       "13558   1.2.826.0.1.3680043.9997_6   1.2.826.0.1.3680043.9997    6   \n",
       "13559   1.2.826.0.1.3680043.9997_7   1.2.826.0.1.3680043.9997    7   \n",
       "\n",
       "                                          slice_num_list  before_image_size  \\\n",
       "0      [50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 63, 6...                320   \n",
       "1      [1, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92...                320   \n",
       "2      [108, 109, 110, 111, 112, 113, 114, 115, 116, ...                320   \n",
       "3      [129, 130, 131, 132, 133, 134, 135, 136, 137, ...                320   \n",
       "4      [154, 155, 156, 157, 158, 159, 160, 161, 162, ...                320   \n",
       "...                                                  ...                ...   \n",
       "13555  [93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 10...                320   \n",
       "13556  [114, 115, 116, 117, 118, 119, 120, 121, 122, ...                320   \n",
       "13557  [136, 137, 138, 139, 140, 141, 142, 144, 145, ...                320   \n",
       "13558  [158, 159, 160, 161, 162, 163, 164, 165, 166, ...                320   \n",
       "13559  [175, 176, 177, 178, 179, 180, 181, 182, 183, ...                320   \n",
       "\n",
       "       x0   x1  y0   y1  z0   z1  label  \n",
       "0       0  267   2  273  48  277      0  \n",
       "1       0  267   2  273  48  277      0  \n",
       "2       0  267   2  273  48  277      0  \n",
       "3       0  267   2  273  48  277      0  \n",
       "4       0  267   2  273  48  277      0  \n",
       "...    ..  ...  ..  ...  ..  ...    ...  \n",
       "13555   0  254   2  262   3  252      0  \n",
       "13556   0  254   2  262   3  252      0  \n",
       "13557   0  254   2  262   3  252      0  \n",
       "13558   0  254   2  262   3  252      0  \n",
       "13559   0  254   2  262   3  252      0  \n",
       "\n",
       "[13560 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "init GRU(2048, 256, num_layers=2, batch_first=True, bidirectional=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:0.0001\n",
      "scheduler_last_epoch:0, scheduler_lr:0.0001\n",
      "optimizer_lr:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/2712] Data 5.687 (5.687) Elapsed 0m 18s (remain 830m 54s) Loss: 0.6663(0.6663) Grad: 99198.4688  LR: 0.0001000  \n",
      "Epoch: [0][100/2712] Data 0.000 (0.057) Elapsed 1m 42s (remain 44m 8s) Loss: 0.0023(0.4971) Grad: 708.3766  LR: 0.0001000  \n",
      "Epoch: [0][200/2712] Data 0.000 (0.029) Elapsed 3m 5s (remain 38m 41s) Loss: 0.0007(0.5808) Grad: 253.1853  LR: 0.0001000  \n",
      "Epoch: [0][300/2712] Data 0.000 (0.019) Elapsed 4m 29s (remain 36m 0s) Loss: 0.0020(0.6324) Grad: 633.3929  LR: 0.0001000  \n",
      "Epoch: [0][400/2712] Data 0.000 (0.014) Elapsed 5m 54s (remain 34m 2s) Loss: 1.7771(0.6241) Grad: 91104.1719  LR: 0.0001000  \n",
      "Epoch: [0][500/2712] Data 0.000 (0.012) Elapsed 7m 20s (remain 32m 26s) Loss: 0.0008(0.6162) Grad: 274.3682  LR: 0.0001000  \n",
      "Epoch: [0][600/2712] Data 0.000 (0.010) Elapsed 8m 48s (remain 30m 57s) Loss: 1.7343(0.6199) Grad: 91561.3203  LR: 0.0001000  \n",
      "Epoch: [0][700/2712] Data 0.000 (0.008) Elapsed 10m 17s (remain 29m 31s) Loss: 3.0664(0.6273) Grad: 160607.9062  LR: 0.0001000  \n",
      "Epoch: [0][800/2712] Data 0.000 (0.007) Elapsed 11m 46s (remain 28m 4s) Loss: 0.0012(0.6325) Grad: 408.1832  LR: 0.0001000  \n",
      "Epoch: [0][900/2712] Data 0.000 (0.007) Elapsed 13m 14s (remain 26m 36s) Loss: 0.0010(0.6257) Grad: 361.6300  LR: 0.0001000  \n",
      "Epoch: [0][1000/2712] Data 0.000 (0.006) Elapsed 14m 38s (remain 25m 1s) Loss: 0.0019(0.6247) Grad: 608.7421  LR: 0.0001000  \n",
      "Epoch: [0][1100/2712] Data 0.000 (0.005) Elapsed 16m 1s (remain 23m 27s) Loss: 0.0010(0.6316) Grad: 349.6617  LR: 0.0001000  \n",
      "Epoch: [0][1200/2712] Data 0.000 (0.005) Elapsed 17m 25s (remain 21m 55s) Loss: 1.5642(0.6409) Grad: 86128.5938  LR: 0.0001000  \n",
      "Epoch: [0][1300/2712] Data 0.000 (0.005) Elapsed 18m 51s (remain 20m 27s) Loss: 0.0017(0.6456) Grad: 563.7941  LR: 0.0001000  \n",
      "Epoch: [0][1400/2712] Data 0.000 (0.004) Elapsed 20m 18s (remain 19m 0s) Loss: 0.0013(0.6566) Grad: 452.8330  LR: 0.0001000  \n",
      "Epoch: [0][1500/2712] Data 0.000 (0.004) Elapsed 21m 47s (remain 17m 34s) Loss: 0.0025(0.6693) Grad: 788.4688  LR: 0.0001000  \n",
      "Epoch: [0][1600/2712] Data 0.000 (0.004) Elapsed 23m 15s (remain 16m 8s) Loss: 0.0014(0.6655) Grad: 493.5764  LR: 0.0001000  \n",
      "Epoch: [0][1700/2712] Data 0.000 (0.004) Elapsed 24m 43s (remain 14m 41s) Loss: 1.6881(0.6670) Grad: 90860.0156  LR: 0.0001000  \n",
      "Epoch: [0][1800/2712] Data 0.000 (0.003) Elapsed 26m 11s (remain 13m 15s) Loss: 0.0014(0.6644) Grad: 477.3322  LR: 0.0001000  \n",
      "Epoch: [0][1900/2712] Data 0.000 (0.003) Elapsed 27m 39s (remain 11m 48s) Loss: 3.1357(0.6648) Grad: 173813.0938  LR: 0.0001000  \n",
      "Epoch: [0][2000/2712] Data 0.000 (0.003) Elapsed 29m 8s (remain 10m 21s) Loss: 0.0008(0.6667) Grad: 290.4651  LR: 0.0001000  \n",
      "Epoch: [0][2100/2712] Data 0.000 (0.003) Elapsed 30m 36s (remain 8m 54s) Loss: 1.7965(0.6632) Grad: 209975.6875  LR: 0.0001000  \n",
      "Epoch: [0][2200/2712] Data 0.000 (0.003) Elapsed 32m 5s (remain 7m 27s) Loss: 0.0015(0.6632) Grad: 519.8716  LR: 0.0001000  \n",
      "Epoch: [0][2300/2712] Data 0.000 (0.003) Elapsed 33m 33s (remain 5m 59s) Loss: 1.6671(0.6567) Grad: 91472.0078  LR: 0.0001000  \n",
      "Epoch: [0][2400/2712] Data 0.000 (0.003) Elapsed 35m 1s (remain 4m 32s) Loss: 0.0010(0.6550) Grad: 353.1104  LR: 0.0001000  \n",
      "Epoch: [0][2500/2712] Data 0.000 (0.003) Elapsed 36m 29s (remain 3m 4s) Loss: 0.0015(0.6550) Grad: 523.9538  LR: 0.0001000  \n",
      "Epoch: [0][2600/2712] Data 0.000 (0.002) Elapsed 37m 58s (remain 1m 37s) Loss: 0.0008(0.6532) Grad: 292.2708  LR: 0.0001000  \n",
      "Epoch: [0][2700/2712] Data 0.000 (0.002) Elapsed 39m 26s (remain 0m 9s) Loss: 0.0021(0.6550) Grad: 707.8889  LR: 0.0001000  \n",
      "Epoch: [0][2711/2712] Data 0.000 (0.002) Elapsed 39m 36s (remain 0m 0s) Loss: 0.0034(0.6559) Grad: 1079.1224  LR: 0.0001000  \n",
      "EVAL: [0/339] Data 6.426 (6.426) Elapsed 0m 14s (remain 80m 38s) Loss: 2.0958(2.0958) \n",
      "EVAL: [100/339] Data 0.000 (0.065) Elapsed 2m 19s (remain 5m 28s) Loss: 1.5404(0.5817) \n",
      "EVAL: [200/339] Data 0.000 (0.033) Elapsed 4m 22s (remain 3m 0s) Loss: 0.0021(0.6316) \n",
      "EVAL: [300/339] Data 0.000 (0.022) Elapsed 6m 20s (remain 0m 48s) Loss: 0.0032(0.6261) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: 0.6559  avg_val_loss: 0.6317  time: 2797s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.020) Elapsed 7m 1s (remain 0m 0s) Loss: 0.0022(0.6317) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:808: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "***** Epoch 1 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:0.0001\n",
      "scheduler_last_epoch:0, scheduler_lr:0.0001\n",
      "optimizer_lr:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2712] Data 6.756 (6.756) Elapsed 0m 7s (remain 345m 20s) Loss: 1.4095(1.4095) Grad: inf  LR: 0.0001000  \n",
      "Epoch: [1][100/2712] Data 0.000 (0.067) Elapsed 1m 31s (remain 39m 14s) Loss: 3.1451(0.6975) Grad: 175137.8125  LR: 0.0001000  \n",
      "Epoch: [1][200/2712] Data 0.001 (0.034) Elapsed 2m 55s (remain 36m 33s) Loss: 0.0018(0.6920) Grad: 614.0773  LR: 0.0001000  \n",
      "Epoch: [1][300/2712] Data 0.000 (0.023) Elapsed 4m 25s (remain 35m 25s) Loss: 0.0007(0.6758) Grad: 278.8288  LR: 0.0001000  \n",
      "Epoch: [1][400/2712] Data 0.000 (0.017) Elapsed 5m 53s (remain 33m 55s) Loss: 1.5173(0.6611) Grad: 85351.6875  LR: 0.0001000  \n",
      "Epoch: [1][500/2712] Data 0.000 (0.014) Elapsed 7m 24s (remain 32m 43s) Loss: 1.5618(0.6733) Grad: 89555.5547  LR: 0.0001000  \n",
      "Epoch: [1][600/2712] Data 0.000 (0.012) Elapsed 8m 53s (remain 31m 13s) Loss: 0.0012(0.6694) Grad: 424.2238  LR: 0.0001000  \n",
      "Epoch: [1][700/2712] Data 0.001 (0.010) Elapsed 10m 22s (remain 29m 45s) Loss: 1.6067(0.6753) Grad: 93016.6484  LR: 0.0001000  \n",
      "Epoch: [1][800/2712] Data 0.000 (0.009) Elapsed 11m 54s (remain 28m 24s) Loss: 0.0030(0.6710) Grad: 936.8574  LR: 0.0001000  \n",
      "Epoch: [1][900/2712] Data 0.000 (0.008) Elapsed 13m 27s (remain 27m 2s) Loss: 1.5881(0.6649) Grad: 94551.8125  LR: 0.0001000  \n",
      "Epoch: [1][1000/2712] Data 0.001 (0.007) Elapsed 14m 53s (remain 25m 27s) Loss: 1.8728(0.6609) Grad: 100743.0859  LR: 0.0001000  \n",
      "Epoch: [1][1100/2712] Data 0.000 (0.007) Elapsed 16m 24s (remain 23m 59s) Loss: 0.0012(0.6578) Grad: 442.4310  LR: 0.0001000  \n",
      "Epoch: [1][1200/2712] Data 0.000 (0.006) Elapsed 17m 47s (remain 22m 22s) Loss: 1.3812(0.6661) Grad: 80795.5625  LR: 0.0001000  \n",
      "Epoch: [1][1300/2712] Data 0.000 (0.006) Elapsed 19m 14s (remain 20m 52s) Loss: 0.0009(0.6715) Grad: 327.9413  LR: 0.0001000  \n",
      "Epoch: [1][1400/2712] Data 0.000 (0.005) Elapsed 20m 46s (remain 19m 26s) Loss: 0.0004(0.6677) Grad: 163.3629  LR: 0.0001000  \n",
      "Epoch: [1][1500/2712] Data 0.000 (0.005) Elapsed 22m 12s (remain 17m 55s) Loss: 0.0008(0.6677) Grad: 295.7685  LR: 0.0001000  \n",
      "Epoch: [1][1600/2712] Data 0.001 (0.005) Elapsed 23m 40s (remain 16m 26s) Loss: 0.0008(0.6605) Grad: 302.9872  LR: 0.0001000  \n",
      "Epoch: [1][1700/2712] Data 0.000 (0.004) Elapsed 25m 10s (remain 14m 57s) Loss: 1.5769(0.6642) Grad: 93831.6641  LR: 0.0001000  \n",
      "Epoch: [1][1800/2712] Data 0.001 (0.004) Elapsed 26m 40s (remain 13m 29s) Loss: 1.7199(0.6601) Grad: 49341.8047  LR: 0.0001000  \n",
      "Epoch: [1][1900/2712] Data 0.000 (0.004) Elapsed 28m 10s (remain 12m 1s) Loss: 0.0030(0.6576) Grad: 508.6443  LR: 0.0001000  \n",
      "Epoch: [1][2000/2712] Data 0.000 (0.004) Elapsed 29m 36s (remain 10m 31s) Loss: 0.0042(0.6551) Grad: 657.2550  LR: 0.0001000  \n",
      "Epoch: [1][2100/2712] Data 0.000 (0.004) Elapsed 31m 0s (remain 9m 0s) Loss: 1.7603(0.6448) Grad: 51264.0938  LR: 0.0001000  \n",
      "Epoch: [1][2200/2712] Data 0.000 (0.003) Elapsed 32m 27s (remain 7m 32s) Loss: 0.0026(0.6405) Grad: 437.7248  LR: 0.0001000  \n",
      "Epoch: [1][2300/2712] Data 0.000 (0.003) Elapsed 33m 59s (remain 6m 4s) Loss: 0.0022(0.6447) Grad: 387.5078  LR: 0.0001000  \n",
      "Epoch: [1][2400/2712] Data 0.000 (0.003) Elapsed 35m 27s (remain 4m 35s) Loss: 1.3688(0.6422) Grad: 41354.5078  LR: 0.0001000  \n",
      "Epoch: [1][2500/2712] Data 0.000 (0.003) Elapsed 36m 56s (remain 3m 7s) Loss: 1.4011(0.6423) Grad: 44470.4883  LR: 0.0001000  \n",
      "Epoch: [1][2600/2712] Data 0.000 (0.003) Elapsed 38m 24s (remain 1m 38s) Loss: 0.0019(0.6380) Grad: 343.6263  LR: 0.0001000  \n",
      "Epoch: [1][2700/2712] Data 0.000 (0.003) Elapsed 39m 59s (remain 0m 9s) Loss: 0.0011(0.6370) Grad: 224.8339  LR: 0.0001000  \n",
      "Epoch: [1][2711/2712] Data 0.000 (0.003) Elapsed 40m 8s (remain 0m 0s) Loss: 0.0028(0.6381) Grad: 489.1531  LR: 0.0001000  \n",
      "EVAL: [0/339] Data 7.844 (7.844) Elapsed 0m 9s (remain 51m 6s) Loss: 2.3696(2.3696) \n",
      "EVAL: [100/339] Data 0.001 (0.078) Elapsed 2m 11s (remain 5m 9s) Loss: 1.6453(0.6220) \n",
      "EVAL: [200/339] Data 0.000 (0.040) Elapsed 4m 12s (remain 2m 53s) Loss: 0.0014(0.6697) \n",
      "EVAL: [300/339] Data 0.000 (0.027) Elapsed 6m 13s (remain 0m 47s) Loss: 0.0026(0.6624) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6381  avg_val_loss: 0.6660  time: 2829s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.024) Elapsed 6m 59s (remain 0m 0s) Loss: 0.0022(0.6660) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 2 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:9.953895432879837e-05\n",
      "scheduler_last_epoch:1, scheduler_lr:9.953895432879837e-05\n",
      "optimizer_lr:9.953895432879837e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2712] Data 4.790 (4.790) Elapsed 0m 5s (remain 258m 19s) Loss: 3.2175(3.2175) Grad: inf  LR: 0.0000995  \n",
      "Epoch: [2][100/2712] Data 0.000 (0.048) Elapsed 1m 33s (remain 40m 12s) Loss: 0.0029(0.6697) Grad: 1003.5286  LR: 0.0000995  \n",
      "Epoch: [2][200/2712] Data 0.000 (0.024) Elapsed 3m 1s (remain 37m 52s) Loss: 0.0007(0.6273) Grad: 292.2397  LR: 0.0000995  \n",
      "Epoch: [2][300/2712] Data 0.000 (0.016) Elapsed 4m 30s (remain 36m 9s) Loss: 0.0010(0.6075) Grad: 389.9406  LR: 0.0000995  \n",
      "Epoch: [2][400/2712] Data 0.000 (0.012) Elapsed 5m 59s (remain 34m 33s) Loss: 1.5041(0.6274) Grad: 95035.3203  LR: 0.0000995  \n",
      "Epoch: [2][500/2712] Data 0.000 (0.010) Elapsed 7m 30s (remain 33m 9s) Loss: 1.5984(0.6375) Grad: 99547.6562  LR: 0.0000995  \n",
      "Epoch: [2][600/2712] Data 0.000 (0.008) Elapsed 9m 5s (remain 31m 54s) Loss: 0.0013(0.6390) Grad: 492.4354  LR: 0.0000995  \n",
      "Epoch: [2][700/2712] Data 0.000 (0.007) Elapsed 10m 33s (remain 30m 18s) Loss: 0.0013(0.6512) Grad: 513.3612  LR: 0.0000995  \n",
      "Epoch: [2][800/2712] Data 0.000 (0.006) Elapsed 12m 7s (remain 28m 56s) Loss: 0.0030(0.6634) Grad: 1058.5339  LR: 0.0000995  \n",
      "Epoch: [2][900/2712] Data 0.000 (0.006) Elapsed 13m 36s (remain 27m 20s) Loss: 1.5705(0.6611) Grad: 49781.6172  LR: 0.0000995  \n",
      "Epoch: [2][1000/2712] Data 0.000 (0.005) Elapsed 15m 6s (remain 25m 49s) Loss: 0.0012(0.6361) Grad: 240.4055  LR: 0.0000995  \n",
      "Epoch: [2][1100/2712] Data 0.000 (0.005) Elapsed 16m 41s (remain 24m 25s) Loss: 1.3415(0.6422) Grad: 43980.4531  LR: 0.0000995  \n",
      "Epoch: [2][1200/2712] Data 0.003 (0.004) Elapsed 18m 13s (remain 22m 55s) Loss: 0.0018(0.6376) Grad: 334.3715  LR: 0.0000995  \n",
      "Epoch: [2][1300/2712] Data 0.000 (0.004) Elapsed 19m 43s (remain 21m 23s) Loss: 1.2007(0.6379) Grad: 39607.6992  LR: 0.0000995  \n",
      "Epoch: [2][1400/2712] Data 0.000 (0.004) Elapsed 21m 15s (remain 19m 53s) Loss: 0.0013(0.6336) Grad: 246.4794  LR: 0.0000995  \n",
      "Epoch: [2][1500/2712] Data 0.003 (0.004) Elapsed 22m 49s (remain 18m 24s) Loss: 0.0043(0.6369) Grad: 722.9115  LR: 0.0000995  \n",
      "Epoch: [2][1600/2712] Data 0.000 (0.003) Elapsed 24m 17s (remain 16m 51s) Loss: 0.0017(0.6322) Grad: 330.3480  LR: 0.0000995  \n",
      "Epoch: [2][1700/2712] Data 0.000 (0.003) Elapsed 25m 53s (remain 15m 23s) Loss: 0.0062(0.6265) Grad: 971.2916  LR: 0.0000995  \n",
      "Epoch: [2][1800/2712] Data 0.000 (0.003) Elapsed 27m 16s (remain 13m 47s) Loss: 0.0022(0.6201) Grad: 418.0939  LR: 0.0000995  \n",
      "Epoch: [2][1900/2712] Data 0.000 (0.003) Elapsed 28m 42s (remain 12m 15s) Loss: 0.0043(0.6182) Grad: 722.7141  LR: 0.0000995  \n",
      "Epoch: [2][2000/2712] Data 0.000 (0.003) Elapsed 30m 15s (remain 10m 45s) Loss: 0.0010(0.6098) Grad: 207.5308  LR: 0.0000995  \n",
      "Epoch: [2][2100/2712] Data 0.000 (0.003) Elapsed 31m 42s (remain 9m 13s) Loss: 0.0015(0.6094) Grad: 288.3087  LR: 0.0000995  \n",
      "Epoch: [2][2200/2712] Data 0.000 (0.003) Elapsed 33m 10s (remain 7m 42s) Loss: 0.0046(0.6170) Grad: 784.9165  LR: 0.0000995  \n",
      "Epoch: [2][2300/2712] Data 0.000 (0.003) Elapsed 34m 46s (remain 6m 12s) Loss: 1.5531(0.6136) Grad: 49460.7578  LR: 0.0000995  \n",
      "Epoch: [2][2400/2712] Data 0.000 (0.002) Elapsed 36m 10s (remain 4m 41s) Loss: 1.6033(0.6127) Grad: 50183.0078  LR: 0.0000995  \n",
      "Epoch: [2][2500/2712] Data 0.000 (0.002) Elapsed 37m 39s (remain 3m 10s) Loss: 1.1373(0.6182) Grad: 39317.5156  LR: 0.0000995  \n",
      "Epoch: [2][2600/2712] Data 0.000 (0.002) Elapsed 39m 10s (remain 1m 40s) Loss: 0.0021(0.6168) Grad: 396.6154  LR: 0.0000995  \n",
      "Epoch: [2][2700/2712] Data 0.000 (0.002) Elapsed 40m 33s (remain 0m 9s) Loss: 0.0020(0.6166) Grad: 385.3184  LR: 0.0000995  \n",
      "Epoch: [2][2711/2712] Data 0.000 (0.002) Elapsed 40m 42s (remain 0m 0s) Loss: 0.0020(0.6162) Grad: 380.9864  LR: 0.0000995  \n",
      "EVAL: [0/339] Data 10.998 (10.998) Elapsed 0m 12s (remain 68m 15s) Loss: 2.3120(2.3120) \n",
      "EVAL: [100/339] Data 0.000 (0.111) Elapsed 2m 1s (remain 4m 46s) Loss: 1.5773(0.6085) \n",
      "EVAL: [200/339] Data 0.000 (0.056) Elapsed 3m 59s (remain 2m 44s) Loss: 0.0015(0.6573) \n",
      "EVAL: [300/339] Data 0.000 (0.039) Elapsed 5m 50s (remain 0m 44s) Loss: 0.0026(0.6517) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.6162  avg_val_loss: 0.6561  time: 2834s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.035) Elapsed 6m 30s (remain 0m 0s) Loss: 0.0026(0.6561) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 3 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:9.816440572371606e-05\n",
      "scheduler_last_epoch:2, scheduler_lr:9.816440572371606e-05\n",
      "optimizer_lr:9.816440572371606e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/2712] Data 5.334 (5.334) Elapsed 0m 6s (remain 281m 48s) Loss: 0.0017(0.0017) Grad: 2695.4114  LR: 0.0000982  \n",
      "Epoch: [3][100/2712] Data 0.000 (0.053) Elapsed 1m 29s (remain 38m 40s) Loss: 0.0014(0.7823) Grad: 546.2412  LR: 0.0000982  \n",
      "Epoch: [3][200/2712] Data 0.000 (0.027) Elapsed 2m 58s (remain 37m 14s) Loss: 0.0013(0.7194) Grad: 516.4739  LR: 0.0000982  \n",
      "Epoch: [3][300/2712] Data 0.000 (0.018) Elapsed 4m 23s (remain 35m 8s) Loss: 0.0021(0.7114) Grad: 783.5538  LR: 0.0000982  \n",
      "Epoch: [3][400/2712] Data 0.003 (0.014) Elapsed 5m 50s (remain 33m 40s) Loss: 0.0007(0.6757) Grad: 304.9323  LR: 0.0000982  \n",
      "Epoch: [3][500/2712] Data 0.000 (0.011) Elapsed 7m 22s (remain 32m 34s) Loss: 0.0013(0.6752) Grad: 496.9733  LR: 0.0000982  \n",
      "Epoch: [3][600/2712] Data 0.000 (0.009) Elapsed 8m 46s (remain 30m 48s) Loss: 0.0023(0.6554) Grad: 408.0723  LR: 0.0000982  \n",
      "Epoch: [3][700/2712] Data 0.000 (0.008) Elapsed 10m 10s (remain 29m 10s) Loss: 1.5860(0.6480) Grad: 49812.3438  LR: 0.0000982  \n",
      "Epoch: [3][800/2712] Data 0.000 (0.007) Elapsed 11m 35s (remain 27m 39s) Loss: 0.0011(0.6413) Grad: 230.1390  LR: 0.0000982  \n",
      "Epoch: [3][900/2712] Data 0.000 (0.006) Elapsed 13m 11s (remain 26m 31s) Loss: 0.0029(0.6382) Grad: 562.6656  LR: 0.0000982  \n",
      "Epoch: [3][1000/2712] Data 0.000 (0.006) Elapsed 14m 39s (remain 25m 3s) Loss: 2.7735(0.6514) Grad: 89423.6641  LR: 0.0000982  \n",
      "Epoch: [3][1100/2712] Data 0.000 (0.005) Elapsed 16m 12s (remain 23m 43s) Loss: 3.0355(0.6454) Grad: 94757.7031  LR: 0.0000982  \n",
      "Epoch: [3][1200/2712] Data 0.000 (0.005) Elapsed 17m 41s (remain 22m 14s) Loss: 1.6561(0.6331) Grad: 53758.8789  LR: 0.0000982  \n",
      "Epoch: [3][1300/2712] Data 0.000 (0.005) Elapsed 19m 17s (remain 20m 55s) Loss: 0.0013(0.6215) Grad: 263.9555  LR: 0.0000982  \n",
      "Epoch: [3][1400/2712] Data 0.000 (0.004) Elapsed 20m 41s (remain 19m 21s) Loss: 1.1830(0.6202) Grad: 41189.2852  LR: 0.0000982  \n",
      "Epoch: [3][1500/2712] Data 0.000 (0.004) Elapsed 22m 11s (remain 17m 54s) Loss: 0.0020(0.6172) Grad: 403.0578  LR: 0.0000982  \n",
      "Epoch: [3][1600/2712] Data 0.000 (0.004) Elapsed 23m 35s (remain 16m 21s) Loss: 0.0075(0.6249) Grad: 1204.9189  LR: 0.0000982  \n",
      "Epoch: [3][1700/2712] Data 0.000 (0.004) Elapsed 25m 0s (remain 14m 51s) Loss: 0.0023(0.6193) Grad: 425.5620  LR: 0.0000982  \n",
      "Epoch: [3][1800/2712] Data 0.000 (0.003) Elapsed 26m 34s (remain 13m 26s) Loss: 4.1408(0.6260) Grad: 135518.9531  LR: 0.0000982  \n",
      "Epoch: [3][1900/2712] Data 0.000 (0.003) Elapsed 27m 59s (remain 11m 56s) Loss: 0.0027(0.6261) Grad: 499.4124  LR: 0.0000982  \n",
      "Epoch: [3][2000/2712] Data 0.001 (0.003) Elapsed 29m 25s (remain 10m 27s) Loss: 0.0037(0.6281) Grad: 653.3227  LR: 0.0000982  \n",
      "Epoch: [3][2100/2712] Data 0.000 (0.003) Elapsed 30m 49s (remain 8m 57s) Loss: 0.0010(0.6184) Grad: 206.5948  LR: 0.0000982  \n",
      "Epoch: [3][2200/2712] Data 0.000 (0.003) Elapsed 32m 15s (remain 7m 29s) Loss: 0.0026(0.6116) Grad: 478.4808  LR: 0.0000982  \n",
      "Epoch: [3][2300/2712] Data 0.000 (0.003) Elapsed 33m 42s (remain 6m 1s) Loss: 0.0029(0.6143) Grad: 523.6652  LR: 0.0000982  \n",
      "Epoch: [3][2400/2712] Data 0.000 (0.003) Elapsed 35m 14s (remain 4m 33s) Loss: 0.0006(0.6080) Grad: 130.2323  LR: 0.0000982  \n",
      "Epoch: [3][2500/2712] Data 0.000 (0.003) Elapsed 36m 42s (remain 3m 5s) Loss: 1.7414(0.6055) Grad: 56999.1836  LR: 0.0000982  \n",
      "Epoch: [3][2600/2712] Data 0.000 (0.002) Elapsed 38m 12s (remain 1m 37s) Loss: 0.0025(0.6069) Grad: 958.0829  LR: 0.0000982  \n",
      "Epoch: [3][2700/2712] Data 0.000 (0.002) Elapsed 39m 41s (remain 0m 9s) Loss: 0.0018(0.6089) Grad: 699.7706  LR: 0.0000982  \n",
      "Epoch: [3][2711/2712] Data 0.000 (0.002) Elapsed 39m 50s (remain 0m 0s) Loss: 0.0018(0.6093) Grad: 717.0948  LR: 0.0000982  \n",
      "EVAL: [0/339] Data 9.789 (9.789) Elapsed 0m 11s (remain 62m 7s) Loss: 2.1400(2.1400) \n",
      "EVAL: [100/339] Data 0.001 (0.097) Elapsed 2m 12s (remain 5m 11s) Loss: 1.7040(0.6088) \n",
      "EVAL: [200/339] Data 0.000 (0.050) Elapsed 4m 16s (remain 2m 55s) Loss: 0.0017(0.6546) \n",
      "EVAL: [300/339] Data 0.000 (0.034) Elapsed 6m 17s (remain 0m 47s) Loss: 0.0028(0.6454) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.6093  avg_val_loss: 0.6482  time: 2810s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.030) Elapsed 6m 58s (remain 0m 0s) Loss: 0.0032(0.6482) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 4 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:9.590195942451992e-05\n",
      "scheduler_last_epoch:3, scheduler_lr:9.590195942451992e-05\n",
      "optimizer_lr:9.590195942451992e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/2712] Data 6.348 (6.348) Elapsed 0m 7s (remain 328m 57s) Loss: 0.0027(0.0027) Grad: 3991.7380  LR: 0.0000959  \n",
      "Epoch: [4][100/2712] Data 0.000 (0.063) Elapsed 1m 30s (remain 39m 2s) Loss: 1.7613(0.7640) Grad: 112354.5547  LR: 0.0000959  \n",
      "Epoch: [4][200/2712] Data 0.000 (0.032) Elapsed 2m 54s (remain 36m 19s) Loss: 1.2983(0.7483) Grad: 44874.1133  LR: 0.0000959  \n",
      "Epoch: [4][300/2712] Data 0.001 (0.021) Elapsed 4m 21s (remain 34m 52s) Loss: 0.0039(0.7072) Grad: 706.7645  LR: 0.0000959  \n",
      "Epoch: [4][400/2712] Data 0.000 (0.016) Elapsed 5m 53s (remain 33m 58s) Loss: 0.0028(0.7180) Grad: 530.8735  LR: 0.0000959  \n",
      "Epoch: [4][500/2712] Data 0.000 (0.013) Elapsed 7m 28s (remain 33m 0s) Loss: 1.4613(0.6988) Grad: 47154.8594  LR: 0.0000959  \n",
      "Epoch: [4][600/2712] Data 0.000 (0.011) Elapsed 8m 57s (remain 31m 27s) Loss: 0.0035(0.6901) Grad: 635.4487  LR: 0.0000959  \n",
      "Epoch: [4][700/2712] Data 0.000 (0.009) Elapsed 10m 26s (remain 29m 56s) Loss: 2.7936(0.6741) Grad: 92029.1250  LR: 0.0000959  \n",
      "Epoch: [4][800/2712] Data 0.000 (0.008) Elapsed 11m 59s (remain 28m 37s) Loss: 0.0029(0.6602) Grad: 559.0613  LR: 0.0000959  \n",
      "Epoch: [4][900/2712] Data 0.000 (0.007) Elapsed 13m 28s (remain 27m 4s) Loss: 1.7021(0.6443) Grad: 56029.4023  LR: 0.0000959  \n",
      "Epoch: [4][1000/2712] Data 0.000 (0.007) Elapsed 15m 4s (remain 25m 45s) Loss: 1.7546(0.6526) Grad: 57017.0625  LR: 0.0000959  \n",
      "Epoch: [4][1100/2712] Data 0.000 (0.006) Elapsed 16m 33s (remain 24m 13s) Loss: 0.0019(0.6369) Grad: 375.7358  LR: 0.0000959  \n",
      "Epoch: [4][1200/2712] Data 0.000 (0.006) Elapsed 18m 2s (remain 22m 41s) Loss: 0.0023(0.6340) Grad: 443.3994  LR: 0.0000959  \n",
      "Epoch: [4][1300/2712] Data 0.004 (0.005) Elapsed 19m 34s (remain 21m 13s) Loss: 1.6071(0.6312) Grad: 54012.9961  LR: 0.0000959  \n",
      "Epoch: [4][1400/2712] Data 0.000 (0.005) Elapsed 21m 3s (remain 19m 42s) Loss: 1.4119(0.6446) Grad: 50644.9766  LR: 0.0000959  \n",
      "Epoch: [4][1500/2712] Data 0.000 (0.005) Elapsed 22m 32s (remain 18m 11s) Loss: 1.8164(0.6323) Grad: 56950.9727  LR: 0.0000959  \n",
      "Epoch: [4][1600/2712] Data 0.000 (0.004) Elapsed 24m 0s (remain 16m 39s) Loss: 0.0016(0.6274) Grad: 330.8407  LR: 0.0000959  \n",
      "Epoch: [4][1700/2712] Data 0.000 (0.004) Elapsed 25m 32s (remain 15m 10s) Loss: 0.0024(0.6218) Grad: 472.2368  LR: 0.0000959  \n",
      "Epoch: [4][1800/2712] Data 0.000 (0.004) Elapsed 27m 1s (remain 13m 40s) Loss: 0.0027(0.6210) Grad: 524.1478  LR: 0.0000959  \n",
      "Epoch: [4][1900/2712] Data 0.000 (0.004) Elapsed 28m 34s (remain 12m 11s) Loss: 0.0015(0.6170) Grad: 307.5036  LR: 0.0000959  \n",
      "Epoch: [4][2000/2712] Data 0.000 (0.004) Elapsed 30m 2s (remain 10m 40s) Loss: 0.0024(0.6158) Grad: 464.1641  LR: 0.0000959  \n",
      "Epoch: [4][2100/2712] Data 0.000 (0.003) Elapsed 31m 34s (remain 9m 11s) Loss: 0.0017(0.6170) Grad: 340.7394  LR: 0.0000959  \n",
      "Epoch: [4][2200/2712] Data 0.000 (0.003) Elapsed 33m 8s (remain 7m 41s) Loss: 0.0009(0.6115) Grad: 396.3882  LR: 0.0000959  \n",
      "Epoch: [4][2300/2712] Data 0.000 (0.003) Elapsed 34m 36s (remain 6m 10s) Loss: 0.0007(0.6117) Grad: 312.3754  LR: 0.0000959  \n",
      "Epoch: [4][2400/2712] Data 0.000 (0.003) Elapsed 36m 11s (remain 4m 41s) Loss: 0.0020(0.6103) Grad: 406.1198  LR: 0.0000959  \n",
      "Epoch: [4][2500/2712] Data 0.000 (0.003) Elapsed 37m 39s (remain 3m 10s) Loss: 1.6677(0.6069) Grad: 56172.8594  LR: 0.0000959  \n",
      "Epoch: [4][2600/2712] Data 0.000 (0.003) Elapsed 39m 14s (remain 1m 40s) Loss: 1.5165(0.6113) Grad: 51914.9805  LR: 0.0000959  \n",
      "Epoch: [4][2700/2712] Data 0.000 (0.003) Elapsed 40m 42s (remain 0m 9s) Loss: 0.0021(0.6087) Grad: 417.1115  LR: 0.0000959  \n",
      "Epoch: [4][2711/2712] Data 0.000 (0.003) Elapsed 40m 51s (remain 0m 0s) Loss: 1.4248(0.6091) Grad: 48988.8906  LR: 0.0000959  \n",
      "EVAL: [0/339] Data 8.674 (8.674) Elapsed 0m 13s (remain 76m 3s) Loss: 2.0499(2.0499) \n",
      "EVAL: [100/339] Data 0.000 (0.096) Elapsed 2m 17s (remain 5m 23s) Loss: 1.3298(0.5698) \n",
      "EVAL: [200/339] Data 0.000 (0.049) Elapsed 4m 20s (remain 2m 58s) Loss: 0.0019(0.6145) \n",
      "EVAL: [300/339] Data 0.000 (0.033) Elapsed 6m 22s (remain 0m 48s) Loss: 0.0030(0.6100) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.6091  avg_val_loss: 0.6138  time: 2880s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.029) Elapsed 7m 8s (remain 0m 0s) Loss: 0.0032(0.6138) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 5 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:9.279376052505117e-05\n",
      "scheduler_last_epoch:4, scheduler_lr:9.279376052505117e-05\n",
      "optimizer_lr:9.279376052505117e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/2712] Data 5.234 (5.234) Elapsed 0m 6s (remain 280m 29s) Loss: 0.0035(0.0035) Grad: 5107.8882  LR: 0.0000928  \n",
      "Epoch: [5][100/2712] Data 0.000 (0.052) Elapsed 1m 34s (remain 40m 38s) Loss: 0.0012(0.6301) Grad: 527.2274  LR: 0.0000928  \n",
      "Epoch: [5][200/2712] Data 0.000 (0.026) Elapsed 3m 3s (remain 38m 8s) Loss: 0.0036(0.6670) Grad: 686.1704  LR: 0.0000928  \n",
      "Epoch: [5][300/2712] Data 0.000 (0.018) Elapsed 4m 32s (remain 36m 19s) Loss: 1.4865(0.6259) Grad: 54357.7930  LR: 0.0000928  \n",
      "Epoch: [5][400/2712] Data 0.000 (0.013) Elapsed 6m 4s (remain 34m 58s) Loss: 0.0042(0.6449) Grad: 759.5908  LR: 0.0000928  \n",
      "Epoch: [5][500/2712] Data 0.000 (0.011) Elapsed 7m 33s (remain 33m 20s) Loss: 0.0014(0.6024) Grad: 296.0289  LR: 0.0000928  \n",
      "Epoch: [5][600/2712] Data 0.000 (0.009) Elapsed 9m 10s (remain 32m 14s) Loss: 0.0011(0.5950) Grad: 246.0741  LR: 0.0000928  \n",
      "Epoch: [5][700/2712] Data 0.000 (0.008) Elapsed 10m 39s (remain 30m 33s) Loss: 0.0019(0.6043) Grad: 407.3957  LR: 0.0000928  \n",
      "Epoch: [5][800/2712] Data 0.000 (0.007) Elapsed 12m 14s (remain 29m 13s) Loss: 0.0012(0.5840) Grad: 261.8177  LR: 0.0000928  \n",
      "Epoch: [5][900/2712] Data 0.000 (0.006) Elapsed 13m 42s (remain 27m 34s) Loss: 0.0015(0.5840) Grad: 329.2873  LR: 0.0000928  \n",
      "Epoch: [5][1000/2712] Data 0.000 (0.006) Elapsed 15m 13s (remain 26m 1s) Loss: 0.0026(0.5850) Grad: 499.9104  LR: 0.0000928  \n",
      "Epoch: [5][1100/2712] Data 0.000 (0.005) Elapsed 16m 47s (remain 24m 34s) Loss: 0.0035(0.6039) Grad: 688.1509  LR: 0.0000928  \n",
      "Epoch: [5][1200/2712] Data 0.000 (0.005) Elapsed 18m 15s (remain 22m 58s) Loss: 1.6171(0.6011) Grad: 57371.4297  LR: 0.0000928  \n",
      "Epoch: [5][1300/2712] Data 0.000 (0.004) Elapsed 19m 42s (remain 21m 22s) Loss: 3.2931(0.5907) Grad: 109697.6875  LR: 0.0000928  \n",
      "Epoch: [5][1400/2712] Data 0.000 (0.004) Elapsed 21m 5s (remain 19m 44s) Loss: 0.0027(0.5978) Grad: 524.6635  LR: 0.0000928  \n",
      "Epoch: [5][1500/2712] Data 0.000 (0.004) Elapsed 22m 37s (remain 18m 15s) Loss: 0.0014(0.5962) Grad: 315.1691  LR: 0.0000928  \n",
      "Epoch: [5][1600/2712] Data 0.000 (0.004) Elapsed 24m 3s (remain 16m 41s) Loss: 0.0017(0.5887) Grad: 363.6523  LR: 0.0000928  \n",
      "Epoch: [5][1700/2712] Data 0.000 (0.004) Elapsed 25m 37s (remain 15m 14s) Loss: 0.0011(0.5837) Grad: 248.2376  LR: 0.0000928  \n",
      "Epoch: [5][1800/2712] Data 0.000 (0.003) Elapsed 27m 6s (remain 13m 42s) Loss: 3.2520(0.5806) Grad: 107097.8359  LR: 0.0000928  \n",
      "Epoch: [5][1900/2712] Data 0.000 (0.003) Elapsed 28m 39s (remain 12m 13s) Loss: 0.0032(0.5850) Grad: 594.3716  LR: 0.0000928  \n",
      "Epoch: [5][2000/2712] Data 0.000 (0.003) Elapsed 30m 11s (remain 10m 43s) Loss: 1.3330(0.5894) Grad: 46731.8086  LR: 0.0000928  \n",
      "Epoch: [5][2100/2712] Data 0.004 (0.003) Elapsed 31m 40s (remain 9m 12s) Loss: 0.0071(0.5972) Grad: 1289.2806  LR: 0.0000928  \n",
      "Epoch: [5][2200/2712] Data 0.000 (0.003) Elapsed 33m 12s (remain 7m 42s) Loss: 0.0013(0.5976) Grad: 565.3002  LR: 0.0000928  \n",
      "Epoch: [5][2300/2712] Data 0.000 (0.003) Elapsed 34m 44s (remain 6m 12s) Loss: 0.0008(0.5935) Grad: 381.1703  LR: 0.0000928  \n",
      "Epoch: [5][2400/2712] Data 0.000 (0.003) Elapsed 36m 12s (remain 4m 41s) Loss: 0.0012(0.5998) Grad: 534.7849  LR: 0.0000928  \n",
      "Epoch: [5][2500/2712] Data 0.000 (0.003) Elapsed 37m 49s (remain 3m 11s) Loss: 0.0019(0.6031) Grad: 787.4651  LR: 0.0000928  \n",
      "Epoch: [5][2600/2712] Data 0.000 (0.002) Elapsed 39m 23s (remain 1m 40s) Loss: 1.5402(0.6066) Grad: 110391.8047  LR: 0.0000928  \n",
      "Epoch: [5][2700/2712] Data 0.000 (0.002) Elapsed 40m 51s (remain 0m 9s) Loss: 0.0013(0.6123) Grad: 573.8106  LR: 0.0000928  \n",
      "Epoch: [5][2711/2712] Data 0.000 (0.002) Elapsed 41m 1s (remain 0m 0s) Loss: 1.3650(0.6122) Grad: 99472.0078  LR: 0.0000928  \n",
      "EVAL: [0/339] Data 9.055 (9.055) Elapsed 0m 10s (remain 57m 56s) Loss: 2.2760(2.2760) \n",
      "EVAL: [100/339] Data 0.000 (0.091) Elapsed 2m 12s (remain 5m 13s) Loss: 1.4863(0.6351) \n",
      "EVAL: [200/339] Data 0.000 (0.046) Elapsed 4m 7s (remain 2m 49s) Loss: 0.0012(0.6884) \n",
      "EVAL: [300/339] Data 0.000 (0.031) Elapsed 5m 54s (remain 0m 44s) Loss: 0.0020(0.6819) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.6122  avg_val_loss: 0.6854  time: 2856s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.028) Elapsed 6m 34s (remain 0m 0s) Loss: 0.0023(0.6854) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 6 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:8.889770888986878e-05\n",
      "scheduler_last_epoch:5, scheduler_lr:8.889770888986878e-05\n",
      "optimizer_lr:8.889770888986878e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/2712] Data 6.106 (6.106) Elapsed 0m 7s (remain 316m 56s) Loss: 1.9379(1.9379) Grad: inf  LR: 0.0000889  \n",
      "Epoch: [6][100/2712] Data 0.000 (0.061) Elapsed 1m 30s (remain 38m 53s) Loss: 0.0013(0.6771) Grad: 568.0807  LR: 0.0000889  \n",
      "Epoch: [6][200/2712] Data 0.001 (0.031) Elapsed 2m 54s (remain 36m 14s) Loss: 0.0021(0.7136) Grad: 419.6077  LR: 0.0000889  \n",
      "Epoch: [6][300/2712] Data 0.000 (0.021) Elapsed 4m 23s (remain 35m 11s) Loss: 0.0043(0.6574) Grad: 819.7164  LR: 0.0000889  \n",
      "Epoch: [6][400/2712] Data 0.000 (0.016) Elapsed 5m 50s (remain 33m 39s) Loss: 3.3744(0.6332) Grad: 114526.8281  LR: 0.0000889  \n",
      "Epoch: [6][500/2712] Data 0.000 (0.013) Elapsed 7m 19s (remain 32m 18s) Loss: 0.0017(0.6224) Grad: 365.0926  LR: 0.0000889  \n",
      "Epoch: [6][600/2712] Data 0.000 (0.011) Elapsed 8m 53s (remain 31m 14s) Loss: 0.0018(0.6227) Grad: 386.4292  LR: 0.0000889  \n",
      "Epoch: [6][700/2712] Data 0.000 (0.009) Elapsed 10m 21s (remain 29m 43s) Loss: 0.0021(0.6208) Grad: 441.9611  LR: 0.0000889  \n",
      "Epoch: [6][800/2712] Data 0.000 (0.008) Elapsed 11m 53s (remain 28m 21s) Loss: 0.0016(0.6224) Grad: 341.3070  LR: 0.0000889  \n",
      "Epoch: [6][900/2712] Data 0.000 (0.007) Elapsed 13m 21s (remain 26m 50s) Loss: 0.0020(0.6199) Grad: 414.5462  LR: 0.0000889  \n",
      "Epoch: [6][1000/2712] Data 0.003 (0.006) Elapsed 14m 53s (remain 25m 26s) Loss: 0.0034(0.6256) Grad: 691.3559  LR: 0.0000889  \n",
      "Epoch: [6][1100/2712] Data 0.000 (0.006) Elapsed 16m 23s (remain 23m 58s) Loss: 0.0045(0.6268) Grad: 857.9359  LR: 0.0000889  \n",
      "Epoch: [6][1200/2712] Data 0.000 (0.005) Elapsed 17m 51s (remain 22m 27s) Loss: 0.0029(0.6223) Grad: 560.3257  LR: 0.0000889  \n",
      "Epoch: [6][1300/2712] Data 0.000 (0.005) Elapsed 19m 26s (remain 21m 5s) Loss: 2.9610(0.6169) Grad: 102728.6016  LR: 0.0000889  \n",
      "Epoch: [6][1400/2712] Data 0.000 (0.005) Elapsed 20m 52s (remain 19m 32s) Loss: 1.6656(0.6101) Grad: 58938.6094  LR: 0.0000889  \n",
      "Epoch: [6][1500/2712] Data 0.003 (0.004) Elapsed 22m 18s (remain 18m 0s) Loss: 3.3997(0.6138) Grad: 117605.3359  LR: 0.0000889  \n",
      "Epoch: [6][1600/2712] Data 0.000 (0.004) Elapsed 23m 42s (remain 16m 27s) Loss: 1.3610(0.6170) Grad: 50040.1484  LR: 0.0000889  \n",
      "Epoch: [6][1700/2712] Data 0.000 (0.004) Elapsed 25m 7s (remain 14m 56s) Loss: 0.0031(0.6191) Grad: 604.2898  LR: 0.0000889  \n",
      "Epoch: [6][1800/2712] Data 0.000 (0.004) Elapsed 26m 34s (remain 13m 26s) Loss: 1.6081(0.6176) Grad: 56170.6758  LR: 0.0000889  \n",
      "Epoch: [6][1900/2712] Data 0.000 (0.004) Elapsed 28m 2s (remain 11m 57s) Loss: 0.0031(0.6221) Grad: 605.4421  LR: 0.0000889  \n",
      "Epoch: [6][2000/2712] Data 0.000 (0.003) Elapsed 29m 37s (remain 10m 31s) Loss: 0.0018(0.6184) Grad: 391.2039  LR: 0.0000889  \n",
      "Epoch: [6][2100/2712] Data 0.000 (0.003) Elapsed 31m 5s (remain 9m 2s) Loss: 0.0011(0.6105) Grad: 248.8866  LR: 0.0000889  \n",
      "Epoch: [6][2200/2712] Data 0.000 (0.003) Elapsed 32m 34s (remain 7m 33s) Loss: 1.2984(0.6092) Grad: 93005.4453  LR: 0.0000889  \n",
      "Epoch: [6][2300/2712] Data 0.000 (0.003) Elapsed 34m 6s (remain 6m 5s) Loss: 1.7221(0.6169) Grad: 116915.8906  LR: 0.0000889  \n",
      "Epoch: [6][2400/2712] Data 0.000 (0.003) Elapsed 35m 36s (remain 4m 36s) Loss: 3.4028(0.6228) Grad: 233856.3906  LR: 0.0000889  \n",
      "Epoch: [6][2500/2712] Data 0.000 (0.003) Elapsed 37m 5s (remain 3m 7s) Loss: 1.6672(0.6193) Grad: 120023.0234  LR: 0.0000889  \n",
      "Epoch: [6][2600/2712] Data 0.000 (0.003) Elapsed 38m 35s (remain 1m 38s) Loss: 0.0006(0.6196) Grad: 288.4158  LR: 0.0000889  \n",
      "Epoch: [6][2700/2712] Data 0.000 (0.003) Elapsed 40m 8s (remain 0m 9s) Loss: 1.5596(0.6218) Grad: 54460.7773  LR: 0.0000889  \n",
      "Epoch: [6][2711/2712] Data 0.000 (0.003) Elapsed 40m 18s (remain 0m 0s) Loss: 0.0014(0.6209) Grad: 324.8110  LR: 0.0000889  \n",
      "EVAL: [0/339] Data 16.696 (16.696) Elapsed 0m 17s (remain 101m 5s) Loss: 2.1171(2.1171) \n",
      "EVAL: [100/339] Data 0.000 (0.166) Elapsed 2m 20s (remain 5m 31s) Loss: 1.4558(0.5905) \n",
      "EVAL: [200/339] Data 0.000 (0.084) Elapsed 4m 23s (remain 3m 0s) Loss: 0.0017(0.6370) \n",
      "EVAL: [300/339] Data 0.001 (0.056) Elapsed 6m 25s (remain 0m 48s) Loss: 0.0025(0.6303) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.6209  avg_val_loss: 0.6332  time: 2851s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.050) Elapsed 7m 12s (remain 0m 0s) Loss: 0.0034(0.6332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 7 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:8.428638058932337e-05\n",
      "scheduler_last_epoch:6, scheduler_lr:8.428638058932337e-05\n",
      "optimizer_lr:8.428638058932337e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/2712] Data 4.671 (4.671) Elapsed 0m 5s (remain 253m 37s) Loss: 0.0018(0.0018) Grad: 3064.9773  LR: 0.0000843  \n",
      "Epoch: [7][100/2712] Data 0.000 (0.047) Elapsed 1m 34s (remain 40m 37s) Loss: 0.0009(0.6666) Grad: 436.1357  LR: 0.0000843  \n",
      "Epoch: [7][200/2712] Data 0.000 (0.024) Elapsed 3m 2s (remain 38m 0s) Loss: 1.8154(0.6833) Grad: 127537.1641  LR: 0.0000843  \n",
      "Epoch: [7][300/2712] Data 0.000 (0.016) Elapsed 4m 39s (remain 37m 17s) Loss: 0.0009(0.6377) Grad: 409.5872  LR: 0.0000843  \n",
      "Epoch: [7][400/2712] Data 0.000 (0.012) Elapsed 6m 7s (remain 35m 17s) Loss: 0.0010(0.6478) Grad: 236.0156  LR: 0.0000843  \n",
      "Epoch: [7][500/2712] Data 0.000 (0.010) Elapsed 7m 41s (remain 33m 56s) Loss: 0.0020(0.6413) Grad: 427.3482  LR: 0.0000843  \n",
      "Epoch: [7][600/2712] Data 0.000 (0.008) Elapsed 9m 9s (remain 32m 11s) Loss: 0.0031(0.6362) Grad: 592.2186  LR: 0.0000843  \n",
      "Epoch: [7][700/2712] Data 0.000 (0.007) Elapsed 10m 38s (remain 30m 32s) Loss: 0.0039(0.6397) Grad: 767.4644  LR: 0.0000843  \n",
      "Epoch: [7][800/2712] Data 0.000 (0.006) Elapsed 12m 13s (remain 29m 9s) Loss: 1.6556(0.6371) Grad: 59770.7734  LR: 0.0000843  \n",
      "Epoch: [7][900/2712] Data 0.001 (0.006) Elapsed 13m 43s (remain 27m 35s) Loss: 0.0032(0.6266) Grad: 324.0027  LR: 0.0000843  \n",
      "Epoch: [7][1000/2712] Data 0.000 (0.005) Elapsed 15m 16s (remain 26m 7s) Loss: 1.2113(0.6288) Grad: 25036.8887  LR: 0.0000843  \n",
      "Epoch: [7][1100/2712] Data 0.000 (0.005) Elapsed 16m 47s (remain 24m 34s) Loss: 0.0040(0.6148) Grad: 406.7738  LR: 0.0000843  \n",
      "Epoch: [7][1200/2712] Data 0.000 (0.004) Elapsed 18m 11s (remain 22m 52s) Loss: 0.0052(0.6047) Grad: 507.5420  LR: 0.0000843  \n",
      "Epoch: [7][1300/2712] Data 0.000 (0.004) Elapsed 19m 39s (remain 21m 19s) Loss: 0.0023(0.5919) Grad: 233.2480  LR: 0.0000843  \n",
      "Epoch: [7][1400/2712] Data 0.000 (0.004) Elapsed 21m 10s (remain 19m 48s) Loss: 0.0057(0.5845) Grad: 536.5591  LR: 0.0000843  \n",
      "Epoch: [7][1500/2712] Data 0.001 (0.004) Elapsed 22m 34s (remain 18m 12s) Loss: 1.3400(0.5796) Grad: 26337.5684  LR: 0.0000843  \n",
      "Epoch: [7][1600/2712] Data 0.000 (0.003) Elapsed 24m 3s (remain 16m 41s) Loss: 1.3249(0.5700) Grad: 23688.8047  LR: 0.0000843  \n",
      "Epoch: [7][1700/2712] Data 0.000 (0.003) Elapsed 25m 28s (remain 15m 8s) Loss: 1.0648(0.5703) Grad: 20292.5742  LR: 0.0000843  \n",
      "Epoch: [7][1800/2712] Data 0.000 (0.003) Elapsed 26m 55s (remain 13m 37s) Loss: 0.0026(0.5663) Grad: 282.2306  LR: 0.0000843  \n",
      "Epoch: [7][1900/2712] Data 0.000 (0.003) Elapsed 28m 19s (remain 12m 5s) Loss: 0.0075(0.5695) Grad: 664.5303  LR: 0.0000843  \n",
      "Epoch: [7][2000/2712] Data 0.000 (0.003) Elapsed 29m 45s (remain 10m 34s) Loss: 0.0037(0.5689) Grad: 378.8252  LR: 0.0000843  \n",
      "Epoch: [7][2100/2712] Data 0.003 (0.003) Elapsed 31m 14s (remain 9m 5s) Loss: 1.1924(0.5662) Grad: 22384.1367  LR: 0.0000843  \n",
      "Epoch: [7][2200/2712] Data 0.000 (0.003) Elapsed 32m 48s (remain 7m 36s) Loss: 1.5934(0.5616) Grad: 28789.8828  LR: 0.0000843  \n",
      "Epoch: [7][2300/2712] Data 0.000 (0.002) Elapsed 34m 16s (remain 6m 7s) Loss: 1.4980(0.5608) Grad: 27713.9141  LR: 0.0000843  \n",
      "Epoch: [7][2400/2712] Data 0.000 (0.002) Elapsed 35m 49s (remain 4m 38s) Loss: 1.0855(0.5601) Grad: 21170.8223  LR: 0.0000843  \n",
      "Epoch: [7][2500/2712] Data 0.000 (0.002) Elapsed 37m 17s (remain 3m 8s) Loss: 0.0094(0.5620) Grad: 843.8195  LR: 0.0000843  \n",
      "Epoch: [7][2600/2712] Data 0.000 (0.002) Elapsed 38m 52s (remain 1m 39s) Loss: 1.2876(0.5544) Grad: 25526.3027  LR: 0.0000843  \n",
      "Epoch: [7][2700/2712] Data 0.000 (0.002) Elapsed 40m 20s (remain 0m 9s) Loss: 0.0053(0.5572) Grad: 507.7383  LR: 0.0000843  \n",
      "Epoch: [7][2711/2712] Data 0.000 (0.002) Elapsed 40m 29s (remain 0m 0s) Loss: 0.0040(0.5575) Grad: 420.1928  LR: 0.0000843  \n",
      "EVAL: [0/339] Data 10.143 (10.143) Elapsed 0m 11s (remain 64m 11s) Loss: 1.7123(1.7123) \n",
      "EVAL: [100/339] Data 0.000 (0.101) Elapsed 2m 14s (remain 5m 15s) Loss: 1.2674(0.4856) \n",
      "EVAL: [200/339] Data 0.000 (0.057) Elapsed 4m 8s (remain 2m 50s) Loss: 0.0056(0.5235) \n",
      "EVAL: [300/339] Data 0.000 (0.038) Elapsed 5m 55s (remain 0m 44s) Loss: 0.0130(0.5164) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.5575  avg_val_loss: 0.5184  time: 2827s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.034) Elapsed 6m 36s (remain 0m 0s) Loss: 0.0122(0.5184) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 8 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:7.904567594468593e-05\n",
      "scheduler_last_epoch:7, scheduler_lr:7.904567594468593e-05\n",
      "optimizer_lr:7.904567594468593e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/2712] Data 5.662 (5.662) Elapsed 0m 6s (remain 296m 19s) Loss: 3.0041(3.0041) Grad: inf  LR: 0.0000790  \n",
      "Epoch: [8][100/2712] Data 0.000 (0.056) Elapsed 1m 31s (remain 39m 31s) Loss: 1.6212(0.6081) Grad: 114909.3047  LR: 0.0000790  \n",
      "Epoch: [8][200/2712] Data 0.000 (0.028) Elapsed 2m 58s (remain 37m 15s) Loss: 0.0011(0.6411) Grad: 511.6925  LR: 0.0000790  \n",
      "Epoch: [8][300/2712] Data 0.000 (0.019) Elapsed 4m 27s (remain 35m 45s) Loss: 1.3211(0.6553) Grad: 97393.2891  LR: 0.0000790  \n",
      "Epoch: [8][400/2712] Data 0.000 (0.014) Elapsed 6m 0s (remain 34m 35s) Loss: 0.0008(0.6075) Grad: 394.3598  LR: 0.0000790  \n",
      "Epoch: [8][500/2712] Data 0.001 (0.012) Elapsed 7m 32s (remain 33m 15s) Loss: 0.0011(0.6102) Grad: 247.7598  LR: 0.0000790  \n",
      "Epoch: [8][600/2712] Data 0.000 (0.010) Elapsed 8m 58s (remain 31m 32s) Loss: 0.0021(0.6047) Grad: 456.4678  LR: 0.0000790  \n",
      "Epoch: [8][700/2712] Data 0.000 (0.008) Elapsed 10m 23s (remain 29m 47s) Loss: 1.4335(0.6090) Grad: 52839.7773  LR: 0.0000790  \n",
      "Epoch: [8][800/2712] Data 0.000 (0.007) Elapsed 11m 50s (remain 28m 15s) Loss: 0.0022(0.6047) Grad: 451.4340  LR: 0.0000790  \n",
      "Epoch: [8][900/2712] Data 0.000 (0.007) Elapsed 13m 16s (remain 26m 41s) Loss: 1.5796(0.5997) Grad: 57137.2695  LR: 0.0000790  \n",
      "Epoch: [8][1000/2712] Data 0.001 (0.006) Elapsed 14m 43s (remain 25m 10s) Loss: 0.0035(0.6099) Grad: 690.4074  LR: 0.0000790  \n",
      "Epoch: [8][1100/2712] Data 0.000 (0.006) Elapsed 16m 19s (remain 23m 52s) Loss: 1.4283(0.6100) Grad: 51231.2227  LR: 0.0000790  \n",
      "Epoch: [8][1200/2712] Data 0.002 (0.005) Elapsed 17m 48s (remain 22m 23s) Loss: 1.1696(0.6118) Grad: 45278.1680  LR: 0.0000790  \n",
      "Epoch: [8][1300/2712] Data 0.002 (0.005) Elapsed 19m 18s (remain 20m 56s) Loss: 0.0056(0.6133) Grad: 1047.7925  LR: 0.0000790  \n",
      "Epoch: [8][1400/2712] Data 0.000 (0.004) Elapsed 20m 52s (remain 19m 32s) Loss: 1.6284(0.6057) Grad: 58011.8359  LR: 0.0000790  \n",
      "Epoch: [8][1500/2712] Data 0.000 (0.004) Elapsed 22m 22s (remain 18m 2s) Loss: 0.0016(0.6009) Grad: 368.0834  LR: 0.0000790  \n",
      "Epoch: [8][1600/2712] Data 0.000 (0.004) Elapsed 23m 51s (remain 16m 33s) Loss: 1.3526(0.6062) Grad: 52485.5078  LR: 0.0000790  \n",
      "Epoch: [8][1700/2712] Data 0.000 (0.004) Elapsed 25m 25s (remain 15m 6s) Loss: 0.0020(0.6142) Grad: 449.2748  LR: 0.0000790  \n",
      "Epoch: [8][1800/2712] Data 0.001 (0.004) Elapsed 27m 0s (remain 13m 39s) Loss: 0.0010(0.6032) Grad: 226.8193  LR: 0.0000790  \n",
      "Epoch: [8][1900/2712] Data 0.000 (0.003) Elapsed 28m 29s (remain 12m 9s) Loss: 0.0042(0.6140) Grad: 812.1294  LR: 0.0000790  \n",
      "Epoch: [8][2000/2712] Data 0.000 (0.003) Elapsed 29m 57s (remain 10m 38s) Loss: 0.0025(0.6106) Grad: 541.0858  LR: 0.0000790  \n",
      "Epoch: [8][2100/2712] Data 0.000 (0.003) Elapsed 31m 30s (remain 9m 9s) Loss: 0.0018(0.6092) Grad: 404.4409  LR: 0.0000790  \n",
      "Epoch: [8][2200/2712] Data 0.001 (0.003) Elapsed 32m 59s (remain 7m 39s) Loss: 1.5986(0.6090) Grad: 58731.7305  LR: 0.0000790  \n",
      "Epoch: [8][2300/2712] Data 0.000 (0.003) Elapsed 34m 32s (remain 6m 10s) Loss: 0.0030(0.6076) Grad: 622.0895  LR: 0.0000790  \n",
      "Epoch: [8][2400/2712] Data 0.000 (0.003) Elapsed 36m 5s (remain 4m 40s) Loss: 0.0010(0.5998) Grad: 242.0591  LR: 0.0000790  \n",
      "Epoch: [8][2500/2712] Data 0.000 (0.003) Elapsed 37m 33s (remain 3m 10s) Loss: 0.0011(0.6070) Grad: 260.3873  LR: 0.0000790  \n",
      "Epoch: [8][2600/2712] Data 0.000 (0.003) Elapsed 39m 7s (remain 1m 40s) Loss: 0.0018(0.6059) Grad: 395.2005  LR: 0.0000790  \n",
      "Epoch: [8][2700/2712] Data 0.000 (0.003) Elapsed 40m 38s (remain 0m 9s) Loss: 1.5066(0.6032) Grad: 56921.2891  LR: 0.0000790  \n",
      "Epoch: [8][2711/2712] Data 0.000 (0.003) Elapsed 40m 48s (remain 0m 0s) Loss: 0.0025(0.6025) Grad: 532.3261  LR: 0.0000790  \n",
      "EVAL: [0/339] Data 9.740 (9.740) Elapsed 0m 10s (remain 61m 48s) Loss: 2.1435(2.1435) \n",
      "EVAL: [100/339] Data 0.000 (0.102) Elapsed 2m 1s (remain 4m 45s) Loss: 1.5217(0.5974) \n",
      "EVAL: [200/339] Data 0.000 (0.052) Elapsed 3m 48s (remain 2m 36s) Loss: 0.0016(0.6454) \n",
      "EVAL: [300/339] Data 0.000 (0.035) Elapsed 5m 40s (remain 0m 42s) Loss: 0.0026(0.6396) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.6025  avg_val_loss: 0.6427  time: 2833s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.031) Elapsed 6m 24s (remain 0m 0s) Loss: 0.0028(0.6427) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 9 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:7.327321936769202e-05\n",
      "scheduler_last_epoch:8, scheduler_lr:7.327321936769202e-05\n",
      "optimizer_lr:7.327321936769202e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][0/2712] Data 6.890 (6.890) Elapsed 0m 7s (remain 354m 14s) Loss: 0.0025(0.0025) Grad: 4339.9404  LR: 0.0000733  \n",
      "Epoch: [9][100/2712] Data 0.000 (0.068) Elapsed 1m 35s (remain 41m 6s) Loss: 0.0006(0.6393) Grad: 317.6314  LR: 0.0000733  \n",
      "Epoch: [9][200/2712] Data 0.002 (0.035) Elapsed 3m 5s (remain 38m 39s) Loss: 1.8923(0.6567) Grad: 134585.1562  LR: 0.0000733  \n",
      "Epoch: [9][300/2712] Data 0.000 (0.023) Elapsed 4m 37s (remain 37m 2s) Loss: 0.0010(0.6341) Grad: 445.4470  LR: 0.0000733  \n",
      "Epoch: [9][400/2712] Data 0.001 (0.018) Elapsed 6m 6s (remain 35m 14s) Loss: 1.6327(0.6444) Grad: 117080.4062  LR: 0.0000733  \n",
      "Epoch: [9][500/2712] Data 0.000 (0.014) Elapsed 7m 40s (remain 33m 52s) Loss: 0.0015(0.6387) Grad: 348.5658  LR: 0.0000733  \n",
      "Epoch: [9][600/2712] Data 0.000 (0.012) Elapsed 9m 9s (remain 32m 9s) Loss: 0.0014(0.6493) Grad: 324.0967  LR: 0.0000733  \n",
      "Epoch: [9][700/2712] Data 0.001 (0.010) Elapsed 10m 38s (remain 30m 31s) Loss: 1.4078(0.6580) Grad: 51645.5625  LR: 0.0000733  \n",
      "Epoch: [9][800/2712] Data 0.000 (0.009) Elapsed 12m 9s (remain 29m 1s) Loss: 0.0013(0.6318) Grad: 308.8142  LR: 0.0000733  \n",
      "Epoch: [9][900/2712] Data 0.000 (0.008) Elapsed 13m 38s (remain 27m 25s) Loss: 0.0013(0.6189) Grad: 281.5719  LR: 0.0000733  \n",
      "Epoch: [9][1000/2712] Data 0.000 (0.007) Elapsed 15m 10s (remain 25m 55s) Loss: 0.0036(0.6232) Grad: 725.5790  LR: 0.0000733  \n",
      "Epoch: [9][1100/2712] Data 0.000 (0.007) Elapsed 16m 45s (remain 24m 31s) Loss: 1.5196(0.6285) Grad: 56779.9883  LR: 0.0000733  \n",
      "Epoch: [9][1200/2712] Data 0.000 (0.006) Elapsed 18m 13s (remain 22m 56s) Loss: 0.0005(0.6209) Grad: 131.5163  LR: 0.0000733  \n",
      "Epoch: [9][1300/2712] Data 0.000 (0.006) Elapsed 19m 45s (remain 21m 26s) Loss: 0.0019(0.6180) Grad: 419.1581  LR: 0.0000733  \n",
      "Epoch: [9][1400/2712] Data 0.000 (0.005) Elapsed 21m 15s (remain 19m 53s) Loss: 0.0024(0.6177) Grad: 509.2953  LR: 0.0000733  \n",
      "Epoch: [9][1500/2712] Data 0.000 (0.005) Elapsed 22m 49s (remain 18m 24s) Loss: 1.6979(0.6120) Grad: 64578.5078  LR: 0.0000733  \n",
      "Epoch: [9][1600/2712] Data 0.000 (0.005) Elapsed 24m 19s (remain 16m 52s) Loss: 0.0027(0.6026) Grad: 534.5193  LR: 0.0000733  \n",
      "Epoch: [9][1700/2712] Data 0.000 (0.004) Elapsed 25m 54s (remain 15m 23s) Loss: 0.0015(0.5997) Grad: 349.5266  LR: 0.0000733  \n",
      "Epoch: [9][1800/2712] Data 0.000 (0.004) Elapsed 27m 23s (remain 13m 51s) Loss: 0.0047(0.5977) Grad: 856.6141  LR: 0.0000733  \n",
      "Epoch: [9][1900/2712] Data 0.000 (0.004) Elapsed 28m 56s (remain 12m 20s) Loss: 1.9498(0.5948) Grad: 67835.0234  LR: 0.0000733  \n",
      "Epoch: [9][2000/2712] Data 0.000 (0.004) Elapsed 30m 25s (remain 10m 48s) Loss: 1.5888(0.5953) Grad: 58335.4453  LR: 0.0000733  \n",
      "Epoch: [9][2100/2712] Data 0.000 (0.004) Elapsed 31m 53s (remain 9m 16s) Loss: 2.7317(0.6021) Grad: 102373.0078  LR: 0.0000733  \n",
      "Epoch: [9][2200/2712] Data 0.000 (0.004) Elapsed 33m 22s (remain 7m 44s) Loss: 0.0036(0.6034) Grad: 714.8332  LR: 0.0000733  \n",
      "Epoch: [9][2300/2712] Data 0.000 (0.003) Elapsed 34m 58s (remain 6m 14s) Loss: 0.0015(0.6024) Grad: 344.0181  LR: 0.0000733  \n",
      "Epoch: [9][2400/2712] Data 0.000 (0.003) Elapsed 36m 26s (remain 4m 43s) Loss: 0.0032(0.6032) Grad: 648.5723  LR: 0.0000733  \n",
      "Epoch: [9][2500/2712] Data 0.000 (0.003) Elapsed 37m 55s (remain 3m 11s) Loss: 0.0021(0.6058) Grad: 459.6219  LR: 0.0000733  \n",
      "Epoch: [9][2600/2712] Data 0.000 (0.003) Elapsed 39m 31s (remain 1m 41s) Loss: 1.6682(0.6066) Grad: 63021.9531  LR: 0.0000733  \n",
      "Epoch: [9][2700/2712] Data 0.000 (0.003) Elapsed 40m 56s (remain 0m 10s) Loss: 0.0014(0.6087) Grad: 329.5481  LR: 0.0000733  \n",
      "Epoch: [9][2711/2712] Data 0.000 (0.003) Elapsed 41m 5s (remain 0m 0s) Loss: 0.0021(0.6074) Grad: 457.6445  LR: 0.0000733  \n",
      "EVAL: [0/339] Data 10.013 (10.013) Elapsed 0m 11s (remain 62m 40s) Loss: 2.1734(2.1734) \n",
      "EVAL: [100/339] Data 0.000 (0.104) Elapsed 1m 59s (remain 4m 40s) Loss: 1.3508(0.5916) \n",
      "EVAL: [200/339] Data 0.002 (0.053) Elapsed 3m 50s (remain 2m 38s) Loss: 0.0008(0.6455) \n",
      "EVAL: [300/339] Data 0.006 (0.036) Elapsed 5m 37s (remain 0m 42s) Loss: 0.0023(0.6383) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.6074  avg_val_loss: 0.6418  time: 2844s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.032) Elapsed 6m 17s (remain 0m 0s) Loss: 0.0028(0.6418) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 10 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:6.707654080246381e-05\n",
      "scheduler_last_epoch:9, scheduler_lr:6.707654080246381e-05\n",
      "optimizer_lr:6.707654080246381e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/2712] Data 3.676 (3.676) Elapsed 0m 4s (remain 207m 33s) Loss: 0.0014(0.0014) Grad: 2642.0720  LR: 0.0000671  \n",
      "Epoch: [10][100/2712] Data 0.000 (0.037) Elapsed 1m 28s (remain 38m 3s) Loss: 3.5081(0.5861) Grad: 121843.9688  LR: 0.0000671  \n",
      "Epoch: [10][200/2712] Data 0.000 (0.019) Elapsed 2m 53s (remain 36m 7s) Loss: 0.0021(0.6047) Grad: 453.8343  LR: 0.0000671  \n",
      "Epoch: [10][300/2712] Data 0.000 (0.013) Elapsed 4m 25s (remain 35m 27s) Loss: 0.0042(0.6014) Grad: 809.5601  LR: 0.0000671  \n",
      "Epoch: [10][400/2712] Data 0.000 (0.010) Elapsed 5m 53s (remain 33m 57s) Loss: 0.0027(0.5841) Grad: 570.4831  LR: 0.0000671  \n",
      "Epoch: [10][500/2712] Data 0.000 (0.008) Elapsed 7m 27s (remain 32m 54s) Loss: 2.9846(0.5787) Grad: 110222.7344  LR: 0.0000671  \n",
      "Epoch: [10][600/2712] Data 0.001 (0.007) Elapsed 8m 58s (remain 31m 32s) Loss: 3.4908(0.5711) Grad: 127294.1172  LR: 0.0000671  \n",
      "Epoch: [10][700/2712] Data 0.000 (0.006) Elapsed 10m 29s (remain 30m 6s) Loss: 0.0032(0.5752) Grad: 650.3676  LR: 0.0000671  \n",
      "Epoch: [10][800/2712] Data 0.000 (0.005) Elapsed 12m 0s (remain 28m 39s) Loss: 0.0016(0.5765) Grad: 335.6020  LR: 0.0000671  \n",
      "Epoch: [10][900/2712] Data 0.000 (0.004) Elapsed 13m 24s (remain 26m 56s) Loss: 1.4649(0.5930) Grad: 55551.1641  LR: 0.0000671  \n",
      "Epoch: [10][1000/2712] Data 0.000 (0.004) Elapsed 14m 47s (remain 25m 17s) Loss: 0.0023(0.5973) Grad: 490.8961  LR: 0.0000671  \n",
      "Epoch: [10][1100/2712] Data 0.000 (0.004) Elapsed 16m 20s (remain 23m 54s) Loss: 0.0017(0.5911) Grad: 378.7904  LR: 0.0000671  \n",
      "Epoch: [10][1200/2712] Data 0.000 (0.003) Elapsed 17m 43s (remain 22m 18s) Loss: 1.9582(0.5903) Grad: 67948.1250  LR: 0.0000671  \n",
      "Epoch: [10][1300/2712] Data 0.000 (0.003) Elapsed 19m 8s (remain 20m 45s) Loss: 0.0019(0.5887) Grad: 412.1211  LR: 0.0000671  \n",
      "Epoch: [10][1400/2712] Data 0.000 (0.003) Elapsed 20m 33s (remain 19m 14s) Loss: 0.0012(0.5873) Grad: 276.7739  LR: 0.0000671  \n",
      "Epoch: [10][1500/2712] Data 0.000 (0.003) Elapsed 22m 2s (remain 17m 47s) Loss: 1.9084(0.5929) Grad: 68529.9297  LR: 0.0000671  \n",
      "Epoch: [10][1600/2712] Data 0.000 (0.003) Elapsed 23m 31s (remain 16m 19s) Loss: 0.0019(0.5913) Grad: 402.8271  LR: 0.0000671  \n",
      "Epoch: [10][1700/2712] Data 0.000 (0.003) Elapsed 25m 2s (remain 14m 53s) Loss: 0.0029(0.5903) Grad: 570.2582  LR: 0.0000671  \n",
      "Epoch: [10][1800/2712] Data 0.000 (0.002) Elapsed 26m 26s (remain 13m 22s) Loss: 0.0035(0.5865) Grad: 682.9893  LR: 0.0000671  \n",
      "Epoch: [10][1900/2712] Data 0.000 (0.002) Elapsed 27m 54s (remain 11m 54s) Loss: 0.0026(0.5904) Grad: 544.4077  LR: 0.0000671  \n",
      "Epoch: [10][2000/2712] Data 0.000 (0.002) Elapsed 29m 18s (remain 10m 24s) Loss: 1.4034(0.5890) Grad: 52608.0156  LR: 0.0000671  \n",
      "Epoch: [10][2100/2712] Data 0.000 (0.002) Elapsed 30m 44s (remain 8m 56s) Loss: 0.0011(0.5891) Grad: 512.2773  LR: 0.0000671  \n",
      "Epoch: [10][2200/2712] Data 0.000 (0.002) Elapsed 32m 9s (remain 7m 27s) Loss: 0.0015(0.5939) Grad: 349.8599  LR: 0.0000671  \n",
      "Epoch: [10][2300/2712] Data 0.000 (0.002) Elapsed 33m 41s (remain 6m 1s) Loss: 0.0012(0.5919) Grad: 294.0355  LR: 0.0000671  \n",
      "Epoch: [10][2400/2712] Data 0.000 (0.002) Elapsed 35m 5s (remain 4m 32s) Loss: 0.0024(0.5961) Grad: 519.4992  LR: 0.0000671  \n",
      "Epoch: [10][2500/2712] Data 0.000 (0.002) Elapsed 36m 30s (remain 3m 4s) Loss: 0.0042(0.5975) Grad: 843.5559  LR: 0.0000671  \n",
      "Epoch: [10][2600/2712] Data 0.000 (0.002) Elapsed 37m 58s (remain 1m 37s) Loss: 1.7505(0.6009) Grad: 67123.9219  LR: 0.0000671  \n",
      "Epoch: [10][2700/2712] Data 0.000 (0.002) Elapsed 39m 29s (remain 0m 9s) Loss: 0.0044(0.6034) Grad: 840.0067  LR: 0.0000671  \n",
      "Epoch: [10][2711/2712] Data 0.000 (0.002) Elapsed 39m 38s (remain 0m 0s) Loss: 1.7525(0.6032) Grad: 65165.9297  LR: 0.0000671  \n",
      "EVAL: [0/339] Data 12.638 (12.638) Elapsed 0m 13s (remain 77m 50s) Loss: 1.9889(1.9889) \n",
      "EVAL: [100/339] Data 0.001 (0.131) Elapsed 2m 1s (remain 4m 47s) Loss: 1.3288(0.5547) \n",
      "EVAL: [200/339] Data 0.000 (0.066) Elapsed 3m 52s (remain 2m 39s) Loss: 0.0019(0.6007) \n",
      "EVAL: [300/339] Data 0.000 (0.044) Elapsed 5m 52s (remain 0m 44s) Loss: 0.0035(0.5950) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.6032  avg_val_loss: 0.5984  time: 2778s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.039) Elapsed 6m 39s (remain 0m 0s) Loss: 0.0047(0.5984) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 11 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:6.057107264610536e-05\n",
      "scheduler_last_epoch:10, scheduler_lr:6.057107264610536e-05\n",
      "optimizer_lr:6.057107264610536e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][0/2712] Data 6.976 (6.976) Elapsed 0m 7s (remain 358m 21s) Loss: 0.0032(0.0032) Grad: 5384.3267  LR: 0.0000606  \n",
      "Epoch: [11][100/2712] Data 0.000 (0.069) Elapsed 1m 36s (remain 41m 38s) Loss: 0.0018(0.5479) Grad: 744.2637  LR: 0.0000606  \n",
      "Epoch: [11][200/2712] Data 0.000 (0.035) Elapsed 3m 5s (remain 38m 34s) Loss: 0.0007(0.6083) Grad: 365.3005  LR: 0.0000606  \n",
      "Epoch: [11][300/2712] Data 0.000 (0.023) Elapsed 4m 33s (remain 36m 31s) Loss: 0.0008(0.6124) Grad: 399.8741  LR: 0.0000606  \n",
      "Epoch: [11][400/2712] Data 0.000 (0.018) Elapsed 6m 2s (remain 34m 47s) Loss: 0.0031(0.5824) Grad: 1180.0817  LR: 0.0000606  \n",
      "Epoch: [11][500/2712] Data 0.000 (0.014) Elapsed 7m 30s (remain 33m 9s) Loss: 0.0010(0.5772) Grad: 477.1198  LR: 0.0000606  \n",
      "Epoch: [11][600/2712] Data 0.002 (0.012) Elapsed 9m 0s (remain 31m 39s) Loss: 1.1021(0.6157) Grad: 44732.3594  LR: 0.0000606  \n",
      "Epoch: [11][700/2712] Data 0.000 (0.010) Elapsed 10m 33s (remain 30m 16s) Loss: 0.0011(0.5997) Grad: 268.9457  LR: 0.0000606  \n",
      "Epoch: [11][800/2712] Data 0.000 (0.009) Elapsed 12m 1s (remain 28m 41s) Loss: 3.0459(0.5972) Grad: 114646.9375  LR: 0.0000606  \n",
      "Epoch: [11][900/2712] Data 0.000 (0.008) Elapsed 13m 30s (remain 27m 9s) Loss: 0.0046(0.6036) Grad: 899.7795  LR: 0.0000606  \n",
      "Epoch: [11][1000/2712] Data 0.000 (0.007) Elapsed 14m 54s (remain 25m 28s) Loss: 0.0021(0.6065) Grad: 465.5933  LR: 0.0000606  \n",
      "Epoch: [11][1100/2712] Data 0.000 (0.007) Elapsed 16m 18s (remain 23m 51s) Loss: 1.3995(0.5966) Grad: 53928.3281  LR: 0.0000606  \n",
      "Epoch: [11][1200/2712] Data 0.000 (0.006) Elapsed 17m 48s (remain 22m 24s) Loss: 1.6579(0.5915) Grad: 61714.4258  LR: 0.0000606  \n",
      "Epoch: [11][1300/2712] Data 0.000 (0.006) Elapsed 19m 20s (remain 20m 58s) Loss: 0.0024(0.5962) Grad: 532.5305  LR: 0.0000606  \n",
      "Epoch: [11][1400/2712] Data 0.000 (0.005) Elapsed 20m 47s (remain 19m 27s) Loss: 1.3422(0.6005) Grad: 56664.8086  LR: 0.0000606  \n",
      "Epoch: [11][1500/2712] Data 0.000 (0.005) Elapsed 22m 16s (remain 17m 58s) Loss: 1.3598(0.6044) Grad: 53470.2969  LR: 0.0000606  \n",
      "Epoch: [11][1600/2712] Data 0.000 (0.005) Elapsed 23m 44s (remain 16m 28s) Loss: 0.0021(0.6015) Grad: 466.5853  LR: 0.0000606  \n",
      "Epoch: [11][1700/2712] Data 0.000 (0.004) Elapsed 25m 16s (remain 15m 1s) Loss: 0.0026(0.6015) Grad: 545.2169  LR: 0.0000606  \n",
      "Epoch: [11][1800/2712] Data 0.000 (0.004) Elapsed 26m 45s (remain 13m 32s) Loss: 0.0019(0.6062) Grad: 441.7637  LR: 0.0000606  \n",
      "Epoch: [11][1900/2712] Data 0.000 (0.004) Elapsed 28m 14s (remain 12m 2s) Loss: 0.0014(0.6010) Grad: 339.6030  LR: 0.0000606  \n",
      "Epoch: [11][2000/2712] Data 0.000 (0.004) Elapsed 29m 43s (remain 10m 33s) Loss: 0.0022(0.6007) Grad: 489.8716  LR: 0.0000606  \n",
      "Epoch: [11][2100/2712] Data 0.000 (0.004) Elapsed 31m 11s (remain 9m 4s) Loss: 1.3216(0.5994) Grad: 52006.0586  LR: 0.0000606  \n",
      "Epoch: [11][2200/2712] Data 0.000 (0.004) Elapsed 32m 40s (remain 7m 35s) Loss: 0.0020(0.5943) Grad: 443.1816  LR: 0.0000606  \n",
      "Epoch: [11][2300/2712] Data 0.000 (0.003) Elapsed 34m 8s (remain 6m 5s) Loss: 1.4939(0.5928) Grad: 59192.3711  LR: 0.0000606  \n",
      "Epoch: [11][2400/2712] Data 0.000 (0.003) Elapsed 35m 41s (remain 4m 37s) Loss: 0.0017(0.5955) Grad: 406.5400  LR: 0.0000606  \n",
      "Epoch: [11][2500/2712] Data 0.000 (0.003) Elapsed 37m 4s (remain 3m 7s) Loss: 0.9871(0.6008) Grad: 42596.9375  LR: 0.0000606  \n",
      "Epoch: [11][2600/2712] Data 0.000 (0.003) Elapsed 38m 29s (remain 1m 38s) Loss: 0.0024(0.6012) Grad: 519.8166  LR: 0.0000606  \n",
      "Epoch: [11][2700/2712] Data 0.000 (0.003) Elapsed 39m 55s (remain 0m 9s) Loss: 0.0039(0.6058) Grad: 744.8625  LR: 0.0000606  \n",
      "Epoch: [11][2711/2712] Data 0.000 (0.003) Elapsed 40m 4s (remain 0m 0s) Loss: 0.0029(0.6039) Grad: 611.2189  LR: 0.0000606  \n",
      "EVAL: [0/339] Data 10.475 (10.475) Elapsed 0m 11s (remain 65m 26s) Loss: 1.9345(1.9345) \n",
      "EVAL: [100/339] Data 0.001 (0.107) Elapsed 1m 59s (remain 4m 41s) Loss: 1.2914(0.5452) \n",
      "EVAL: [200/339] Data 0.000 (0.054) Elapsed 3m 49s (remain 2m 37s) Loss: 0.0022(0.5923) \n",
      "EVAL: [300/339] Data 0.000 (0.036) Elapsed 5m 45s (remain 0m 43s) Loss: 0.0049(0.5839) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 0.6039  avg_val_loss: 0.5875  time: 2796s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [338/339] Data 0.000 (0.032) Elapsed 6m 30s (remain 0m 0s) Loss: 0.0044(0.5875) \n",
      "early_stopping\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(CFG.suffix)\n",
    "    if CFG.device == 'TPU':\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as cpu\n",
    "if CFG.device == 'TPU': \n",
    "    for fold in range(CFG.fold_num):\n",
    "        if fold in CFG.fold_list:\n",
    "            # best score\n",
    "            state = torch.load(outputdir+f'{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{cur_best_list[4]}.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), 'preds': state['preds'], 'cur_best_list': state['cur_best_list']}, \n",
    "                    outputdir+f'{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{cur_best_list[4]}_cpu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b79a61544c9a744d09395b396d14bdc3ab2980641b64ddb1c7bc6d7b892900a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
