{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.16.2)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (20.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.1.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.21.6)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (1.14.0)\n",
      "Installing collected packages: tifffile, scikit-image\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.16.2\n",
      "    Uninstalling scikit-image-0.16.2:\n",
      "      Successfully uninstalled scikit-image-0.16.2\n",
      "Successfully installed scikit-image-0.19.3 tifffile-2021.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting timm\n",
      "  Using cached timm-0.6.11-py3-none-any.whl (548 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "Collecting torch>=1.7\n",
      "  Using cached torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (59.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (0.34.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.42.1)\n",
      "Collecting packaging>=20.9\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (5.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.0.12)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.8)\n",
      "Installing collected packages: packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, huggingface-hub, torch, torchvision, timm\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "sagemaker 2.116.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 5.0.0 which is incompatible.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.11.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-21.3 timm-0.6.11 torch-1.13.0 torchvision-0.14.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-4.0.2-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nibabel) (59.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from nibabel) (1.21.6)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from nibabel) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->nibabel) (2.4.6)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-4.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting python-gdcm\n",
      "  Using cached python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Installing collected packages: python-gdcm\n",
      "Successfully installed python-gdcm-3.0.20\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting pylibjpeg\n",
      "  Using cached pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting pylibjpeg-libjpeg\n",
      "  Using cached pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting pydicom\n",
      "  Using cached pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n",
      "Installing collected packages: pylibjpeg-libjpeg, pylibjpeg, pydicom\n",
      "Successfully installed pydicom-2.3.1 pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Using cached opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (0.22.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.16.1->albumentations) (4.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (0.14.1)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.0 opencv-python-headless-4.6.0.66 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting segmentation_models_pytorch\n",
      "  Using cached segmentation_models_pytorch-0.3.0-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.14.0)\n",
      "Collecting timm==0.4.12\n",
      "  Using cached timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (4.42.1)\n",
      "Collecting efficientnet-pytorch==0.7.1\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Collecting pretrainedmodels==0.7.4\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (9.3.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
      "Collecting munch\n",
      "  Using cached munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (59.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.9.24)\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 0.6.11\n",
      "    Uninstalling timm-0.6.11:\n",
      "      Successfully uninstalled timm-0.6.11\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-2.5.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.0 timm-0.4.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -U scikit-image\n",
    "# !pip install timm\n",
    "# !pip install nibabel\n",
    "# ! pip install python-gdcm\n",
    "# ! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n",
    "# !pip install -U albumentations\n",
    "# !pip install segmentation_models_pytorch\n",
    "# !pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "datadir = '/root/input/rsna-2022-cervical-spine-fracture-detection'\n",
    "libdir = '/root/workspace/RSNA2022RAWE'\n",
    "outputdir = '/root/workspace/RSNA2022RAWE'\n",
    "otherdir = '/root/workspace/RSNA2022RAWE'\n",
    "\n",
    "train_bs_ = 16 # train_batch_size\n",
    "valid_bs_ = 128 # valid_batch_size\n",
    "num_workers_ = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU' # ['TPU', 'GPU']\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    fold_num=5 \n",
    "    \n",
    "    target_cols=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"OT\"]\n",
    "    num_classes=8 \n",
    "    \n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] \n",
    "    normalize_std=[0.22, 0.22, 0.22] \n",
    "    \n",
    "    fold_list=[0]\n",
    "\n",
    "    model_arch=\"efficientnet-b0\" \n",
    "    img_size=320 \n",
    "    croped_img_size = 320 # 裁剪后的图片尺寸\n",
    "    weight_path = f\"{outputdir}/efficientnet-b0_109_fold0_epoch9.pth\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys; \n",
    "    \n",
    "import ast\n",
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import gc \n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "\n",
    "def init_logger(log_file=outputdir+'/train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    # data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>prediction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C2</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C3</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id           StudyInstanceUID prediction_type\n",
       "0  1.2.826.0.1.3680043.22327_C1  1.2.826.0.1.3680043.22327              C1\n",
       "1  1.2.826.0.1.3680043.22327_C2  1.2.826.0.1.3680043.22327              C2\n",
       "2  1.2.826.0.1.3680043.22327_C3  1.2.826.0.1.3680043.22327              C3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = 'input/rsna-2022-cervical-spine-fracture-detection/sample_submission.csv'\n",
    "# Fix mismatch with test_images folder\n",
    "test_df = pd.DataFrame(columns = ['row_id','StudyInstanceUID','prediction_type'])\n",
    "for i in ['1.2.826.0.1.3680043.22327','1.2.826.0.1.3680043.25399','1.2.826.0.1.3680043.5876']:\n",
    "    for j in ['C1','C2','C3','C4','C5','C6','C7','patient_overall']:\n",
    "        test_df = test_df.append({'row_id':i+'_'+j,'StudyInstanceUID':i,'prediction_type':j},ignore_index=True)\n",
    "\n",
    "# Sample submission\n",
    "ss = pd.DataFrame(test_df['row_id'])\n",
    "ss['fractured'] = 0.5\n",
    "\n",
    "display(test_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 72.95it/s]\n"
     ]
    }
   ],
   "source": [
    "test_slice_list = []\n",
    "for file_name in tqdm(test_df[\"StudyInstanceUID\"].values):\n",
    "    test_image_path = glob(f\"{datadir}/test_images/{file_name}/*\")\n",
    "    test_image_path = sorted(test_image_path, key=lambda x:int(x.split(\"/\")[-1].replace(\".dcm\",\"\")))\n",
    "    for path_idx in range(len(test_image_path)):\n",
    "        path1 = \"nofile\" if path_idx-1 < 0 else test_image_path[path_idx-1].replace(f\"{datadir}/\", \"\")\n",
    "        path2 = test_image_path[path_idx].replace(f\"{datadir}/\", \"\")\n",
    "        path3 = \"nofile\" if path_idx+1 >= len(test_image_path) else test_image_path[path_idx+1].replace(f\"{datadir}/\", \"\")\n",
    "        slice_num = int(path2.split(\"/\")[-1].replace(\".dcm\",\"\"))\n",
    "        test_slice_list.append([f\"{file_name}_{slice_num}\", file_name, slice_num, path1, path2, path3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10544 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id           StudyInstanceUID  slice_num  \\\n",
       "0       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "1       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "2       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "3       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "4       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "...                             ...                        ...        ...   \n",
       "10539  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10540  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10541  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10542  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10543  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "\n",
       "                                              path1  \\\n",
       "0                                            nofile   \n",
       "1                                            nofile   \n",
       "2                                            nofile   \n",
       "3                                            nofile   \n",
       "4                                            nofile   \n",
       "...                                             ...   \n",
       "10539  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10540  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10541  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10542  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10543  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "\n",
       "                                              path2  \\\n",
       "0       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "1       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "2       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "3       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "4       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "...                                             ...   \n",
       "10539  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10540  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10541  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10542  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10543  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "\n",
       "                                             path3  \n",
       "0      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "1      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "2      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "3      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "4      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "...                                            ...  \n",
       "10539                                       nofile  \n",
       "10540                                       nofile  \n",
       "10541                                       nofile  \n",
       "10542                                       nofile  \n",
       "10543                                       nofile  \n",
       "\n",
       "[10544 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_slice_list, columns=[\"id\", \"StudyInstanceUID\", \"slice_num\", \"path1\", \"path2\", \"path3\"])\n",
    "test_df = test_df.sort_values(['StudyInstanceUID', 'slice_num'], ascending = [True, True]).reset_index(drop=True)\n",
    "test_df.to_csv(f'{outputdir}/test_slice_list.csv', index=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        im2 = load_dicom(f\"{datadir}/{row['path2']}\")   # 512*512  \n",
    "        im2h = im2.shape[0]\n",
    "        im2w = im2.shape[1]\n",
    "\n",
    "        im1 = load_dicom(f\"{datadir}/{row['path1']}\") if row['path1'] != \"nofile\" else np.zeros((im2h, im2w))  # 512*512                                                       \n",
    "        im3 = load_dicom(f\"{datadir}/{row['path3']}\") if row['path3'] != \"nofile\" else np.zeros((im2h, im2w))  # 512*512  \n",
    "\n",
    "        if im1.shape !=  (im2h, im2w):\n",
    "            im1 = cv2.resize(im1, (im2w, im2h))\n",
    "        if im3.shape !=  (im2h, im2w):\n",
    "            im3 = cv2.resize(im3, (im2w, im2h)) \n",
    "        image_list = [im1, im2, im3]\n",
    "        image = np.stack(image_list, axis=2) # 512*512*3; 0-1\n",
    "\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # image = image/255.0\n",
    "        image = np.transpose(image, (2, 0, 1)) # 3*img_size*img_size; 0-1\n",
    "        return torch.from_numpy(image), row['StudyInstanceUID'], row['slice_num'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n",
    "    CenterCrop, Resize, RandomCrop, GaussianBlur, JpegCompression, Downscale, ElasticTransform\n",
    ")\n",
    "import albumentations\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transforms(data):\n",
    "    if data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CFG.model_arch,    # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path)[\"model\"])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{outputdir}/test_voxel_mask\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertebra_class = []\n",
    "voxel_crop_list = []\n",
    "def crop_voxel(voxels, voxel_mask, last_f_name, croped_img_size):\n",
    "    area_thr = 10\n",
    "    # x\n",
    "    x_list = []\n",
    "    length = voxel_mask.shape[0]\n",
    "    for i in range(length):\n",
    "        if voxel_mask[i].sum().item() >= area_thr:\n",
    "            x_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        x_list.append(0)\n",
    "\n",
    "    for i in range(length-1, -1, -1):\n",
    "        if voxel_mask[i].sum().item() >= area_thr:\n",
    "            x_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        x_list.append(length-1)\n",
    "\n",
    "    # y\n",
    "    y_list = []\n",
    "    length = voxel_mask.shape[1]\n",
    "    for i in range(length):\n",
    "        if voxel_mask[:, i].sum().item() >= area_thr:\n",
    "            y_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        y_list.append(0)\n",
    "\n",
    "    for i in range(length-1, -1, -1):\n",
    "        if voxel_mask[:, i].sum().item() >= area_thr:\n",
    "            y_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        y_list.append(length-1)\n",
    "\n",
    "    # z\n",
    "    z_list = []\n",
    "    length = voxel_mask.shape[2]\n",
    "    for i in range(length):\n",
    "        if voxel_mask[:, :, i].sum().item() >= area_thr:\n",
    "            z_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        z_list.append(0)\n",
    "\n",
    "    for i in range(length-1, -1, -1):\n",
    "        if voxel_mask[:, :, i].sum().item() >= area_thr:\n",
    "            z_list.append(i)\n",
    "            break\n",
    "    else:\n",
    "        z_list.append(length-1)\n",
    "        \n",
    "    try:\n",
    "        croped_voxel_mask = voxel_mask[x_list[0]:x_list[1]+1, y_list[0]:y_list[1]+1, z_list[0]:z_list[1]+1]\n",
    "        row = [last_f_name, voxel_mask.shape[1], x_list[0], x_list[1]+1, y_list[0], y_list[1]+1, z_list[0], z_list[1]+1]\n",
    "    except:\n",
    "        print(f\"last_f_name:{last_f_name}, voxel_mask.shape:{voxel_mask.shape}, x_list:{x_list}, y_list:{y_list}, z_list:{z_list}\")\n",
    "        croped_voxel_mask = voxel_mask\n",
    "        row = [last_f_name, voxel_mask.shape[1], 0, voxel_mask.shape[0], 0, voxel_mask.shape[1], 0, voxel_mask.shape[2]]\n",
    "    voxel_crop_list.append(row)\n",
    "\n",
    "    croped_voxel_mask = croped_voxel_mask.to('cpu').numpy().astype(np.uint8) # bs*img_size*img_size; 0-8 classes\n",
    "\n",
    "\n",
    "    for x_idx in range(croped_voxel_mask.shape[0]):\n",
    "        slice_mask = croped_voxel_mask[x_idx]\n",
    "\n",
    "        unique, counts = np.unique(slice_mask, return_counts=True)\n",
    "        if len(unique) == 1 and unique[0] == 0:\n",
    "            vertebra_class.append([last_f_name, x_idx, 0])\n",
    "        elif unique[0] == 0:\n",
    "            unique = unique[1:]\n",
    "            counts = counts[1:]\n",
    "            vertebra_class.append([last_f_name, x_idx, unique[counts.argmax()]])\n",
    "        else:\n",
    "            vertebra_class.append([last_f_name, x_idx, unique[counts.argmax()]])\n",
    "        \n",
    "    return None, croped_voxel_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:43<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dataset = TestDataset(test_df, transform=get_transforms(\"valid\")) # get_transforms(\"valid\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.valid_bs, num_workers=CFG.num_workers, shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "model = load_model(CFG.weight_path)\n",
    "model.eval()\n",
    "last_f_name = \"\"\n",
    "voxel_mask = []\n",
    "voxels = []\n",
    "for step, (images, file_names, n_slice) in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "    images = images.to(device, dtype=torch.float) # bs*3*image_size*image_size\n",
    "    batch_size = images.size(0)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(images) # [B, 8, H, W]\n",
    "    y_pred = y_pred.sigmoid() ####\n",
    "    slice_mask_max = torch.max(y_pred, 1) # bs*img_size*img_size\n",
    "    slice_mask = torch.where((slice_mask_max.values)>0.5, slice_mask_max.indices+1, 0) # bs*img_size*img_size; 0-8 classes\n",
    "\n",
    "    start_idx = 0\n",
    "    for bs_idx in range(batch_size):\n",
    "        f_name = file_names[bs_idx]\n",
    "        if f_name != last_f_name:\n",
    "            voxel_mask.append(slice_mask[start_idx:bs_idx])\n",
    "            voxel_mask = torch.cat(voxel_mask, dim=0) # n_slice*img_size*img_size; 0-8 classes\n",
    "            \n",
    "            if len(voxel_mask) > 0:\n",
    "                croped_voxel, croped_voxel_mask = crop_voxel(None, voxel_mask, last_f_name, CFG.croped_img_size)\n",
    "            last_f_name = f_name\n",
    "            start_idx = bs_idx\n",
    "            voxel_mask = []\n",
    "            # voxels = []\n",
    "        elif bs_idx == batch_size-1:\n",
    "            voxel_mask.append(slice_mask[start_idx:batch_size])\n",
    "\n",
    "voxel_mask = torch.cat(voxel_mask, dim=0)\n",
    "if len(voxel_mask) > 0:\n",
    "    croped_voxel, croped_voxel_mask = crop_voxel(None, voxel_mask, last_f_name, CFG.croped_img_size)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voxel_crop_list) # 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>before_image_size</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  before_image_size   x0    x1   y0   y1  z0   z1\n",
       "0  1.2.826.0.1.3680043.22327                320    0  2496    6  265  86  238\n",
       "1  1.2.826.0.1.3680043.25399                320  784  4336  109  274  65  204\n",
       "2   1.2.826.0.1.3680043.5876                320    0  3656    3  249  71  225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_crop_df = pd.DataFrame(voxel_crop_list, columns=[\"StudyInstanceUID\", \"before_image_size\", \"x0\", \"x1\", \"y0\", \"y1\", \"z0\", \"z1\"])\n",
    "study_crop_df.to_csv(f\"{datadir}/test_study_crop_info.csv\", index=False)\n",
    "study_crop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_458</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>nofile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10544 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id           StudyInstanceUID  slice_num  \\\n",
       "0       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "1       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "2       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "3       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "4       1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "...                             ...                        ...        ...   \n",
       "10539  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10540  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10541  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10542  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "10543  1.2.826.0.1.3680043.5876_458   1.2.826.0.1.3680043.5876        458   \n",
       "\n",
       "                                              path1  \\\n",
       "0                                            nofile   \n",
       "1                                            nofile   \n",
       "2                                            nofile   \n",
       "3                                            nofile   \n",
       "4                                            nofile   \n",
       "...                                             ...   \n",
       "10539  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10540  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10541  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10542  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "10543  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "\n",
       "                                              path2  \\\n",
       "0       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "1       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "2       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "3       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "4       test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "...                                             ...   \n",
       "10539  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10540  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10541  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10542  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "10543  test_images/1.2.826.0.1.3680043.5876/458.dcm   \n",
       "\n",
       "                                             path3  \n",
       "0      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "1      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "2      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "3      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "4      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "...                                            ...  \n",
       "10539                                       nofile  \n",
       "10540                                       nofile  \n",
       "10541                                       nofile  \n",
       "10542                                       nofile  \n",
       "10543                                       nofile  \n",
       "\n",
       "[10544 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_slice_list = pd.read_csv(f\"{outputdir}/test_slice_list.csv\")\n",
    "test_slice_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9704 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id           StudyInstanceUID  slice_num  \\\n",
       "0      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "1      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "2      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "3      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "4      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "...                            ...                        ...        ...   \n",
       "9699  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9700  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9701  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9702  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9703  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "\n",
       "                                             path1  \\\n",
       "0                                           nofile   \n",
       "1                                           nofile   \n",
       "2                                           nofile   \n",
       "3                                           nofile   \n",
       "4                                           nofile   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "\n",
       "                                             path2  \\\n",
       "0      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "1      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "2      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "3      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "4      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "\n",
       "                                             path3  \n",
       "0      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "1      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "2      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "3      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "4      test_images/1.2.826.0.1.3680043.22327/2.dcm  \n",
       "...                                            ...  \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/458.dcm  \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/458.dcm  \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/458.dcm  \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/458.dcm  \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/458.dcm  \n",
       "\n",
       "[9704 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = []\n",
    "for idx, study_id, _, x0, x1, _, _, _, _, in study_crop_df.itertuples():\n",
    "    one_study = test_slice_list[test_slice_list[\"StudyInstanceUID\"] == study_id].reset_index(drop=True)\n",
    "    new_df.append(one_study[x0:x1])\n",
    "new_df = pd.concat(new_df, axis=0).reset_index(drop=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>new_slice_num</th>\n",
       "      <th>vertebra_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3651</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3652</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3653</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3654</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3655</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9704 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID  new_slice_num  vertebra_class\n",
       "0     1.2.826.0.1.3680043.22327              0               2\n",
       "1     1.2.826.0.1.3680043.22327              1               2\n",
       "2     1.2.826.0.1.3680043.22327              2               2\n",
       "3     1.2.826.0.1.3680043.22327              3               2\n",
       "4     1.2.826.0.1.3680043.22327              4               2\n",
       "...                         ...            ...             ...\n",
       "9699   1.2.826.0.1.3680043.5876           3651               8\n",
       "9700   1.2.826.0.1.3680043.5876           3652               8\n",
       "9701   1.2.826.0.1.3680043.5876           3653               8\n",
       "9702   1.2.826.0.1.3680043.5876           3654               8\n",
       "9703   1.2.826.0.1.3680043.5876           3655               8\n",
       "\n",
       "[9704 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_class_df = pd.DataFrame(vertebra_class, columns=[\"StudyInstanceUID\", \"new_slice_num\", \"vertebra_class\"])\n",
    "slice_class_df.sort_values(by=[\"StudyInstanceUID\", \"new_slice_num\"], inplace=True)\n",
    "slice_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "      <th>new_slice_num</th>\n",
       "      <th>vertebra_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3651</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3652</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3653</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3654</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3655</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9704 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id           StudyInstanceUID  slice_num  \\\n",
       "0      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "1      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "2      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "3      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "4      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "...                            ...                        ...        ...   \n",
       "9699  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9700  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9701  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9702  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9703  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "\n",
       "                                             path1  \\\n",
       "0                                           nofile   \n",
       "1                                           nofile   \n",
       "2                                           nofile   \n",
       "3                                           nofile   \n",
       "4                                           nofile   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "\n",
       "                                             path2  \\\n",
       "0      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "1      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "2      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "3      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "4      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "\n",
       "                                             path3  new_slice_num  \\\n",
       "0      test_images/1.2.826.0.1.3680043.22327/2.dcm              0   \n",
       "1      test_images/1.2.826.0.1.3680043.22327/2.dcm              1   \n",
       "2      test_images/1.2.826.0.1.3680043.22327/2.dcm              2   \n",
       "3      test_images/1.2.826.0.1.3680043.22327/2.dcm              3   \n",
       "4      test_images/1.2.826.0.1.3680043.22327/2.dcm              4   \n",
       "...                                            ...            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/458.dcm           3651   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/458.dcm           3652   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/458.dcm           3653   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/458.dcm           3654   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/458.dcm           3655   \n",
       "\n",
       "      vertebra_class  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "...              ...  \n",
       "9699               8  \n",
       "9700               8  \n",
       "9701               8  \n",
       "9702               8  \n",
       "9703               8  \n",
       "\n",
       "[9704 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([new_df, slice_class_df[[\"new_slice_num\", \"vertebra_class\"]]], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>path1</th>\n",
       "      <th>path2</th>\n",
       "      <th>path3</th>\n",
       "      <th>new_slice_num</th>\n",
       "      <th>vertebra_class</th>\n",
       "      <th>before_image_size</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>nofile</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/1.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.22327/2.dcm</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3651</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3652</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3653</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3654</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_457</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/456.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/457.dcm</td>\n",
       "      <td>test_images/1.2.826.0.1.3680043.5876/458.dcm</td>\n",
       "      <td>3655</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9704 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id           StudyInstanceUID  slice_num  \\\n",
       "0      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "1      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "2      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "3      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "4      1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327          1   \n",
       "...                            ...                        ...        ...   \n",
       "9699  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9700  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9701  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9702  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "9703  1.2.826.0.1.3680043.5876_457   1.2.826.0.1.3680043.5876        457   \n",
       "\n",
       "                                             path1  \\\n",
       "0                                           nofile   \n",
       "1                                           nofile   \n",
       "2                                           nofile   \n",
       "3                                           nofile   \n",
       "4                                           nofile   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/456.dcm   \n",
       "\n",
       "                                             path2  \\\n",
       "0      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "1      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "2      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "3      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "4      test_images/1.2.826.0.1.3680043.22327/1.dcm   \n",
       "...                                            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/457.dcm   \n",
       "\n",
       "                                             path3  new_slice_num  \\\n",
       "0      test_images/1.2.826.0.1.3680043.22327/2.dcm              0   \n",
       "1      test_images/1.2.826.0.1.3680043.22327/2.dcm              1   \n",
       "2      test_images/1.2.826.0.1.3680043.22327/2.dcm              2   \n",
       "3      test_images/1.2.826.0.1.3680043.22327/2.dcm              3   \n",
       "4      test_images/1.2.826.0.1.3680043.22327/2.dcm              4   \n",
       "...                                            ...            ...   \n",
       "9699  test_images/1.2.826.0.1.3680043.5876/458.dcm           3651   \n",
       "9700  test_images/1.2.826.0.1.3680043.5876/458.dcm           3652   \n",
       "9701  test_images/1.2.826.0.1.3680043.5876/458.dcm           3653   \n",
       "9702  test_images/1.2.826.0.1.3680043.5876/458.dcm           3654   \n",
       "9703  test_images/1.2.826.0.1.3680043.5876/458.dcm           3655   \n",
       "\n",
       "      vertebra_class  before_image_size  x0    x1  y0   y1  z0   z1  \n",
       "0                  2                320   0  2496   6  265  86  238  \n",
       "1                  2                320   0  2496   6  265  86  238  \n",
       "2                  2                320   0  2496   6  265  86  238  \n",
       "3                  2                320   0  2496   6  265  86  238  \n",
       "4                  2                320   0  2496   6  265  86  238  \n",
       "...              ...                ...  ..   ...  ..  ...  ..  ...  \n",
       "9699               8                320   0  3656   3  249  71  225  \n",
       "9700               8                320   0  3656   3  249  71  225  \n",
       "9701               8                320   0  3656   3  249  71  225  \n",
       "9702               8                320   0  3656   3  249  71  225  \n",
       "9703               8                320   0  3656   3  249  71  225  \n",
       "\n",
       "[9704 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_slice_df = new_df.merge(study_crop_df, on=\"StudyInstanceUID\", how=\"left\")\n",
    "new_slice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_slice_df.to_csv(f\"{datadir}/test_slice.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 113.71it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_num = 24\n",
    "vertebrae_df_list = []\n",
    "for study_id in tqdm(np.unique(new_slice_df[\"StudyInstanceUID\"])):\n",
    "    one_study = new_slice_df[new_slice_df[\"StudyInstanceUID\"] == study_id].reset_index(drop=True)\n",
    "    for cid in range(1, 8):\n",
    "        one_study_cid = one_study[one_study[\"vertebra_class\"] == cid].reset_index(drop=True)\n",
    "        if len(one_study_cid) >= sample_num:\n",
    "            sample_index = np.linspace(0, len(one_study_cid)-1, sample_num, dtype=int)\n",
    "            one_study_cid = one_study_cid.iloc[sample_index].reset_index(drop=True)\n",
    "        if len(one_study_cid) < 5:\n",
    "            continue\n",
    "        slice_num_list = one_study_cid[\"slice_num\"].values.tolist()\n",
    "        arow = one_study_cid.iloc[0]\n",
    "        vertebrae_df_list.append([f\"{study_id}_{cid}\", study_id, cid, slice_num_list, arow[\"before_image_size\"], \\\n",
    "            arow[\"x0\"], arow[\"x1\"], arow[\"y0\"], arow[\"y1\"], arow[\"z0\"], arow[\"z1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_cid</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>cid</th>\n",
       "      <th>slice_num_list</th>\n",
       "      <th>before_image_size</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>[46, 47, 49, 50, 52, 54, 55, 57, 58, 60, 62, 6...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_2</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_3</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>3</td>\n",
       "      <td>[116, 117, 118, 119, 120, 121, 122, 123, 125, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_4</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>4</td>\n",
       "      <td>[142, 143, 144, 145, 146, 147, 148, 149, 150, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_5</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>5</td>\n",
       "      <td>[167, 167, 168, 169, 170, 171, 172, 173, 174, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_6</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>6</td>\n",
       "      <td>[189, 190, 192, 193, 194, 195, 196, 197, 198, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_7</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>7</td>\n",
       "      <td>[215, 216, 217, 218, 219, 220, 221, 222, 224, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_1</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>1</td>\n",
       "      <td>[99, 101, 103, 105, 107, 109, 111, 113, 116, 1...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_2</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>2</td>\n",
       "      <td>[148, 150, 152, 154, 156, 158, 160, 162, 165, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_3</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>3</td>\n",
       "      <td>[197, 198, 200, 202, 203, 205, 207, 209, 210, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_4</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>4</td>\n",
       "      <td>[237, 238, 240, 242, 244, 246, 248, 250, 252, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_5</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>5</td>\n",
       "      <td>[277, 278, 279, 280, 282, 283, 284, 286, 287, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_6</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>6</td>\n",
       "      <td>[313, 314, 316, 317, 319, 321, 322, 324, 325, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_7</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>7</td>\n",
       "      <td>[350, 351, 353, 354, 356, 357, 359, 360, 362, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>784</td>\n",
       "      <td>4336</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>65</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_1</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>1</td>\n",
       "      <td>[50, 52, 54, 56, 59, 61, 63, 66, 68, 70, 72, 7...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_2</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 104, 106, 108, 110, 112, 115, 117, 119, 12...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_3</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>3</td>\n",
       "      <td>[152, 153, 155, 156, 158, 159, 161, 162, 164, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_4</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>4</td>\n",
       "      <td>[187, 188, 189, 191, 192, 194, 195, 197, 198, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_5</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>5</td>\n",
       "      <td>[220, 221, 222, 224, 225, 226, 228, 229, 231, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_6</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>6</td>\n",
       "      <td>[252, 253, 254, 255, 257, 258, 259, 261, 262, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_7</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>7</td>\n",
       "      <td>[282, 283, 284, 286, 287, 288, 290, 291, 292, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>3656</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      study_cid           StudyInstanceUID  cid  \\\n",
       "0   1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327    1   \n",
       "1   1.2.826.0.1.3680043.22327_2  1.2.826.0.1.3680043.22327    2   \n",
       "2   1.2.826.0.1.3680043.22327_3  1.2.826.0.1.3680043.22327    3   \n",
       "3   1.2.826.0.1.3680043.22327_4  1.2.826.0.1.3680043.22327    4   \n",
       "4   1.2.826.0.1.3680043.22327_5  1.2.826.0.1.3680043.22327    5   \n",
       "5   1.2.826.0.1.3680043.22327_6  1.2.826.0.1.3680043.22327    6   \n",
       "6   1.2.826.0.1.3680043.22327_7  1.2.826.0.1.3680043.22327    7   \n",
       "7   1.2.826.0.1.3680043.25399_1  1.2.826.0.1.3680043.25399    1   \n",
       "8   1.2.826.0.1.3680043.25399_2  1.2.826.0.1.3680043.25399    2   \n",
       "9   1.2.826.0.1.3680043.25399_3  1.2.826.0.1.3680043.25399    3   \n",
       "10  1.2.826.0.1.3680043.25399_4  1.2.826.0.1.3680043.25399    4   \n",
       "11  1.2.826.0.1.3680043.25399_5  1.2.826.0.1.3680043.25399    5   \n",
       "12  1.2.826.0.1.3680043.25399_6  1.2.826.0.1.3680043.25399    6   \n",
       "13  1.2.826.0.1.3680043.25399_7  1.2.826.0.1.3680043.25399    7   \n",
       "14   1.2.826.0.1.3680043.5876_1   1.2.826.0.1.3680043.5876    1   \n",
       "15   1.2.826.0.1.3680043.5876_2   1.2.826.0.1.3680043.5876    2   \n",
       "16   1.2.826.0.1.3680043.5876_3   1.2.826.0.1.3680043.5876    3   \n",
       "17   1.2.826.0.1.3680043.5876_4   1.2.826.0.1.3680043.5876    4   \n",
       "18   1.2.826.0.1.3680043.5876_5   1.2.826.0.1.3680043.5876    5   \n",
       "19   1.2.826.0.1.3680043.5876_6   1.2.826.0.1.3680043.5876    6   \n",
       "20   1.2.826.0.1.3680043.5876_7   1.2.826.0.1.3680043.5876    7   \n",
       "\n",
       "                                       slice_num_list  before_image_size   x0  \\\n",
       "0   [46, 47, 49, 50, 52, 54, 55, 57, 58, 60, 62, 6...                320    0   \n",
       "1   [1, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98...                320    0   \n",
       "2   [116, 117, 118, 119, 120, 121, 122, 123, 125, ...                320    0   \n",
       "3   [142, 143, 144, 145, 146, 147, 148, 149, 150, ...                320    0   \n",
       "4   [167, 167, 168, 169, 170, 171, 172, 173, 174, ...                320    0   \n",
       "5   [189, 190, 192, 193, 194, 195, 196, 197, 198, ...                320    0   \n",
       "6   [215, 216, 217, 218, 219, 220, 221, 222, 224, ...                320    0   \n",
       "7   [99, 101, 103, 105, 107, 109, 111, 113, 116, 1...                320  784   \n",
       "8   [148, 150, 152, 154, 156, 158, 160, 162, 165, ...                320  784   \n",
       "9   [197, 198, 200, 202, 203, 205, 207, 209, 210, ...                320  784   \n",
       "10  [237, 238, 240, 242, 244, 246, 248, 250, 252, ...                320  784   \n",
       "11  [277, 278, 279, 280, 282, 283, 284, 286, 287, ...                320  784   \n",
       "12  [313, 314, 316, 317, 319, 321, 322, 324, 325, ...                320  784   \n",
       "13  [350, 351, 353, 354, 356, 357, 359, 360, 362, ...                320  784   \n",
       "14  [50, 52, 54, 56, 59, 61, 63, 66, 68, 70, 72, 7...                320    0   \n",
       "15  [1, 104, 106, 108, 110, 112, 115, 117, 119, 12...                320    0   \n",
       "16  [152, 153, 155, 156, 158, 159, 161, 162, 164, ...                320    0   \n",
       "17  [187, 188, 189, 191, 192, 194, 195, 197, 198, ...                320    0   \n",
       "18  [220, 221, 222, 224, 225, 226, 228, 229, 231, ...                320    0   \n",
       "19  [252, 253, 254, 255, 257, 258, 259, 261, 262, ...                320    0   \n",
       "20  [282, 283, 284, 286, 287, 288, 290, 291, 292, ...                320    0   \n",
       "\n",
       "      x1   y0   y1  z0   z1  \n",
       "0   2496    6  265  86  238  \n",
       "1   2496    6  265  86  238  \n",
       "2   2496    6  265  86  238  \n",
       "3   2496    6  265  86  238  \n",
       "4   2496    6  265  86  238  \n",
       "5   2496    6  265  86  238  \n",
       "6   2496    6  265  86  238  \n",
       "7   4336  109  274  65  204  \n",
       "8   4336  109  274  65  204  \n",
       "9   4336  109  274  65  204  \n",
       "10  4336  109  274  65  204  \n",
       "11  4336  109  274  65  204  \n",
       "12  4336  109  274  65  204  \n",
       "13  4336  109  274  65  204  \n",
       "14  3656    3  249  71  225  \n",
       "15  3656    3  249  71  225  \n",
       "16  3656    3  249  71  225  \n",
       "17  3656    3  249  71  225  \n",
       "18  3656    3  249  71  225  \n",
       "19  3656    3  249  71  225  \n",
       "20  3656    3  249  71  225  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertebrae_df = pd.DataFrame(vertebrae_df_list, columns=[\"study_cid\", \"StudyInstanceUID\", \"cid\", \"slice_num_list\", \\\n",
    "    \"before_image_size\", \"x0\", \"x1\", \"y0\", \"y1\", \"z0\", \"z1\"])\n",
    "vertebrae_df.to_pickle(f\"{datadir}/vertebrae_df_test.pkl\")    \n",
    "vertebrae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "datadir = '/root/input/rsna-2022-cervical-spine-fracture-detection'\n",
    "libdir = '/root/workspace/RSNA2022RAWE'\n",
    "outputdir = '/root/workspace/RSNA2022RAWE'\n",
    "otherdir = '/root/workspace/RSNA2022RAWE'\n",
    "train_bs_ = 4\n",
    "valid_bs_ = 8\n",
    "num_workers_ = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU'\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    fold_num=5\n",
    "\n",
    "    target_cols=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\"]\n",
    "    num_classes=7\n",
    "\n",
    "    accum_iter=1\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] # [0.485, 0.456, 0.406] [0.4824, 0.4824, 0.4824]\n",
    "    normalize_std=[0.22, 0.22, 0.22] # [0.229, 0.224, 0.225] [0.22, 0.22, 0.22]\n",
    "    \n",
    "    suffix=\"401\" \n",
    "    fold_list=[0] \n",
    "    epochs=25\n",
    "    model_arch=\"resnet50d\" # tf_efficientnetv2_s, resnest50d\n",
    "    img_size=320\n",
    "    optimizer=\"AdamW\"\n",
    "    scheduler=\"CosineAnnealingLR\"\n",
    "    loss_fn=\"BCEWithLogitsLoss\"\n",
    "    scheduler_warmup=\"GradualWarmupSchedulerV3\" \n",
    "\n",
    "    warmup_epo=1\n",
    "    warmup_factor = 10\n",
    "    T_max= epochs-warmup_epo-2 if scheduler_warmup==\"GradualWarmupSchedulerV2\" else \\\n",
    "           epochs-warmup_epo-1 if scheduler_warmup==\"GradualWarmupSchedulerV3\" else epochs-1 # CosineAnnealingLR\n",
    "    \n",
    "    seq_len = 24\n",
    "    lr=5e-4\n",
    "    min_lr=1e-6 \n",
    "    weight_decay=0\n",
    "    dropout=0.1\n",
    "\n",
    "    gpu_parallel=False\n",
    "    n_early_stopping=4\n",
    "    debug=False\n",
    "    multihead=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; \n",
    "    \n",
    "import ast\n",
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import gc \n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(f'{datadir}/vertebrae_df_test.pkl')\n",
    "submission_df = pd.read_csv(f'{datadir}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_cid</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>cid</th>\n",
       "      <th>slice_num_list</th>\n",
       "      <th>before_image_size</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "      <td>[46, 47, 49, 50, 52, 54, 55, 57, 58, 60, 62, 6...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_2</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_3</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>3</td>\n",
       "      <td>[116, 117, 118, 119, 120, 121, 122, 123, 125, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_4</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>4</td>\n",
       "      <td>[142, 143, 144, 145, 146, 147, 148, 149, 150, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_5</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>5</td>\n",
       "      <td>[167, 167, 168, 169, 170, 171, 172, 173, 174, ...</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>86</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     study_cid           StudyInstanceUID  cid  \\\n",
       "0  1.2.826.0.1.3680043.22327_1  1.2.826.0.1.3680043.22327    1   \n",
       "1  1.2.826.0.1.3680043.22327_2  1.2.826.0.1.3680043.22327    2   \n",
       "2  1.2.826.0.1.3680043.22327_3  1.2.826.0.1.3680043.22327    3   \n",
       "3  1.2.826.0.1.3680043.22327_4  1.2.826.0.1.3680043.22327    4   \n",
       "4  1.2.826.0.1.3680043.22327_5  1.2.826.0.1.3680043.22327    5   \n",
       "\n",
       "                                      slice_num_list  before_image_size  x0  \\\n",
       "0  [46, 47, 49, 50, 52, 54, 55, 57, 58, 60, 62, 6...                320   0   \n",
       "1  [1, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98...                320   0   \n",
       "2  [116, 117, 118, 119, 120, 121, 122, 123, 125, ...                320   0   \n",
       "3  [142, 143, 144, 145, 146, 147, 148, 149, 150, ...                320   0   \n",
       "4  [167, 167, 168, 169, 170, 171, 172, 173, 174, ...                320   0   \n",
       "\n",
       "     x1  y0   y1  z0   z1  \n",
       "0  2496   6  265  86  238  \n",
       "1  2496   6  265  86  238  \n",
       "2  2496   6  265  86  238  \n",
       "3  2496   6  265  86  238  \n",
       "4  2496   6  265  86  238  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    VERSION = \"1.7\"\n",
    "    CP_V = \"36\" if ENV == \"colab\" else \"37\"\n",
    "    wheel = f\"torch_xla-{VERSION}-cp{CP_V}-cp{CP_V}m-linux_x86_64.whl\"\n",
    "    url = f\"https://storage.googleapis.com/tpu-pytorch/wheels/{wheel}\"\n",
    "    !pip3 -q install cloud-tpu-client==0.10 $url\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.train_bs = CFG.train_bs // CFG.nprocs\n",
    "    device = xm.xla_device()\n",
    "    \n",
    "elif CFG.device == \"GPU\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        study_id = row[\"StudyInstanceUID\"]\n",
    "        slice_num_list = row['slice_num_list']\n",
    "        slice_list = []\n",
    "        for s_num in slice_num_list:\n",
    "            path = f\"{datadir}/test_images/{study_id}/{s_num}.dcm\"\n",
    "            img = load_dicom(path)\n",
    "            if len(slice_list) == 0:\n",
    "                imgh = img.shape[0]\n",
    "                imgw = img.shape[1]\n",
    "            elif img.shape != (imgh, imgw):\n",
    "                img = cv2.resize(img,(imgh,imgw))\n",
    "\n",
    "            slice_list.append(img)\n",
    "        for _ in range(CFG.seq_len - len(slice_list)):\n",
    "            slice_list.append(np.zeros((imgh,imgw)))\n",
    "\n",
    "        image = np.stack(slice_list, axis=2) # 512*512*seq_len; 0-1\n",
    "\n",
    "        assert image.shape == (imgh, imgw, CFG.seq_len)\n",
    "\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1)) # seq_len*img_size*img_size; 0-1\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n",
    "    CenterCrop, Resize, RandomCrop, GaussianBlur, JpegCompression, Downscale, ElasticTransform\n",
    ")\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "dataset_show = TestDataset(\n",
    "    test_df,\n",
    "    transform=get_transforms(data='light_train') # None, get_transforms(data='check')\n",
    "    )\n",
    "rcParams['figure.figsize'] = 30,20\n",
    "\n",
    "for i in range(4):\n",
    "    f, axarr = plt.subplots(1,5)\n",
    "    idx = np.random.randint(0, len(dataset_show))\n",
    "    img= dataset_show[idx]\n",
    "    # axarr[p].imshow(img) # transform=None\n",
    "    axarr[0].imshow(img[0]); plt.axis('OFF');\n",
    "    axarr[1].imshow(img[1]); plt.axis('OFF');\n",
    "    axarr[2].imshow(img[2]); plt.axis('OFF');\n",
    "    axarr[3].imshow(img[3]); plt.axis('OFF');\n",
    "    axarr[4].imshow(img[4]); plt.axis('OFF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from itertools import repeat\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict, Optional\n",
    " \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "    \n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        return attn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, hidden_dim=256, seq_len=24, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.model = timm.create_model(model_arch, in_chans=1, pretrained=pretrained)\n",
    "\n",
    "        if 'efficientnet' in CFG.model_arch:\n",
    "            cnn_feature = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "        elif \"res\" in CFG.model_arch:\n",
    "            cnn_feature = self.model.fc.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.fc = nn.Identity()\n",
    "            self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(cnn_feature, hidden_dim, 2, batch_first=True, bidirectional=True)\n",
    "        self.mlp_attention_layer = MLPAttentionNetwork(2 * hidden_dim)\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(CFG.dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "\n",
    "    def forward(self, x): # (B, seq_len, H, W)\n",
    "        bs = x.size(0) \n",
    "        x = x.reshape(bs*self.seq_len, 1, x.size(2), x.size(3)) # (B*seq_len, 1, H, W)\n",
    "        features = self.model(x)   \n",
    "        if \"res\" in CFG.model_arch:                             \n",
    "            features = self.pooling(features).view(bs*self.seq_len, -1) # (B*seq_len, cnn_feature)\n",
    "        features = self.spatialdropout(features)                # (B*seq_len, cnn_feature)\n",
    "        # print(features.shape)\n",
    "        features = features.reshape(bs, self.seq_len, -1)       # (B, seq_len, cnn_feature)\n",
    "        features, _ = self.gru(features)                        # (B, seq_len, hidden_dim*2)\n",
    "        atten_out = self.mlp_attention_layer(features)          # (B, hidden_dim*2)\n",
    "        pred = self.logits(atten_out)                           # (B, 1)\n",
    "        pred = pred.view(bs, -1)                                # (B, 1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init GRU(2048, 256, num_layers=2, batch_first=True, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "model = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=24, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size, stride, padding,\n",
    "        bias=False, use_bn=True, activ=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels,\n",
    "        out_channels_list,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadResNet200D(nn.Module):\n",
    "    def __init__(self, out_dims_head=[3, 4, 3, 1],  pretrained=False):\n",
    "        self.base_name = \"resnet200d_320\"\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadResNet200D, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(self.base_name, num_classes=sum(out_dims_head), pretrained=False)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        if pretrained:\n",
    "            pretrained_model_path = CFG.student\n",
    "            state_dict = dict()\n",
    "            for k, v in torch.load(pretrained_model_path, map_location='cpu')[\"model\"].items():\n",
    "                if k[:6] == \"model.\":\n",
    "                    k = k.replace(\"model.\", \"\")\n",
    "                state_dict[k] = v\n",
    "            base_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        hs = [getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return None, None, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.accum_iter > 1:\n",
    "            loss = loss / CFG.accum_iter\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            cusprint('EVAL: [{0}/{1}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                ))\n",
    "\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss & optimizer & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RSNAClassifier(\n",
       "  (model): ResNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): Identity()\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (spatialdropout): SpatialDropout()\n",
       "  (gru): GRU(2048, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (mlp_attention_layer): MLPAttentionNetwork(\n",
       "    (proj_w): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (proj_v): Linear(in_features=512, out_features=1, bias=False)\n",
       "  )\n",
       "  (logits): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "PATH='/root/workspace/RSNA2022RAWE/resnet50d_401_fold0_epoch11.pth'\n",
    "if torch.cuda.is_available():\n",
    "    checkpoint = torch.load(PATH)\n",
    "else:\n",
    "    checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load states\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# Evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_df, transform=get_transforms(data='valid'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.valid_bs, shuffle=False,num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "preds = []\n",
    "for step, (images) in enumerate(test_loader):\n",
    "    images = images.to(device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "        y_preds = y_preds.squeeze(1)\n",
    "    preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    \n",
    "predictions = np.concatenate(preds)\n",
    "\n",
    "test_df['Preds'] = predictions * 100\n",
    "\n",
    "test_df.to_csv(f\"{outputdir}/test_preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b79a61544c9a744d09395b396d14bdc3ab2980641b64ddb1c7bc6d7b892900a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
