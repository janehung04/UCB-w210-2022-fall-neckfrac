{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n#! pip install -U python-gdcm","metadata":{"execution":{"iopub.status.busy":"2022-10-22T18:39:30.742862Z","iopub.execute_input":"2022-10-22T18:39:30.743288Z","iopub.status.idle":"2022-10-22T18:39:55.807293Z","shell.execute_reply.started":"2022-10-22T18:39:30.743257Z","shell.execute_reply":"2022-10-22T18:39:55.806057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python -m pip download python-gdcm -q\n#!python -m pip download pylibjpeg-libjpeg -q\n#!python -m pip download pylibjpeg -q","metadata":{"execution":{"iopub.status.busy":"2022-10-22T19:21:06.608872Z","iopub.execute_input":"2022-10-22T19:21:06.609236Z","iopub.status.idle":"2022-10-22T19:21:10.266045Z","shell.execute_reply.started":"2022-10-22T19:21:06.609208Z","shell.execute_reply":"2022-10-22T19:21:10.264520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/kerasapplications')\nsys.path.append('../input/efficientnet-keras-source-code/')\nsys.path.append('../input/python-gdcm/')\nimport keras_applications\nimport efficientnet.tfkeras as efficientnet","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":6.552897,"end_time":"2022-08-14T14:38:57.371965","exception":false,"start_time":"2022-08-14T14:38:50.819068","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-24T05:38:48.875646Z","iopub.execute_input":"2022-10-24T05:38:48.876062Z","iopub.status.idle":"2022-10-24T05:38:48.882700Z","shell.execute_reply.started":"2022-10-24T05:38:48.876031Z","shell.execute_reply":"2022-10-24T05:38:48.881155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{sys.executable} -m pip install '../input/mypackage/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl' -q\n!{sys.executable} -m pip install '../input/mypackage/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl' -q\n!{sys.executable} -m pip install '../input/mypackage/python_gdcm-3.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl' -q\n!{sys.executable} -m pip install '../input/mypackage/pylibjpeg-1.4.0-py3-none-any.whl' -q","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:38:51.926359Z","iopub.execute_input":"2022-10-24T05:38:51.926771Z","iopub.status.idle":"2022-10-24T05:40:59.171692Z","shell.execute_reply.started":"2022-10-24T05:38:51.926738Z","shell.execute_reply":"2022-10-24T05:40:59.169931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport cv2\nimport os\nfrom os import listdir\nimport re\nimport gc\n\nimport gdcm\nimport pydicom as dicom\nfrom pydicom import dcmread\nimport pylibjpeg\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom pydicom.data import get_testdata_files\n\nfrom path import Path\nimport scipy.ndimage\nfrom tqdm import tqdm\nimport nibabel as nib\nfrom pprint import pprint\nfrom time import time\nimport itertools\nfrom skimage import measure \nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom glob import glob\nimport warnings\nimport dask.array as da\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import losses, callbacks\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow_hub as hub\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\n\nfrom PIL import Image as im\nimport traceback\n\nimport imageio\n\n\n#from efficientnet_v2 import EfficientNetV2S\n%matplotlib inline\nsns.set(style='darkgrid', font_scale=1.6)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:40:59.177145Z","iopub.execute_input":"2022-10-24T05:40:59.177557Z","iopub.status.idle":"2022-10-24T05:41:00.513428Z","shell.execute_reply.started":"2022-10-24T05:40:59.177508Z","shell.execute_reply":"2022-10-24T05:41:00.512419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bad = np.array([['1.2.826.0.1.3680043.10197_C1', '1.2.826.0.1.3680043.10197','C1'],['1.2.826.0.1.3680043.10454_C1', '1.2.826.0.1.3680043.10454','C1'],['1.2.826.0.1.3680043.10690_C1', '1.2.826.0.1.3680043.10690','C1']], dtype=np.object)\n\ntrain_df = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\ntest_df = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/test.csv\")\n\ntrain_dir = '../input/rsna-2022-cervical-spine-fracture-detection/train_images'\ntest_dir = '../input/rsna-2022-cervical-spine-fracture-detection/test_images'\nfirst_image = os.path.join(test_dir, test_df['StudyInstanceUID'].iloc[0])\n\nnew_submission = []\nmeans = train_df.median(numeric_only=True).to_dict()\nmeans = dict(zip(train_df.columns[1:], np.average(train_df[train_df.columns[1:]], axis=0, weights=train_df[\"patient_overall\"] + 1)))\nprediction_type = test_df['prediction_type'].tolist()\nsubmission = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/sample_submission.csv')\nfor i in range(len(submission)):        \n    new_submission.append(means[prediction_type[i]])\nsubmission['fractured'] = new_submission\n\n\nif(test_df.values[0][0] == bad[0][0]): test_df = pd.DataFrame({\"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'], \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'], \"prediction_type\": [\"C1\", \"C1\", \"C1\"]})  \nprediction_type_mapping = test_df['prediction_type'].map({'C1': 0, 'C2': 1, 'C3': 2, 'C4': 3, 'C5': 4, 'C6': 5, 'C7': 6}).values","metadata":{"_kg_hide-output":true,"papermill":{"duration":0.054187,"end_time":"2022-08-14T14:38:58.390389","exception":false,"start_time":"2022-08-14T14:38:58.336202","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-10-24T05:41:00.515209Z","iopub.execute_input":"2022-10-24T05:41:00.516321Z","iopub.status.idle":"2022-10-24T05:41:00.575137Z","shell.execute_reply.started":"2022-10-24T05:41:00.516279Z","shell.execute_reply":"2022-10-24T05:41:00.573655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading Scans\ndef atoi(text):\n    return int(text) if text.isdigit() else text\ndef natural_keys(text):\n    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n\n# Load the scans in given folder path\ndef load_scan(path):\n    \n    dcm_paths = glob(f\"{path}/*\")\n    dcm_paths.sort(key=natural_keys)\n    \n    patient_scan = [dicom.dcmread(paths) for paths in dcm_paths]\n    \n    return patient_scan","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:41:00.579102Z","iopub.execute_input":"2022-10-24T05:41:00.579503Z","iopub.status.idle":"2022-10-24T05:41:00.587777Z","shell.execute_reply.started":"2022-10-24T05:41:00.579467Z","shell.execute_reply":"2022-10-24T05:41:00.586178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pixels_hu(slices):\n   \n    image = np.stack([cv2.resize(s.pixel_array,(256,256),interpolation = cv2.INTER_NEAREST) for s in slices])\n    #image = np.stack([cv2.cvtColor(s.pixel_array.reshape(512,512),cv2.COLOR_GRAY2RGB) for s in slices])\n\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16) #int16\n    image = da.from_array(image) #Using Dask to speed up processing\n    \n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image <= -1000] = 0\n    \n    # Convert to Hounsfield units (HU)\n        \n    intercept = da.from_array([slices[slice_number].RescaleIntercept for slice_number in range(len(slices))])\n    slope = da.from_array([slices[slice_number].RescaleSlope for slice_number in range(len(slices))])\n    \n    intercept=intercept.reshape((-1,1,1))\n    slope=slope.reshape((-1,1,1))\n    #print(slope.shape)\n    #print(image.shape)\n    image= slope * image.astype(\"float64\")\n    #print(image.shape)   \n    image+= intercept\n    #print(image.shape)      \n    return image.astype(\"int16\")","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:41:00.589089Z","iopub.execute_input":"2022-10-24T05:41:00.589500Z","iopub.status.idle":"2022-10-24T05:41:00.601472Z","shell.execute_reply.started":"2022-10-24T05:41:00.589465Z","shell.execute_reply":"2022-10-24T05:41:00.600154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MIN_BOUND = 150.0\nMAX_BOUND = 2050.0\n    \ndef normalize(image):\n    image = (image - MIN_BOUND)*255.0 / (MAX_BOUND - MIN_BOUND)\n    image[image>255] = 255.\n    image[image<0] = 255.\n    \n    image = image.astype(np.int16)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:41:00.602989Z","iopub.execute_input":"2022-10-24T05:41:00.603482Z","iopub.status.idle":"2022-10-24T05:41:00.620385Z","shell.execute_reply.started":"2022-10-24T05:41:00.603431Z","shell.execute_reply":"2022-10-24T05:41:00.619080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_whole = keras.models.load_model('../input/effnet-whole-model-large/effnet_whole_128.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-24T02:14:23.098223Z","iopub.execute_input":"2022-10-24T02:14:23.098514Z","iopub.status.idle":"2022-10-24T02:14:33.510853Z","shell.execute_reply.started":"2022-10-24T02:14:23.098486Z","shell.execute_reply":"2022-10-24T02:14:33.509159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_classification = keras.models.load_model('../input/effnetclassificationmodel/Classifier_v3.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-23T02:39:41.332142Z","iopub.execute_input":"2022-10-23T02:39:41.332563Z","iopub.status.idle":"2022-10-23T02:39:52.433919Z","shell.execute_reply.started":"2022-10-23T02:39:41.332530Z","shell.execute_reply":"2022-10-23T02:39:52.432851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Generator\n\n- Yields only image samples","metadata":{"papermill":{"duration":0.012384,"end_time":"2022-08-14T14:39:32.209528","exception":false,"start_time":"2022-08-14T14:39:32.197144","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def RSNATestGenerator(test_df, batch_size, infinite = True, base_path = test_dir):\n    while 1:        \n        testset=[]\n        testidt=[]\n        for i in (range(len(test_df))):        \n            if type(test_df) is list: idt = test_df[i]\n            else: idt = test_df['StudyInstanceUID'].iloc[i]\n            path = os.path.join(base_path, idt)\n            \n            patient_scan=load_scan(path)\n            patient_hu=get_pixels_hu(patient_scan)\n            patient_hu_normalised=normalize(patient_hu)\n            \n            if os.path.exists(path):\n                 for j in range(len(os.listdir(path))):\n                    img = patient_hu_normalised[j]\n                    img = np.array(img)\n                    img=cv2.resize(img,(128, 128))\n                    image=img_to_array(img)\n                    image=image/255.0\n                    testset+=[image]\n                    testidt+=[idt]\n                    if len(testset) == batch_size:                        \n                        yield np.array(testset)\n                        testset = []\n        if len(testset) > 0: yield np.array(testset)\n        if not infinite: break","metadata":{"_kg_hide-output":true,"papermill":{"duration":0.024957,"end_time":"2022-08-14T14:39:32.247245","exception":false,"start_time":"2022-08-14T14:39:32.222288","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-10-24T05:41:00.622076Z","iopub.execute_input":"2022-10-24T05:41:00.623273Z","iopub.status.idle":"2022-10-24T05:41:00.634325Z","shell.execute_reply.started":"2022-10-24T05:41:00.623216Z","shell.execute_reply":"2022-10-24T05:41:00.632963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_idx, val_idx in StratifiedKFold(5).split(train_df, train_df['patient_overall']):\n    i=1\n    K.clear_session()\n    model = model_whole\n    \n    try: # the best we can do at the moment..\n        preds = model.predict_generator(RSNATestGenerator(test_df, min(len(test_df), 64), infinite = False, base_path = test_dir), steps = max((len(test_df) // 64), 1))\n        \n        new_preds = []\n        for pred_idx in range(len(preds)):\n            new_preds.append(preds[pred_idx][prediction_type_mapping[pred_idx]])\n        # submission['fractured'] += preds[:, prediction_type_mapping] / 5\n        submission['fractured'] += np.array(new_preds) / 5\n        \n    except: traceback.print_exc()    ","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:41:00.635874Z","iopub.execute_input":"2022-10-24T05:41:00.636604Z","iopub.status.idle":"2022-10-24T05:42:48.721964Z","shell.execute_reply.started":"2022-10-24T05:41:00.636535Z","shell.execute_reply":"2022-10-24T05:42:48.720846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fracture_threshold = 0.55\n\n# preds = model.predict_generator(RSNATestGenerator(test_df, \n#                                                   min(len(test_df), 64), \n#                                                   infinite = False, \n#                                                   base_path = test_dir),\n#                                 steps = max((len(test_df) // 64), 1))\n        \n# new_preds = []\n# for i in preds:\n#     new_pred_j = []\n#     overall = 0\n#     for j in i:\n#         if j>fracture_threshold:\n#             overall = 1\n#         new_pred_j.append(j)\n        \n#     new_pred_j.append(overall)\n    \n#     new_preds.append(new_pred_j)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-23T02:44:37.702166Z","iopub.execute_input":"2022-10-23T02:44:37.702576Z","iopub.status.idle":"2022-10-23T02:44:49.173290Z","shell.execute_reply.started":"2022-10-23T02:44:37.702544Z","shell.execute_reply":"2022-10-23T02:44:49.172176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_submission = pd.DataFrame(columns = ['row_id', 'fractured'])\n\n# test_idt = []\n\n# for i in (range(len(test_df))):        \n#     if type(test_df) is list: idt = test_df[i]\n#     else: idt = test_df['StudyInstanceUID'].iloc[i]\n#     test_idt.append(idt)\n\n# row_id = []\n# fracture = []\n# for i in range(len(test_idt)):\n#     for j in range(8):\n#         if j != 7:\n#             row_id.append(f'{test_idt[i]}_C{j+1}')\n#             fracture.append(new_preds[i][j])\n            \n#         if j ==7:\n#             row_id.append(f'{test_idt[i]}_patient_overall')\n#             fracture.append(new_preds[i][j])\n# df_submission['row_id'] = row_id\n# df_submission['fractured'] = fracture\n# df_submission","metadata":{"execution":{"iopub.status.busy":"2022-10-23T02:44:50.874130Z","iopub.execute_input":"2022-10-23T02:44:50.875065Z","iopub.status.idle":"2022-10-23T02:44:50.902944Z","shell.execute_reply.started":"2022-10-23T02:44:50.875024Z","shell.execute_reply":"2022-10-23T02:44:50.901842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Submission","metadata":{"papermill":{"duration":0.053456,"end_time":"2022-08-14T14:54:59.031614","exception":false,"start_time":"2022-08-14T14:54:58.978158","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# submission = pd.DataFrame(columns=['row_id', 'fractured'])\n# submission['row_id'] = test_df['row_id']\n# submission['fractured'] =  submission['row_id'].map(df_submission.set_index('row_id')['fractured'])\n# print(submission.head())\n# submission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.069591,"end_time":"2022-08-14T14:54:59.152542","exception":false,"start_time":"2022-08-14T14:54:59.082951","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-10-23T02:44:54.803789Z","iopub.execute_input":"2022-10-23T02:44:54.804267Z","iopub.status.idle":"2022-10-23T02:44:54.813737Z","shell.execute_reply.started":"2022-10-23T02:44:54.804230Z","shell.execute_reply":"2022-10-23T02:44:54.812149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:42:48.738386Z","iopub.execute_input":"2022-10-24T05:42:48.739176Z","iopub.status.idle":"2022-10-24T05:42:48.758422Z","shell.execute_reply.started":"2022-10-24T05:42:48.739137Z","shell.execute_reply":"2022-10-24T05:42:48.757487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T05:42:48.723452Z","iopub.execute_input":"2022-10-24T05:42:48.723973Z","iopub.status.idle":"2022-10-24T05:42:48.734808Z","shell.execute_reply.started":"2022-10-24T05:42:48.723937Z","shell.execute_reply":"2022-10-24T05:42:48.733609Z"},"trusted":true},"execution_count":null,"outputs":[]}]}