{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-09T21:16:22.960135Z","iopub.execute_input":"2022-10-09T21:16:22.960659Z","iopub.status.idle":"2022-10-09T21:16:22.967362Z","shell.execute_reply.started":"2022-10-09T21:16:22.960610Z","shell.execute_reply":"2022-10-09T21:16:22.966112Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Load Packages","metadata":{}},{"cell_type":"code","source":"!pip install warmup_scheduler\n!pip install monai\n!pip install -U \"python-gdcm\" pydicom pylibjpeg\n!pip install -U torchvision\n!pip install opencv-python","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:16:22.969983Z","iopub.execute_input":"2022-10-09T21:16:22.970535Z","iopub.status.idle":"2022-10-09T21:17:20.127769Z","shell.execute_reply.started":"2022-10-09T21:16:22.970494Z","shell.execute_reply":"2022-10-09T21:17:20.126263Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: warmup_scheduler in /opt/conda/lib/python3.7/site-packages (0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: monai in /opt/conda/lib/python3.7/site-packages (1.0.0)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from monai) (1.12.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai) (1.21.6)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->monai) (4.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: python-gdcm in /opt/conda/lib/python3.7/site-packages (3.0.19)\nRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.0)\nRequirement already satisfied: pylibjpeg in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.13.1)\nRequirement already satisfied: torch==1.12.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.12.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision) (4.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.6.15.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.5.4.60)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Libraries\nimport os\nimport re\nimport gc\nimport cv2\nimport wandb\nimport PIL\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\nimport random\nimport math\nimport shutil\nfrom glob import glob\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom time import time\nimport warnings\nimport itertools\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib import cm\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap\nfrom matplotlib.patches import Rectangle\nfrom IPython.display import display_html\nplt.rcParams.update({'font.size': 16})\n\nfrom pathlib import Path\n\n# .dcm handling\nimport pydicom\nimport nibabel as nib\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n# Environment check\nwarnings.filterwarnings(\"ignore\")\n\n# set seaborn theme\nsns.set_theme(style=\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.131137Z","iopub.execute_input":"2022-10-09T21:17:20.131755Z","iopub.status.idle":"2022-10-09T21:17:20.145150Z","shell.execute_reply.started":"2022-10-09T21:17:20.131693Z","shell.execute_reply":"2022-10-09T21:17:20.143966Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# PyTorch\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nimport torchvision \nimport torchvision.transforms as transforms\nfrom warmup_scheduler import GradualWarmupScheduler\nimport albumentations\n\nfrom sklearn.model_selection import GroupKFold, train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n\n# MONAI 3D\nfrom monai.transforms import Randomizable, apply_transform\nfrom monai.transforms import Compose, Resize, ScaleIntensity, ToTensor, RandAffine\nfrom monai.networks.nets import densenet","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.146336Z","iopub.execute_input":"2022-10-09T21:17:20.146703Z","iopub.status.idle":"2022-10-09T21:17:20.167548Z","shell.execute_reply.started":"2022-10-09T21:17:20.146673Z","shell.execute_reply":"2022-10-09T21:17:20.166089Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Helper Function","metadata":{}},{"cell_type":"code","source":"def read_data():\n    '''Reads in all .csv files.'''\n    \n    train = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n    train_bbox = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv\")\n    test = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/test.csv\")\n    ss = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/sample_submission.csv\")\n    \n    return train, train_bbox, test, ss\n\ndef get_csv_info(csv, name=\"Default\"):\n    '''Prints main information for the speciffied .csv file.'''\n    \n    print(f\"=== {name} ===\")\n    print(f\"Shape:\", csv.shape)\n    print(f\"Missing Values:\", csv.isna().sum().sum(), \"total missing datapoints.\")\n    print(\"Columns:\", list(csv.columns), \"\\n\")\n    \n    display_html(csv.head())\n    print(\"\\n\")\n    \ndef set_seed(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)  \n    torch.cuda.manual_seed(seed)  \n    torch.cuda.manual_seed_all(seed)  \n    torch.backends.cudnn.deterministic = True\n    \ndef atoi(text):\n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n    '''\n    alist.sort(key=natural_keys) sorts in human order\n    http://nedbatchelder.com/blog/200712/human_sorting.html\n    (See Toothy's implementation in the comments)\n    '''\n    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n\n# some patients have reverse order for the CT scan, so have a function to check\ndef check_reverse_required(path):\n    paths = list(path.glob('*'))\n    paths.sort(key=lambda x:int(x.stem))\n    z_first = pydicom.dcmread(paths[0]).get(\"ImagePositionPatient\")[-1]\n    z_last = pydicom.dcmread(paths[-1]).get(\"ImagePositionPatient\")[-1]\n    if z_last < z_first:\n        return False\n    return True\n\npaths = {\n    'train': Path('../input/rsna-2022-cervical-spine-fracture-detection/train.csv'),\n    'train_bbox': Path('../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv'),\n    'train_images': Path('../input/rsna-2022-cervical-spine-fracture-detection/train_images'),\n    'train_nifti_segments': Path('../input/rsna-2022-cervical-spine-fracture-detection/segmentations'),\n    'test_df': Path('../input/rsna-2022-cervical-spine-fracture-detection/test.csv'),\n    'test_images': Path('../input/rsna-2022-cervical-spine-fracture-detection/test_images')\n}\n\n# === 🐝 W&B ===\ndef save_dataset_artifact(run_name, artifact_name, path, data_type=\"dataset\"):\n    '''Saves dataset to W&B Artifactory.\n    run_name: name of the experiment\n    artifact_name: under what name should the dataset be stored\n    path: path to the dataset'''\n    \n    run = wandb.init(project='RSNA_SpineFructure', \n                     name=run_name, \n                     config=CONFIG)\n    artifact = wandb.Artifact(name=artifact_name, \n                              type=data_type)\n    artifact.add_file(path)\n\n    wandb.log_artifact(artifact)\n    wandb.finish()\n    print(\"Artifact has been saved successfully.\")\n\ndef create_wandb_plot(x_data=None, y_data=None, x_name=None, y_name=None, title=None, log=None, plot=\"line\"):\n    '''Create and save lineplot/barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    \n    if plot == \"line\":\n        wandb.log({log : wandb.plot.line(table, x_name, y_name, title=title)})\n    elif plot == \"bar\":\n        wandb.log({log : wandb.plot.bar(table, x_name, y_name, title=title)})\n    elif plot == \"scatter\":\n        wandb.log({log : wandb.plot.scatter(table, x_name, y_name, title=title)})\n        \ndef create_wandb_hist(x_data=None, x_name=None, title=None, log=None):\n    '''Create and save histogram in W&B Environment.\n    x_data: Pandas Series containing x values\n    x_name: strings containing axis name\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[x] for x in x_data]\n    table = wandb.Table(data=data, columns=[x_name])\n    wandb.log({log : wandb.plot.histogram(table, x_name, title=title)})","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.171224Z","iopub.execute_input":"2022-10-09T21:17:20.171746Z","iopub.status.idle":"2022-10-09T21:17:20.196250Z","shell.execute_reply.started":"2022-10-09T21:17:20.171704Z","shell.execute_reply":"2022-10-09T21:17:20.194947Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# custom weighted loss function\n# From: https://www.kaggle.com/code/andradaolteanu/rsna-fracture-detect-pytorch-densenet-train#2.-Data-Split\ndef get_custom_loss(logits, targets):\n    \n    # Compute the weights\n    weights = targets * competition_weights['+'] + (1 - targets) * competition_weights['-']\n    \n    # Losses on label and exam level\n    L = torch.zeros(targets.shape, device=DEVICE)\n\n    w = weights\n    y = targets\n    p = logits\n    eps=1e-8\n\n    for i in range(L.shape[0]):\n        for j in range(L.shape[1]):\n            L[i, j] = -w[i, j] * (\n                y[i, j] * math.log(p[i, j] + eps) +\n                (1 - y[i, j]) * math.log(1 - p[i, j] + eps))\n            \n    # Average Loss on Exam (or patient)\n    Exams_Loss = torch.div(torch.sum(L, dim=1), torch.sum(w, dim=1))\n    \n    return Exams_Loss","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.197802Z","iopub.execute_input":"2022-10-09T21:17:20.198180Z","iopub.status.idle":"2022-10-09T21:17:20.215904Z","shell.execute_reply.started":"2022-10-09T21:17:20.198145Z","shell.execute_reply":"2022-10-09T21:17:20.214941Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Set up parameters","metadata":{}},{"cell_type":"code","source":"# Environment check\nwarnings.filterwarnings(\"ignore\")\n# os.environ[\"WANDB_SILENT\"] = \"true\"\nCONFIG = {'competition': 'RSNA_SpineFracture', '_wandb_kernel': 'aot'}\n\n# set seed\nset_seed(0)\n\n# set GPU\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Device:\", DEVICE)\n\n# Kaggle Notebook Setup\nDF_SIZE = 0.01\nN_SPLITS = 5\nKERNEL_TYPE = 'densenet121_baseline'\nIMG_RESIZE = 100\nSTACK_RESIZE = 50\nuse_amp = False\nNUM_WORKERS = 1\nBATCH_SIZE = 2\nLR = 0.05\nOUT_DIM = 8\nEPOCHS = 2\n\ntarget_cols = ['C1', 'C2', 'C3', \n               'C4', 'C5', 'C6', 'C7',\n               'patient_overall']\n\ncompetition_weights = {\n    '-' : torch.tensor([1, 1, 1, 1, 1, 1, 1, 7], dtype=torch.float, device=DEVICE),\n    '+' : torch.tensor([2, 2, 2, 2, 2, 2, 2, 14], dtype=torch.float, device=DEVICE),\n}","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.217822Z","iopub.execute_input":"2022-10-09T21:17:20.218327Z","iopub.status.idle":"2022-10-09T21:17:20.234189Z","shell.execute_reply.started":"2022-10-09T21:17:20.218277Z","shell.execute_reply":"2022-10-09T21:17:20.233060Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Device: cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"np.random.seed(0)\n\ndf = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n\n# reverse the slices\ndf['segment_path'] = df['StudyInstanceUID'].map(lambda x: paths['train_images']/x)\ndf['reverse_required'] = df['segment_path'].map(check_reverse_required)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:20.235685Z","iopub.execute_input":"2022-10-09T21:17:20.236021Z","iopub.status.idle":"2022-10-09T21:17:35.819985Z","shell.execute_reply.started":"2022-10-09T21:17:20.235985Z","shell.execute_reply":"2022-10-09T21:17:35.818651Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0   \n1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0   \n2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0   \n3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0   \n4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0   \n\n                                        segment_path  reverse_required  \n0  ../input/rsna-2022-cervical-spine-fracture-det...             False  \n1  ../input/rsna-2022-cervical-spine-fracture-det...              True  \n2  ../input/rsna-2022-cervical-spine-fracture-det...             False  \n3  ../input/rsna-2022-cervical-spine-fracture-det...             False  \n4  ../input/rsna-2022-cervical-spine-fracture-det...              True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StudyInstanceUID</th>\n      <th>patient_overall</th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>segment_path</th>\n      <th>reverse_required</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2.826.0.1.3680043.6200</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.2.826.0.1.3680043.27262</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2.826.0.1.3680043.21561</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.2.826.0.1.3680043.12351</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.2.826.0.1.3680043.1363</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Sample down df\ninstances = df.StudyInstanceUID.unique().tolist()\ninstances = random.sample(instances, k=int(len(instances)*DF_SIZE))\ndf = df[df[\"StudyInstanceUID\"].isin(instances)].reset_index(drop=True)\nprint(\"Dataframe size:\", df.shape)\n\n# Create folds\nkfold = GroupKFold(n_splits=N_SPLITS)\ndf['fold'] = -1\n\n# Append fold\nfor k, (_, valid_i) in enumerate(kfold.split(df,\n                                             groups=df.StudyInstanceUID)):\n    df.loc[valid_i, 'fold'] = k\n    \nprint(\"K Folds Count:\")\ndf[\"fold\"].value_counts(","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.822133Z","iopub.execute_input":"2022-10-09T21:17:35.822639Z","iopub.status.idle":"2022-10-09T21:17:35.834437Z","shell.execute_reply.started":"2022-10-09T21:17:35.822592Z","shell.execute_reply":"2022-10-09T21:17:35.830880Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_18/1181204886.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    df[\"fold\"].value_counts(\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"],"ename":"SyntaxError","evalue":"unexpected EOF while parsing (1181204886.py, line 17)","output_type":"error"}]},{"cell_type":"markdown","source":"## Stack all scans together","metadata":{}},{"cell_type":"code","source":"# take a look at an example\nstudy_paths = glob(f\"../input/rsna-fracture-detection/zip_png_images/1.2.826.0.1.3680043.27262/*\")\nstudy_paths.sort(key=natural_keys)\n        \n# Load images\n#OpenCV use BGR format so we need to transfer RGB to BRG\nstudy_images = [cv2.imread(path)[:,:,::-1] for path in study_paths]\n\nprint(\"# of scans:\", len(study_images))\nprint(\"dimension of each scan:\", study_images[0].shape)\n\n# stack images\nstacked_image = np.stack([img.astype(np.float32) for img in study_images], \n                                 axis=2).transpose(3,0,1,2)\n\nprint(\"dimension of each scan after stack:\", stacked_image.shape)\n\n#show the stacked image \n# cv2.imshow('image', stacked_image)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.836177Z","iopub.status.idle":"2022-10-09T21:17:35.836808Z","shell.execute_reply.started":"2022-10-09T21:17:35.836499Z","shell.execute_reply":"2022-10-09T21:17:35.836523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RSNADataset(Dataset, Randomizable):\n    \n    def __init__(self, csv, mode, transform=None):\n        self.csv = csv\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return self.csv.shape[0]\n    \n    def randomize(self) -> None:\n        '''-> None is a type annotation for the function that states \n        that this function returns None.'''\n        \n        MAX_SEED = np.iinfo(np.uint32).max + 1\n        self.seed = self.R.randint(MAX_SEED, dtype=\"uint32\")\n        \n    def __getitem__(self, index):\n        # Set Random Seed\n        self.randomize()\n        \n        dt = self.csv.iloc[index, :]\n        study_paths = glob(f\"../input/rsna-fracture-detection/zip_png_images/{dt.StudyInstanceUID}/*\")\n        study_paths.sort(key=natural_keys)\n        \n        # Load images\n        study_images = [cv2.imread(path)[:,:,::-1] for path in study_paths]\n        # Stack all scans into 1\n        stacked_image = np.stack([img.astype(np.float32) for img in study_images], \n                                 axis=2).transpose(3,0,1,2)\n        \n        if self.transform:\n            if isinstance(self.transform, Randomizable):\n                self.transform.set_random_state(seed=self.seed)\n                \n            stacked_image = apply_transform(self.transform, stacked_image)\n        \n        if self.mode==\"test\":\n            return {\"image\": stacked_image}\n        else:\n            targets = torch.tensor(dt[target_cols]).float()\n            return {\"image\": stacked_image,\n                    \"targets\": targets}","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.838288Z","iopub.status.idle":"2022-10-09T21:17:35.838887Z","shell.execute_reply.started":"2022-10-09T21:17:35.838602Z","shell.execute_reply":"2022-10-09T21:17:35.838630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# send the data to GPU\ndef data_to_device(data):\n    \n    image, targets = data.values()\n    return image.to(DEVICE), targets.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.841330Z","iopub.status.idle":"2022-10-09T21:17:35.841809Z","shell.execute_reply.started":"2022-10-09T21:17:35.841581Z","shell.execute_reply":"2022-10-09T21:17:35.841613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform\ntrain_transforms = Compose([ScaleIntensity(), \n                            Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), \n                            # TODO - add more here\n                            ToTensor()])\nvalid_transforms = Compose([ScaleIntensity(), \n                          Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), \n                          ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.843432Z","iopub.status.idle":"2022-10-09T21:17:35.843887Z","shell.execute_reply.started":"2022-10-09T21:17:35.843663Z","shell.execute_reply":"2022-10-09T21:17:35.843683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity Check\n\n# Sample data\nsample_df = df.head(6)\n\n# Instantiate Dataset object\ndataset = RSNADataset(csv=sample_df, mode=\"train\", transform=train_transforms)\n# The Dataloader\ndataloader = DataLoader(dataset, batch_size=3, shuffle=False)\n\n# Output of the Dataloader\nfor k, data in enumerate(dataloader):\n    image, targets = data_to_device(data)\n    print( f\"Batch: {k}\", \"\\n\" +\n          \"Image:\", image.shape, \"\\n\" +\n          \"Targets:\", targets, \"\\n\" +\n          \"=\"*50)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.845455Z","iopub.status.idle":"2022-10-09T21:17:35.846173Z","shell.execute_reply.started":"2022-10-09T21:17:35.845955Z","shell.execute_reply":"2022-10-09T21:17:35.845977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataset, dataloader, image, targets\n\n# gabage collector which is used to free up memory, return the counts of objects \n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.847513Z","iopub.status.idle":"2022-10-09T21:17:35.847961Z","shell.execute_reply.started":"2022-10-09T21:17:35.847761Z","shell.execute_reply":"2022-10-09T21:17:35.847781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss & Gradual warmup","metadata":{}},{"cell_type":"markdown","source":"Reference link: [HERE](https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch)\n\ntorch.view(-1):\n* view() reshapes the tensor without copying memory, similar to numpy's reshape().\n* -1 flatten the tensor","metadata":{}},{"cell_type":"code","source":"CRITERION = nn.BCEWithLogitsLoss(reduction='none')\n\ndef get_criterion(logits, target): \n    loss = CRITERION(logits.view(-1), target.view(-1))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.849789Z","iopub.status.idle":"2022-10-09T21:17:35.850529Z","shell.execute_reply.started":"2022-10-09T21:17:35.850308Z","shell.execute_reply":"2022-10-09T21:17:35.850332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    '''\n    src: https://www.kaggle.com/code/boliu0/monai-3d-cnn-training/notebook\n    '''\n    \n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, \n                                                       total_epoch, after_scheduler)\n    \n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier \n                                                     for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        \n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) \n                    for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) \n                    for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.851953Z","iopub.status.idle":"2022-10-09T21:17:35.852668Z","shell.execute_reply.started":"2022-10-09T21:17:35.852407Z","shell.execute_reply":"2022-10-09T21:17:35.852427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Log the info","metadata":{}},{"cell_type":"code","source":"def add_in_file(text, f):\n    \n    with open(f'log_{KERNEL_TYPE}.txt', 'a+') as f:\n        print(text, file=f)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.854001Z","iopub.status.idle":"2022-10-09T21:17:35.854844Z","shell.execute_reply.started":"2022-10-09T21:17:35.854540Z","shell.execute_reply":"2022-10-09T21:17:35.854591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Epoch","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, epoch, f):\n    \n    # Add info to file\n    print(\"Training...\")\n    add_in_file('Training...', f)\n    \n    # Track training time for 1 epoch\n    start_time = time()\n    \n    # === TRAIN ===\n    model.train()\n    train_losses, train_comp_losses = [], []\n    \n    # Loop through the data\n    bar = tqdm(dataloader)\n    for data in bar:\n        image, targets = data_to_device(data)\n        \n        # Train & Optimize\n        optimizer.zero_grad()\n        logits = model(image)\n        loss = get_criterion(logits, targets)\n        loss.sum().backward()\n        optimizer.step()\n        \n        # === COMP LOSS ===\n        comp_loss = get_custom_loss(logits, targets)\n\n        # Save losses\n        train_losses.append(loss.detach().cpu().numpy())\n        train_comp_losses.append(comp_loss.detach().cpu().numpy().mean())\n        \n        gc.collect()\n\n    # Compute Overall Loss\n    mean_train_loss = np.mean(train_losses)\n    mean_comp_loss = np.mean(train_comp_losses)\n    \n    # Save info\n    total_time = round((time() - start_time)/60, 3)\n    add_in_file('Train Mean Loss: {}'.format(mean_train_loss), f)\n    add_in_file('Train Mean Comp Loss: {}'.format(mean_comp_loss), f)\n    add_in_file('~~~ Train Time: {} mins ~~~'.format(total_time), f)\n    \n    # 🐝 Log to W&B\n    wandb.log({\"train_loss\": mean_train_loss,\n               \"train_comp_loss\": mean_comp_loss,}, step=epoch)\n                \n    # Print info\n    print(\"Train Mean Loss:\", mean_train_loss)\n    print(\"Train Mean Comp Loss:\", mean_comp_loss)\n    print(f\"~~~ Train Time: {total_time} mins ~~~\")\n    \n    return mean_train_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.857144Z","iopub.status.idle":"2022-10-09T21:17:35.857655Z","shell.execute_reply.started":"2022-10-09T21:17:35.857421Z","shell.execute_reply":"2022-10-09T21:17:35.857441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation Epoch","metadata":{}},{"cell_type":"code","source":"def valid_epoch(model, dataloader, epoch, f):\n    \n    # Add info to file\n    print(\"Validation...\")\n    add_in_file('Validation...', f)\n    \n    # Track validation time for 1 epoch\n    start_time = time()\n    \n    # === EVAL ===\n    model.eval()\n    valid_preds, valid_targets, valid_comp_loss = [], [], []\n    \n    with torch.no_grad():\n        for data in dataloader:\n            \n            image, targets = data_to_device(data)\n            logits = model(image)\n            \n            # === COMP LOSS ===\n            comp_loss = get_custom_loss(logits, targets)\n            # Save actuals, preds and losses\n            valid_targets.append(targets.detach().cpu())\n            valid_preds.append(logits.detach().cpu())\n            valid_comp_loss.append(comp_loss.detach().cpu().numpy().mean())\n            \n            gc.collect()\n            \n    # Overall Valid Loss\n    valid_losses = get_criterion(torch.cat(valid_preds), torch.cat(valid_targets)).numpy()\n    mean_valid_loss = np.mean(valid_losses)\n    \n    # Overall Competition Loss\n    mean_comp_valid_loss = np.mean(valid_comp_loss)\n    \n    # Compute Area Under Curve\n    PREDS = np.concatenate(torch.cat(valid_preds).numpy())\n    TARGETS = np.concatenate(torch.cat(valid_targets).numpy())\n    auc = roc_auc_score(TARGETS, PREDS)\n    \n    # Save info\n    total_time = round((time() - start_time)/60, 3)\n    add_in_file('Valid Mean Loss: {}'.format(mean_valid_loss), f)\n    add_in_file('Valid Mean Comp Loss: {}'.format(mean_comp_valid_loss), f)\n    add_in_file('Valid AUC: {}'.format(auc), f)\n    add_in_file('~~~ Valid Time: {} mins ~~~'.format(total_time), f)\n    \n    # 🐝 Log to W&B\n    wandb.log({\"valid_loss\": mean_valid_loss,\n               \"valid_comp_loss\": mean_comp_valid_loss,\n               \"valid_auc\": auc}, step=epoch)\n        \n    # Print info\n    print(\"Valid Mean Loss:\", mean_valid_loss)\n    print(\"Valid Mean Comp Loss:\", mean_comp_valid_loss)\n    print(\"Valid AUC:\", auc)\n    print(f\"~~~ Validation Time: {total_time} mins ~~~\")\n    \n    return mean_valid_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.859362Z","iopub.status.idle":"2022-10-09T21:17:35.859792Z","shell.execute_reply.started":"2022-10-09T21:17:35.859587Z","shell.execute_reply":"2022-10-09T21:17:35.859610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_train(fold):\n    \n    # 🐝 W&B Tracking\n    RUN_CONFIG = CONFIG.copy()\n    params = dict(model=\"densenet121\", \n                  epochs=EPOCHS, \n                  split=N_SPLITS, \n                  batch=BATCH_SIZE, lr=LR,\n                  img_size=IMG_RESIZE, stack_size=STACK_RESIZE,\n                  data_size=DF_SIZE)\n    RUN_CONFIG.update(params)\n    run = wandb.init(project='RSNA_SpineFracture', config=CONFIG)\n    \n    # Get the train and valid data\n    train = df[df[\"fold\"] != fold].reset_index(drop=True)\n    valid = df[df[\"fold\"] == fold].reset_index(drop=True)\n    \n    # Create the Dataset & Dataloader\n    train_dataset = RSNADataset(csv=train, mode=\"train\", \n                                transform=train_transforms)\n    valid_dataset = RSNADataset(csv=valid, mode=\"train\", \n                                transform=valid_transforms)\n    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                             sampler=RandomSampler(train_dataset))\n    validloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n    \n    # Model\n    model = densenet.densenet121(spatial_dims=3, in_channels=3,\n                                 out_channels=OUT_DIM)\n    model.class_layers.out = nn.Sequential(nn.Linear(in_features=1024, out_features=OUT_DIM), \n                                           nn.Softmax(dim=1))\n    model.to(DEVICE)\n    wandb.watch(model, log_freq=100) # 🐝\n    \n    # Optimizer & Scheduler\n    optimizer = optim.Adam(model.parameters(), lr=LR)\n    scheduler_cosine = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, \n                                                total_epoch=1, \n                                                after_scheduler=scheduler_cosine)\n    \n    # Initiate initial loss\n    valid_loss_BEST = 1000\n    # Create model name\n    model_file = f'{KERNEL_TYPE}_best_fold{fold}.pth'\n    # Create file to save outputs\n    f = open(f'log_{KERNEL_TYPE}.txt', 'a')\n    \n    for epoch in range(EPOCHS):\n        \n        add_in_file('======== Epoch: {}/{} ========'.format(epoch+1, EPOCHS), f)\n        print(\"=\"*8, f\"Epoch {epoch}\", \"=\"*8)\n        \n        scheduler_warmup.step(epoch-1)\n        \n        # Train & Validate\n        mean_train_loss = train_epoch(model, trainloader, optimizer, epoch, f)\n        mean_valid_loss = valid_epoch(model, validloader, epoch, f)\n        \n        # Save model\n        if mean_valid_loss < valid_loss_BEST:\n            print('Saving model ...')\n            add_in_file('Saving model => {}'.format(model_file), f)\n            torch.save(model.state_dict(), model_file)\n            valid_loss_BEST = mean_valid_loss\n            \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    # 🐝 Experiment End\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.861333Z","iopub.status.idle":"2022-10-09T21:17:35.861779Z","shell.execute_reply.started":"2022-10-09T21:17:35.861542Z","shell.execute_reply":"2022-10-09T21:17:35.861580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"run_train(fold=0)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.863888Z","iopub.status.idle":"2022-10-09T21:17:35.864305Z","shell.execute_reply.started":"2022-10-09T21:17:35.864100Z","shell.execute_reply":"2022-10-09T21:17:35.864120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 🐝 Save Artifacts\nsave_dataset_artifact(run_name=\"save_logs\", artifact_name=\"logs\",\n                      path=\"../input/rsna-fracture-detection/log_densenet121_baseline.txt\", data_type=\"dataset\")\nsave_dataset_artifact(run_name=\"save_model\", artifact_name=\"model\",\n                      path=\"../input/rsna-fracture-detection/densenet121_baseline_best_fold0.pth\", data_type=\"model\")","metadata":{"execution":{"iopub.status.busy":"2022-10-09T21:17:35.866151Z","iopub.status.idle":"2022-10-09T21:17:35.866655Z","shell.execute_reply.started":"2022-10-09T21:17:35.866414Z","shell.execute_reply":"2022-10-09T21:17:35.866434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference","metadata":{}},{"cell_type":"markdown","source":"* [RSNA Fracture Detect: PyTorch DenseNet train](https://www.kaggle.com/code/andradaolteanu/rsna-fracture-detect-pytorch-densenet-train)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}