{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install warmup_scheduler\n",
    "# !pip install monai\n",
    "# !pip install -U \"python-gdcm\" pydicom pylibjpeg\n",
    "# !pip install -U torchvision\n",
    "# !pip install opencv-python\n",
    "# !pip install opencv-python-headless\n",
    "# !pip install wandb\n",
    "# !pip install nibabel\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: warmup_scheduler in /opt/conda/lib/python3.7/site-packages (0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.16.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (0.22.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (3.1.3)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (0.14.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (59.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: monai in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from monai) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->monai) (4.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.13.1)\n",
      "Requirement already satisfied: torch==1.12.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install warmup_scheduler\n",
    "!pip install -U pydicom\n",
    "!pip install albumentations\n",
    "!pip install monai\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import uuid\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import cv2\n",
    "import wandb\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import display_html\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "import multiprocessing as mp\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# .dcm handling\n",
    "import pydicom\n",
    "# import nibabel as nib\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "# Environment check\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import albumentations\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "# MONAI 3D\n",
    "from monai.transforms import Randomizable, apply_transform\n",
    "from monai.transforms import Compose, Resize, ScaleIntensity, ToTensor, RandAffine\n",
    "from monai.networks.nets import densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    '''Reads in all .csv files.'''\n",
    "    \n",
    "    train = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "    train_bbox = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv\")\n",
    "    test = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/test.csv\")\n",
    "    \n",
    "    return train, train_bbox, test\n",
    "\n",
    "def get_csv_info(csv, name=\"Default\"):\n",
    "    '''Prints main information for the speciffied .csv file.'''\n",
    "    \n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Shape:\", csv.shape)\n",
    "    print(f\"Missing Values:\", csv.isna().sum().sum(), \"total missing datapoints.\")\n",
    "    print(\"Columns:\", list(csv.columns), \"\\n\")\n",
    "    \n",
    "    display_html(csv.head())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "# some patients have reverse order for the CT scan, so have a function to check\n",
    "def check_reverse_required(path):\n",
    "    paths = list(path.glob('*'))\n",
    "    paths.sort(key=lambda x:int(x.stem))\n",
    "    z_first = pydicom.dcmread(paths[0]).get(\"ImagePositionPatient\")[-1]\n",
    "    z_last = pydicom.dcmread(paths[-1]).get(\"ImagePositionPatient\")[-1]\n",
    "    if z_last < z_first:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "paths = {\n",
    "    'train': Path('../input/rsna-2022-cervical-spine-fracture-detection/train.csv'),\n",
    "    'train_bbox': Path('../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv'),\n",
    "    'train_images': Path('../input/rsna-2022-cervical-spine-fracture-detection/train_images'),\n",
    "    'train_nifti_segments': Path('../input/rsna-2022-cervical-spine-fracture-detection/segmentations'),\n",
    "    'test_df': Path('../input/rsna-2022-cervical-spine-fracture-detection/test.csv'),\n",
    "    'test_images': Path('../input/rsna-2022-cervical-spine-fracture-detection/test_images')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom weighted loss function\n",
    "# From: https://www.kaggle.com/code/andradaolteanu/rsna-fracture-detect-pytorch-densenet-train#2.-Data-Split\n",
    "def get_custom_loss(logits, targets):\n",
    "    \n",
    "    # Compute the weights\n",
    "    weights = targets * competition_weights['+'] + (1 - targets) * competition_weights['-']\n",
    "    \n",
    "    # Losses on label and exam level\n",
    "    L = torch.zeros(targets.shape, device=DEVICE)\n",
    "\n",
    "    w = weights\n",
    "    y = targets\n",
    "    p = logits\n",
    "    eps=1e-8\n",
    "\n",
    "    for i in range(L.shape[0]):\n",
    "        for j in range(L.shape[1]):\n",
    "            L[i, j] = -w[i, j] * (\n",
    "                y[i, j] * math.log(p[i, j] + eps) +\n",
    "                (1 - y[i, j]) * math.log(1 - p[i, j] + eps))\n",
    "            \n",
    "    # Average Loss on Exam (or patient)\n",
    "    Exams_Loss = torch.div(torch.sum(L, dim=1), torch.sum(w, dim=1))\n",
    "    \n",
    "    return Exams_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "UUID: b5b28ea2-548c-11ed-8f29-951b5e95cbdb\n"
     ]
    }
   ],
   "source": [
    "# Environment check\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set seed\n",
    "set_seed(0)\n",
    "\n",
    "# set GPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Kaggle Notebook Setup\n",
    "DF_SIZE = .15\n",
    "N_SPLITS = 5\n",
    "KERNEL_TYPE = 'densenet121_baseline'\n",
    "IMG_RESIZE = 150\n",
    "STACK_RESIZE = 50\n",
    "use_amp = False\n",
    "NUM_WORKERS = 0 #mp.cpu_count()\n",
    "BATCH_SIZE = 8 #16\n",
    "LR = 0.0005\n",
    "OUT_DIM = 8\n",
    "EPOCHS = 5\n",
    "UUID = uuid.uuid1()\n",
    "print(f'UUID: {UUID}')\n",
    "\n",
    "target_cols = ['C1', 'C2', 'C3', \n",
    "               'C4', 'C5', 'C6', 'C7',\n",
    "               'patient_overall']\n",
    "\n",
    "competition_weights = {\n",
    "    '-' : torch.tensor([1, 1, 1, 1, 1, 1, 1, 7], dtype=torch.float, device=DEVICE),\n",
    "    '+' : torch.tensor([2, 2, 2, 2, 2, 2, 2, 14], dtype=torch.float, device=DEVICE),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.21561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.1363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n",
       "0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0\n",
       "1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n",
       "2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
       "3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n",
       "4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv(\"/root/input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: (302, 9)\n",
      "K Folds Count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    61\n",
       "0    61\n",
       "3    60\n",
       "4    60\n",
       "2    60\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample down df\n",
    "instances = df.StudyInstanceUID.unique().tolist()\n",
    "instances = random.sample(instances, k=int(len(instances)*DF_SIZE))\n",
    "df = df[df[\"StudyInstanceUID\"].isin(instances)].reset_index(drop=True)\n",
    "print(\"Dataframe size:\", df.shape)\n",
    "\n",
    "# Create folds\n",
    "kfold = GroupKFold(n_splits=N_SPLITS)\n",
    "df['fold'] = -1\n",
    "\n",
    "# Append fold\n",
    "for k, (_, valid_i) in enumerate(kfold.split(df,\n",
    "                                             groups=df.StudyInstanceUID)):\n",
    "    df.loc[valid_i, 'fold'] = k\n",
    "    \n",
    "print(\"K Folds Count:\")\n",
    "df[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNADataset(Dataset, Randomizable):\n",
    "    \n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "        self.csv = csv\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "    def randomize(self) -> None:\n",
    "        '''-> None is a type annotation for the function that states \n",
    "        that this function returns None.'''\n",
    "        \n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        self.seed = self.R.randint(MAX_SEED, dtype=\"uint32\")\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Set Random Seed\n",
    "        self.randomize()\n",
    "        \n",
    "        dt = self.csv.iloc[index, :]\n",
    "        study_paths = glob(f\"/root/input/rsna-2022-cervical-spine-fracture-detection/train_images/{dt.StudyInstanceUID}/*\")\n",
    "        study_paths.sort(key=natural_keys)\n",
    "        \n",
    "        # Load images\n",
    "        study_images = [cv2.imread(path)[:,:,::-1] for path in study_paths]\n",
    "        # Stack all scans into 1\n",
    "        stacked_image = np.stack([img.astype(np.float32) for img in study_images], \n",
    "                                 axis=2).transpose(3,0,1,2)\n",
    "        \n",
    "        if self.transform:\n",
    "            if isinstance(self.transform, Randomizable):\n",
    "                self.transform.set_random_state(seed=self.seed)\n",
    "                \n",
    "            stacked_image = apply_transform(self.transform, stacked_image)\n",
    "        \n",
    "        if self.mode==\"test\":\n",
    "            return {\"image\": stacked_image}\n",
    "        else:\n",
    "            targets = torch.tensor(dt[target_cols]).float()\n",
    "            return {\"image\": stacked_image,\n",
    "                    \"targets\": targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send the data to GPU\n",
    "def data_to_device(data):\n",
    "    \n",
    "    image, targets = data.values()\n",
    "    return image.to(DEVICE), targets.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "train_transforms = Compose([ScaleIntensity(), \n",
    "                            Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), \n",
    "                            # TODO - add more here\n",
    "                            ToTensor()])\n",
    "valid_transforms = Compose([ScaleIntensity(), \n",
    "                          Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), \n",
    "                          ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & Gradual warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference link: [HERE](https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch)\n",
    "\n",
    "torch.view(-1):\n",
    "* view() reshapes the tensor without copying memory, similar to numpy's reshape().\n",
    "* -1 flatten the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CRITERION = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "def get_criterion(logits, target): \n",
    "    loss = CRITERION(logits.view(-1), target.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    '''\n",
    "    src: https://www.kaggle.com/code/boliu0/monai-3d-cnn-training/notebook\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, \n",
    "                                                       total_epoch, after_scheduler)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier \n",
    "                                                     for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        \n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) \n",
    "                    for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) \n",
    "                    for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_in_file(text, f):\n",
    "    \n",
    "    with open(f'log_{KERNEL_TYPE}_{UUID}.txt', 'a+') as f:\n",
    "        print(text, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, epoch, f):\n",
    "    \n",
    "    # Add info to file\n",
    "    print(\"Training...\")\n",
    "    add_in_file('Training...', f)\n",
    "    \n",
    "    # Track training time for 1 epoch\n",
    "    start_time = time()\n",
    "    \n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    train_losses, train_comp_losses = [], []\n",
    "    \n",
    "    # Loop through the data\n",
    "    bar = tqdm(dataloader)\n",
    "    for data in bar:\n",
    "        image, targets = data_to_device(data)\n",
    "        \n",
    "        # Train & Optimize\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image)\n",
    "        loss = get_criterion(logits, targets)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # === COMP LOSS ===\n",
    "        comp_loss = get_custom_loss(logits, targets)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses.append(loss.detach().cpu().numpy())\n",
    "        train_comp_losses.append(comp_loss.detach().cpu().numpy().mean())\n",
    "        \n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    print(train_losses)\n",
    "    # Compute Overall Loss\n",
    "    mean_train_loss = np.mean(np.concatenate(train_losses))\n",
    "    mean_comp_loss = np.mean(np.concatenate(train_comp_losses))\n",
    "    \n",
    "    # Save info\n",
    "    total_time = round((time() - start_time)/60, 3)\n",
    "    add_in_file('Train Mean Loss: {}'.format(mean_train_loss), f)\n",
    "    add_in_file('Train Mean Comp Loss: {}'.format(mean_comp_loss), f)\n",
    "    add_in_file('~~~ Train Time: {} mins ~~~'.format(total_time), f)\n",
    "    \n",
    "                \n",
    "    # Print info\n",
    "    print(\"Train Mean Loss:\", mean_train_loss)\n",
    "    print(\"Train Mean Comp Loss:\", mean_comp_loss)\n",
    "    print(f\"~~~ Train Time: {total_time} mins ~~~\")\n",
    "    \n",
    "    return mean_train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_epoch(model, dataloader, epoch, f):\n",
    "    \n",
    "    # Add info to file\n",
    "    print(\"Validation...\")\n",
    "    add_in_file('Validation...', f)\n",
    "    \n",
    "    # Track validation time for 1 epoch\n",
    "    start_time = time()\n",
    "    \n",
    "    # === EVAL ===\n",
    "    model.eval()\n",
    "    valid_preds, valid_targets, valid_comp_loss = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            \n",
    "            image, targets = data_to_device(data)\n",
    "            logits = model(image)\n",
    "            \n",
    "            # === COMP LOSS ===\n",
    "            comp_loss = get_custom_loss(logits, targets)\n",
    "            # Save actuals, preds and losses\n",
    "            valid_targets.append(targets.detach().cpu())\n",
    "            valid_preds.append(logits.detach().cpu())\n",
    "            valid_comp_loss.append(comp_loss.detach().cpu().numpy().mean())\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "    # Overall Valid Loss\n",
    "    valid_losses = get_criterion(torch.cat(valid_preds), torch.cat(valid_targets)).numpy()\n",
    "    mean_valid_loss = np.mean(np.concatenate(valid_losses))\n",
    "    \n",
    "    # Overall Competition Loss\n",
    "    mean_comp_valid_loss = np.mean(np.concatenate(valid_comp_loss))\n",
    "    \n",
    "    # Compute Area Under Curve\n",
    "    PREDS = np.concatenate(torch.cat(valid_preds).numpy())\n",
    "    TARGETS = np.concatenate(torch.cat(valid_targets).numpy())\n",
    "    auc = roc_auc_score(TARGETS, PREDS)\n",
    "    \n",
    "    # Save info\n",
    "    total_time = round((time() - start_time)/60, 3)\n",
    "    add_in_file('Valid Mean Loss: {}'.format(mean_valid_loss), f)\n",
    "    add_in_file('Valid Mean Comp Loss: {}'.format(mean_comp_valid_loss), f)\n",
    "    add_in_file('Valid AUC: {}'.format(auc), f)\n",
    "    add_in_file('~~~ Valid Time: {} mins ~~~'.format(total_time), f)\n",
    "\n",
    "        \n",
    "    # Print info\n",
    "    print(\"Valid Mean Loss:\", mean_valid_loss)\n",
    "    print(\"Valid Mean Comp Loss:\", mean_comp_valid_loss)\n",
    "    print(\"Valid AUC:\", auc)\n",
    "    print(f\"~~~ Validation Time: {total_time} mins ~~~\")\n",
    "    \n",
    "    return mean_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_train(fold):\n",
    "\n",
    "    \n",
    "    # Get the train and valid data\n",
    "    train = df[df[\"fold\"] != fold].reset_index(drop=True)\n",
    "    valid = df[df[\"fold\"] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # Create the Dataset & Dataloader\n",
    "    train_dataset = RSNADataset(csv=train, mode=\"train\", \n",
    "                                transform=train_transforms)\n",
    "    valid_dataset = RSNADataset(csv=valid, mode=\"train\", \n",
    "                                transform=valid_transforms)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                             sampler=RandomSampler(train_dataset), num_workers=NUM_WORKERS)\n",
    "    validloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    # Model\n",
    "    model = densenet.densenet121(spatial_dims=3, in_channels=3,\n",
    "                                 out_channels=OUT_DIM)\n",
    "    model.class_layers.out = nn.Sequential(nn.Linear(in_features=1024, out_features=OUT_DIM), \n",
    "                                           nn.Softmax(dim=1))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler_cosine = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, \n",
    "                                                total_epoch=1, \n",
    "                                                after_scheduler=scheduler_cosine)\n",
    "    \n",
    "    # Initiate initial loss\n",
    "    valid_loss_BEST = 1000\n",
    "    # Create model name\n",
    "    model_file = f'{KERNEL_TYPE}_best_fold{fold}_{UUID}.pth'\n",
    "    # Create file to save outputs\n",
    "    f = open(f'log_{KERNEL_TYPE}_{UUID}.txt', 'a')\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        add_in_file('======== Epoch: {}/{} ========'.format(epoch+1, EPOCHS), f)\n",
    "        print(\"=\"*8, f\"Epoch {epoch}\", \"=\"*8)\n",
    "        \n",
    "        scheduler_warmup.step(epoch-1)\n",
    "        \n",
    "        # Train & Validate\n",
    "        mean_train_loss = train_epoch(model, trainloader, optimizer, epoch, f)\n",
    "        mean_valid_loss = valid_epoch(model, validloader, epoch, f)\n",
    "        \n",
    "        # Save model\n",
    "        if mean_valid_loss < valid_loss_BEST:\n",
    "            print('Saving model ...')\n",
    "            add_in_file('Saving model => {}'.format(model_file), f)\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            valid_loss_BEST = mean_valid_loss\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 0 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 28/31 [21:07<02:18, 46.02s/it]"
     ]
    }
   ],
   "source": [
    "run_train(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.cuda(), (3,150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [RSNA Fracture Detect: PyTorch DenseNet train](https://www.kaggle.com/code/andradaolteanu/rsna-fracture-detect-pytorch-densenet-train)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
